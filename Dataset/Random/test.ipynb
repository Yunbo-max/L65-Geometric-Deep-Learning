{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import InMemoryDataset, download_url\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "class MyOwnDataset(InMemoryDataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None, pre_filter=None):\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        # Return a list of raw file names (if any)\n",
    "        return ['some_file_1', 'some_file_2']\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        # Return the name of the processed file\n",
    "        return ['data_long.pt']\n",
    "\n",
    "    def download(self):\n",
    "        # Download raw data if needed\n",
    "        # Example:\n",
    "        # download_url(url, self.raw_dir)\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "        # Example of processing raw data to create PyG Data objects\n",
    "        # Read data into a list of Data objects\n",
    "        data_list = []\n",
    "\n",
    "        # Example: create dummy data\n",
    "        for i in range(10):\n",
    "            edge_index = torch.tensor([[0, 1, 1, 2],\n",
    "                                       [1, 0, 2, 1]], dtype=torch.long)\n",
    "            x = torch.randn(3, 5)  # Node features\n",
    "            y = torch.tensor([0, 1, 0], dtype=torch.long)  # Node labels\n",
    "            data = Data(x=x, edge_index=edge_index, y=y)\n",
    "            data_list.append(data)\n",
    "\n",
    "        # Apply pre_filter if defined\n",
    "        if self.pre_filter is not None:\n",
    "            data_list = [data for data in data_list if self.pre_filter(data)]\n",
    "\n",
    "        # Apply pre_transform if defined\n",
    "        if self.pre_transform is not None:\n",
    "            data_list = [self.pre_transform(data) for data in data_list]\n",
    "\n",
    "        # Save the processed data list\n",
    "        self.data, self.slices = self.collate(data_list)\n",
    "        torch.save((self.data, self.slices), self.processed_paths[0])\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}()'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyOwnDataset()\n"
     ]
    }
   ],
   "source": [
    "dataset = MyOwnDataset(root='data/')\n",
    "print(dataset)  # This will print: MyOwnDataset()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Accessing a single data instance\n",
    "data = dataset[0]\n",
    "print(data)\n",
    "\n",
    "# Length of the dataset\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 61\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TUDataset\n\u001b[1;32m     59\u001b[0m transform \u001b[38;5;241m=\u001b[39m T\u001b[38;5;241m.\u001b[39mCompose([T\u001b[38;5;241m.\u001b[39mToUndirected(), T\u001b[38;5;241m.\u001b[39mAddSelfLoops()])\n\u001b[0;32m---> 61\u001b[0m dataset \u001b[38;5;241m=\u001b[39m TUDataset(\u001b[43mpath\u001b[49m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMUTAG\u001b[39m\u001b[38;5;124m'\u001b[39m, transform\u001b[38;5;241m=\u001b[39mtransform)\n\u001b[1;32m     62\u001b[0m data \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# Implicitly transform data on every access.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m data \u001b[38;5;241m=\u001b[39m TUDataset(path, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMUTAG\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'path' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import InMemoryDataset, Data\n",
    "\n",
    "\n",
    "class MyOwnDataset(InMemoryDataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None, pre_filter=None):\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ['some_file_1', 'some_file_2']  # Add your raw file names here\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data_long.pt']  # Processed file name\n",
    "\n",
    "    def download(self):\n",
    "        # Download to `self.raw_dir`.\n",
    "        # Implement your downloading logic here\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "        # Dummy data creation, replace this with your actual data loading and processing\n",
    "        data_list = []\n",
    "\n",
    "        # Creating dummy data (you should replace this with your actual data loading)\n",
    "        for i in range(10):\n",
    "            x = torch.tensor([[i, i + 1], [i + 2, i + 3]], dtype=torch.float)\n",
    "            edge_index = torch.tensor([[0, 1], [1, 0]], dtype=torch.long)\n",
    "            data = Data(x=x, edge_index=edge_index)\n",
    "            data_list.append(data)\n",
    "\n",
    "        if self.pre_filter is not None:\n",
    "            data_list = [data for data in data_list if self.pre_filter(data)]\n",
    "\n",
    "        if self.pre_transform is not None:\n",
    "            data_list = [self.pre_transform(data) for data in data_list]\n",
    "\n",
    "        # Save the processed data\n",
    "        torch.save(self.collate(data_list), self.processed_paths[0])\n",
    "\n",
    "    # Define your pre_filter function here if needed\n",
    "    def pre_filter(self, data):\n",
    "        # Example pre_filter: filtering out data based on some condition\n",
    "        return data.x.sum() > 10  # Filter out data if sum of x is less than or equal to 10\n",
    "\n",
    "    # Define your pre_transform function here if needed\n",
    "    def pre_transform(self, data):\n",
    "        # Example pre_transform: doubling the value of x\n",
    "        data.x = data.x * 2\n",
    "        return data\n",
    "\n",
    "\n",
    "# Example usage of the custom dataset\n",
    "dataset = MyOwnDataset(root='dataset', transform=None, pre_transform=None, pre_filter=None)\n",
    "print(len(dataset))  # Print number of data points in the dataset\n",
    "print(dataset.num_classes)  # Print number of classes in the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[2, 2], edge_index=[2, 2])\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
