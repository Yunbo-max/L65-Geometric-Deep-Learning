{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcHQFzsOFwPx"
      },
      "source": [
        "# L65 Practical - An Introduction to Graph Neural Networks & Geometric Deep Learning\n",
        "\n",
        "Welcome to **the Practical** for L65 - Geometric Deep Learning!\n",
        "\n",
        "## Introduction\n",
        "\n",
        "Graph Neural Networks (GNNs) are a part of a broad and emerging research paradigm called **Geometric Deep Learning** -- devising neural network architectures that respect the invariances and symmetries in data. This practical aims to be a gentle introduction into the world of Geometric Deep Learning, with a focus on GNNs.\n",
        "\n",
        "## What's to come in this practical\n",
        "\n",
        "In this practical we will start with an introduction to graph-structured data and GNNs, using node classification on a citation network as an example. We will then transition to graph classification tasks on molecular data to study GNNs for geometric graphs embedded in 3D space with coordinates.\n",
        "\n",
        "The **aims** of this practical are as follows:\n",
        "\n",
        "1. Understanding **invariant** and **equivariant** properties of Graph Neural Networks, from theory and proofs to programming and unit testing.\n",
        "2. Code up your first GNNs from scratch to understand the details of Graph Convolutional Networks and batching graph datasets with variable graph sizes per sample.\n",
        "2. Becoming hands-on with [**PyTorch Geometric**](https://pytorch-geometric.readthedocs.io/en/latest/) (PyG), a popular library\n",
        "for developing state-of-the-art GNNs and Geometric Deep Learning models. In particular, gaining familiarity with the `MessagePassing` base class for designing novel GNN layers and the `Data` object for representing graph datasets.\n",
        "3. Gaining an appreciation of the fundamental principles behind constructing GNN layers that take advantage of **geometric information** for graph data located in **3D space**, a highly active area of GNN research.\n",
        "\n",
        "## Outline\n",
        "\n",
        "This practical is split into 2 parts:\n",
        "\n",
        "**Part 1:** Introduction to GNNs\n",
        "- Understand how to work with graph-structure data.\n",
        "- Implement your first GNNLayer for node-level prediction.\n",
        "- Create mini-batches for graphs.\n",
        "- Implement your first GNNLayer for graph-level prediction.\n",
        "\n",
        "**Part 2:** GNNs for geometric graphs\n",
        "- GNNs with 3D coordinate information.\n",
        "- Invariant message passing GNNs.\n",
        "- Equivariant message passing GNNs.\n",
        "- Understanding the benefits of equivariance over invariance.\n",
        "\n",
        "⚠️ Coding tasks have associated **unit tests** (marked with ✅). While passing them does not guarantee your implementation is 100% correct, they represent good sanity check and they are designed for you to more easily identify potential mistakes. Marking would be primarily based on the results of the unit tests.\n",
        "\n",
        "## Authors\n",
        "\n",
        "**Here are the authors** (in alphabetical order): Do not hesitate to reach out to us for any queries and feedback!\n",
        "\n",
        "- Chaitanya K. Joshi (ckj24@cl.cam.ac.uk)\n",
        "- Iulia Duta (id366@cam.ac.uk)\n",
        "- Miruna Cretu (mtc49@cam.ac.uk)\n",
        "- Paul Scherer (pms69@cam.ac.uk)\n",
        "- Rishabh Jain (rj412@cam.ac.uk)\n",
        "\n",
        "Previous versions of this practical were also prepared by:\n",
        "- Charles Harris\n",
        "- Cristian Bodnar\n",
        "- Julia Komorowska\n",
        "- Pietro Barbiero\n",
        "- Simon V. Mathis\n",
        "- Ramon Viñas Torné\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qU87TNON39IV"
      },
      "source": [
        "# ⚙️ [Setup] Installation and Setup\n",
        "\n",
        "**❗️Note:** You will need a GPU to complete this practical. Remember to click `Runtime -> Change runtime type`, and set the `hardware accelerator` to **GPU**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ZoyyKP8bWk7a"
      },
      "outputs": [],
      "source": [
        "# #@title [RUN] Sanity check torch version and GPU runtime\n",
        "\n",
        "# import torch\n",
        "# assert torch.cuda.is_available(), \"WARNING! You are running on a non-GPU instance. For this practical a GPU is highly recommended.\"\n",
        "# REQUIRED_VERSION = \"2.1.0+cu121\"\n",
        "# TORCH_VERSION = torch.__version__\n",
        "# CUDA_VERSION = TORCH_VERSION.split(\"+\")\n",
        "\n",
        "# if TORCH_VERSION != REQUIRED_VERSION:\n",
        "#   print(f\"Detected torch version {TORCH_VERSION}, but notebook was created for {REQUIRED_VERSION}\")\n",
        "#   print(f\"Attempting installation of {REQUIRED_VERSION}\")\n",
        "#   !pip install torch==2.1.0+cu121\n",
        "# print(\"Correct version of torch detected. You are running on a machine with GPU.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZCNrlEcbWy1t"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Installing PyTorch Geometric\n",
            "Installing other libraries\n",
            "Requirement already satisfied: networkx in /Users/yunbo/anaconda3/envs/basic/lib/python3.9/site-packages (3.1)\n",
            "Collecting mycolorpy\n",
            "  Downloading mycolorpy-1.5.1.tar.gz (2.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: numpy in /Users/yunbo/anaconda3/envs/basic/lib/python3.9/site-packages (from mycolorpy) (1.26.2)\n",
            "Requirement already satisfied: matplotlib in /Users/yunbo/anaconda3/envs/basic/lib/python3.9/site-packages (from mycolorpy) (3.8.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /Users/yunbo/anaconda3/envs/basic/lib/python3.9/site-packages (from matplotlib->mycolorpy) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /Users/yunbo/anaconda3/envs/basic/lib/python3.9/site-packages (from matplotlib->mycolorpy) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /Users/yunbo/anaconda3/envs/basic/lib/python3.9/site-packages (from matplotlib->mycolorpy) (4.25.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/yunbo/anaconda3/envs/basic/lib/python3.9/site-packages (from matplotlib->mycolorpy) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/yunbo/anaconda3/envs/basic/lib/python3.9/site-packages (from matplotlib->mycolorpy) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /Users/yunbo/anaconda3/envs/basic/lib/python3.9/site-packages (from matplotlib->mycolorpy) (10.0.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /Users/yunbo/anaconda3/envs/basic/lib/python3.9/site-packages (from matplotlib->mycolorpy) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /Users/yunbo/anaconda3/envs/basic/lib/python3.9/site-packages (from matplotlib->mycolorpy) (2.8.2)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/yunbo/anaconda3/envs/basic/lib/python3.9/site-packages (from matplotlib->mycolorpy) (6.1.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /Users/yunbo/anaconda3/envs/basic/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib->mycolorpy) (3.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /Users/yunbo/anaconda3/envs/basic/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib->mycolorpy) (1.16.0)\n",
            "Building wheels for collected packages: mycolorpy\n",
            "  Building wheel for mycolorpy (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for mycolorpy: filename=mycolorpy-1.5.1-py3-none-any.whl size=3851 sha256=04a89d79a689e7b293c1a46d96c8e0bd3ccfc52c843332d64f3cba7215c29ba2\n",
            "  Stored in directory: /Users/yunbo/Library/Caches/pip/wheels/b9/56/d6/a163bcbec3bb69f3f7797b1b542870b18d7e31ff5dbc0b87e3\n",
            "Successfully built mycolorpy\n",
            "Installing collected packages: mycolorpy\n",
            "Successfully installed mycolorpy-1.5.1\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Installing collected packages: colorama\n",
            "Successfully installed colorama-0.4.6\n"
          ]
        }
      ],
      "source": [
        "#@title [RUN] Install required python libraries\n",
        "import os\n",
        "\n",
        "# Install PyTorch Geometric and other libraries\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "    print(\"Installing PyTorch Geometric\")\n",
        "    !pip install -q torch-scatter -f https://data.pyg.org/whl/torch-2.1.0+cu121.html\n",
        "    !pip install -q torch-sparse -f https://data.pyg.org/whl/torch-2.1.0+cu121.html\n",
        "    !pip install -q torch-geometric\n",
        "    print(\"Installing other libraries\")\n",
        "    !pip install -q rdkit-pypi==2021.9.4\n",
        "    !pip install -q py3Dmol==1.8.0\n",
        "    !pip install networkx\n",
        "    !pip install mycolorpy\n",
        "    !pip install colorama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ZLrrWpkk6xv-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All imports succeeded.\n",
            "Python version 3.9.18 (main, Sep 11 2023, 08:25:10) \n",
            "[Clang 14.0.6 ]\n",
            "PyTorch version 2.1.2\n",
            "PyG version 2.4.0\n"
          ]
        }
      ],
      "source": [
        "#@title [RUN] Import python modules\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import math\n",
        "import random\n",
        "import itertools\n",
        "from datetime import datetime\n",
        "from typing import Mapping, Tuple, Sequence, List\n",
        "\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "from scipy.stats import ortho_group\n",
        "from scipy.linalg import block_diag\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from torch.nn import Embedding, Linear, ReLU, BatchNorm1d, Module, ModuleList, Sequential\n",
        "\n",
        "import torch_geometric\n",
        "from torch_geometric.data import Data, Batch\n",
        "from torch_geometric.loader import DataLoader\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.utils import remove_self_loops, to_dense_adj, dense_to_sparse\n",
        "from torch_geometric.datasets import Planetoid, QM9\n",
        "from torch_geometric.nn import MessagePassing, global_mean_pool\n",
        "from torch_scatter import scatter, scatter_mean, scatter_max, scatter_sum\n",
        "\n",
        "import rdkit.Chem as Chem\n",
        "from rdkit.Geometry.rdGeometry import Point3D\n",
        "from rdkit.Chem import QED, Crippen, rdMolDescriptors, rdmolops\n",
        "from rdkit.Chem.Draw import IPythonConsole\n",
        "\n",
        "import py3Dmol\n",
        "from rdkit.Chem import AllChem\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from mycolorpy import colorlist as mcp\n",
        "import matplotlib.cm as cm\n",
        "import colorama\n",
        "\n",
        "# from google.colab import files\n",
        "from IPython.display import HTML\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "print(\"All imports succeeded.\")\n",
        "print(\"Python version {}\".format(sys.version))\n",
        "print(\"PyTorch version {}\".format(torch.__version__))\n",
        "print(\"PyG version {}\".format(torch_geometric.__version__))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "wV9ViIZBZ1TG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All seeds set.\n"
          ]
        }
      ],
      "source": [
        "#@title [RUN] Set random seed for deterministic results\n",
        "\n",
        "def seed(seed=0):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seed(0)\n",
        "print(\"All seeds set.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "1us6k7hEq8Q0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Helper functions loaded.\n"
          ]
        }
      ],
      "source": [
        "#@title [RUN] Helper functions for data preparation\n",
        "\n",
        "class SetTarget:\n",
        "    \"\"\"\n",
        "    This transform modifies the labels vector per data sample to only keep\n",
        "    the label for a specific target (there are 19 targets in QM9).\n",
        "\n",
        "    Note: for this practical, we have hardcoded the target to be target #0,\n",
        "    i.e. the electric dipole moment of a drug-like molecule.\n",
        "    (https://en.wikipedia.org/wiki/Electric_dipole_moment)\n",
        "    \"\"\"\n",
        "    def __call__(self, data):\n",
        "        target = 0 # we hardcoded choice of target\n",
        "        data.y = data.y[:, target]\n",
        "        return data\n",
        "\n",
        "\n",
        "class CompleteGraph:\n",
        "    \"\"\"\n",
        "    This transform adds all pairwise edges into the edge index per data sample,\n",
        "    then removes self loops, i.e. it builds a fully connected or complete graph\n",
        "    \"\"\"\n",
        "    def __call__(self, input):\n",
        "        data = input.clone()\n",
        "        device = data.edge_index.device\n",
        "\n",
        "        row = torch.arange(data.num_nodes, dtype=torch.long, device=device)\n",
        "        col = torch.arange(data.num_nodes, dtype=torch.long, device=device)\n",
        "\n",
        "        row = row.view(-1, 1).repeat(1, data.num_nodes).view(-1)\n",
        "        col = col.repeat(data.num_nodes)\n",
        "        edge_index = torch.stack([row, col], dim=0)\n",
        "\n",
        "        edge_attr = None\n",
        "        if data.edge_attr is not None:\n",
        "            idx = data.edge_index[0] * data.num_nodes + data.edge_index[1]\n",
        "            size = list(data.edge_attr.size())\n",
        "            size[0] = data.num_nodes * data.num_nodes\n",
        "            edge_attr = data.edge_attr.new_zeros(size)\n",
        "            edge_attr[idx] = data.edge_attr\n",
        "\n",
        "        edge_index, edge_attr = remove_self_loops(edge_index, edge_attr)\n",
        "        data.edge_attr = edge_attr\n",
        "        data.edge_index = edge_index\n",
        "\n",
        "        return data\n",
        "\n",
        "print(\"Helper functions loaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "EiuxXrwgmBE-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Helper functions loaded.\n"
          ]
        }
      ],
      "source": [
        "# @title [RUN] Helper functions for plots and visualisations\n",
        "\n",
        "\n",
        "def draw_one_graph(ax, edges, label=None, node_emb=None, layout=None, special_color=False):\n",
        "    \"\"\"draw a graph with networkx based on adjacency matrix (edges)\n",
        "    graph labels could be displayed as a title for each graph\n",
        "    node_emb could be displayed in colors\n",
        "    \"\"\"\n",
        "    graph = nx.Graph()\n",
        "    edges = zip(edges[0], edges[1])\n",
        "    graph.add_edges_from(edges)\n",
        "    node_pos = layout(graph)\n",
        "    #add colors according to node embeding\n",
        "    if (node_emb is not None) or special_color:\n",
        "        color_map = []\n",
        "        node_list = [node[0] for node in graph.nodes(data = True)]\n",
        "        for i,node in enumerate(node_list):\n",
        "            #just ignore this branch\n",
        "            if special_color:\n",
        "                if len(node_list) == 3:\n",
        "                    crt_color = (1,0,0)\n",
        "                elif len(node_list) == 5:\n",
        "                    crt_color = (0,1,0)\n",
        "                elif len(node_list) == 4:\n",
        "                    crt_color = (1,1,0)\n",
        "                else:\n",
        "                  special_list = [(1,0,0)] * 3 + [(0,1,0)] * 5 + [(1,1,0)] * 4\n",
        "                  crt_color = special_list[i]\n",
        "            else:\n",
        "                crt_node_emb = node_emb[node]\n",
        "                #map float number (node embeding) to a color\n",
        "                crt_color = cm.gist_rainbow(crt_node_emb, bytes=True)\n",
        "                crt_color = (crt_color[0]/255.0, crt_color[1]/255.0, crt_color[2]/255.0, crt_color[3]/255.0)\n",
        "            color_map.append(crt_color)\n",
        "\n",
        "        nx.draw_networkx_nodes(graph,node_pos, node_color=color_map,\n",
        "                        nodelist = node_list, ax=ax)\n",
        "        nx.draw_networkx_edges(graph, node_pos, ax=ax)\n",
        "        nx.draw_networkx_labels(graph,node_pos, ax=ax)\n",
        "    else:\n",
        "        nx.draw_networkx(graph, node_pos, ax=ax)\n",
        "\n",
        "\n",
        "def gallery(graphs, labels=None, node_emb=None, special_color=False, max_graphs=4, max_fig_size=(40, 10), layout=nx.layout.kamada_kawai_layout):\n",
        "    ''' Draw multiple graphs as a gallery\n",
        "    Args:\n",
        "      graphs: torch_geometrics.dataset object/ List of Graph objects\n",
        "      labels: num_graphs\n",
        "      node_emb: num_graphs* [num_nodes x num_ch]\n",
        "      max_graphs: maximum graphs display\n",
        "    '''\n",
        "    num_graphs = min(len(graphs), max_graphs)\n",
        "    ff, axes = plt.subplots(1, num_graphs,\n",
        "                            figsize=max_fig_size,\n",
        "                            subplot_kw={'xticks': [], 'yticks': []})\n",
        "    if num_graphs == 1:\n",
        "        axes = [axes]\n",
        "    if node_emb is None:\n",
        "        node_emb = num_graphs*[None]\n",
        "    if labels is None:\n",
        "        labels = num_graphs * [\" \"]\n",
        "\n",
        "\n",
        "    for i in range(num_graphs):\n",
        "        draw_one_graph(axes[i], graphs[i].edge_index.numpy(), labels[i], node_emb[i], layout, special_color)\n",
        "        if labels[i] != \" \":\n",
        "            axes[i].set_title(f\"Target: {labels[i]}\", fontsize=28)\n",
        "        axes[i].set_axis_off()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def hash_node_embedings(node_emb):\n",
        "  \"\"\" Hash the tensor representing nodes' features\n",
        "  to a number in [0,1] used to represent a color\n",
        "\n",
        "  Args:\n",
        "    node_emb: list of num_graphs arrays, each of dim (num_nodes x num_feats)\n",
        "  Returns:\n",
        "    list of num_graphs arrays in [0,1], each of dim (num_nodes)\n",
        "  \"\"\"\n",
        "  chunk_size_graph = [x.shape[0] for x in node_emb]\n",
        "  start_idx_graph = [0] + list(itertools.accumulate(chunk_size_graph))[:-1]\n",
        "\n",
        "  node_emb_flatten = np.concatenate(node_emb).mean(-1)\n",
        "\n",
        "  min_emb = node_emb_flatten.min()\n",
        "  max_emb = node_emb_flatten.max()\n",
        "  node_emb_flatten = (node_emb_flatten-min_emb)/(max_emb-min_emb)\n",
        "\n",
        "  #split in graphs again according to (start_idx_graph, chunk_size_graph)\n",
        "  node_emb_hashed = [node_emb_flatten[i:i+l] for (i,l) in zip(start_idx_graph, chunk_size_graph)]\n",
        "  return node_emb_hashed\n",
        "\n",
        "\n",
        "def update_stats(training_stats, epoch_stats):\n",
        "    \"\"\" Store metrics along the training\n",
        "    Args:\n",
        "      epoch_stats: dict containg metrics about one epoch\n",
        "      training_stats: dict containing lists of metrics along training\n",
        "    Returns:\n",
        "      updated training_stats\n",
        "    \"\"\"\n",
        "    if training_stats is None:\n",
        "        training_stats = {}\n",
        "        for key in epoch_stats.keys():\n",
        "            training_stats[key] = []\n",
        "    for key,val in epoch_stats.items():\n",
        "        training_stats[key].append(val)\n",
        "    return training_stats\n",
        "\n",
        "\n",
        "def plot_stats(training_stats, figsize=(5, 5), name=\"\"):\n",
        "    \"\"\" Create one plot for each metric stored in training_stats\n",
        "    \"\"\"\n",
        "    stats_names = [key[6:] for key in training_stats.keys() if key.startswith('train_')]\n",
        "    f, ax = plt.subplots(len(stats_names), 1, figsize=figsize)\n",
        "    if len(stats_names)==1:\n",
        "        ax = np.array([ax])\n",
        "    for key, axx in zip(stats_names, ax.reshape(-1,)):\n",
        "        axx.plot(\n",
        "            training_stats['epoch'],\n",
        "            training_stats[f'train_{key}'],\n",
        "            label=f\"Training {key}\")\n",
        "        axx.plot(\n",
        "            training_stats['epoch'],\n",
        "            training_stats[f'val_{key}'],\n",
        "            label=f\"Validation {key}\")\n",
        "        axx.set_xlabel(\"Training epoch\")\n",
        "        axx.set_ylabel(key)\n",
        "        axx.legend()\n",
        "    plt.title(name)\n",
        "\n",
        "\n",
        "def get_color_coded_str(i, color):\n",
        "    return \"\\033[3{}m{}\\033[0m\".format(int(color), int(i))\n",
        "\n",
        "\n",
        "def print_color_numpy(map, list_graphs):\n",
        "    \"\"\" print matrix map in color according to list_graphs\n",
        "    \"\"\"\n",
        "    list_blocks = []\n",
        "    for i,graph in enumerate(list_graphs):\n",
        "        block_i = (i+1)*np.ones((graph.num_nodes,graph.num_nodes))\n",
        "        list_blocks += [block_i]\n",
        "    block_color = block_diag(*list_blocks)\n",
        "\n",
        "    map_modified = np.vectorize(get_color_coded_str)(map, block_color)\n",
        "    print(\"\\n\".join([\" \".join([\"{}\"]*map.shape[0])]*map.shape[1]).format(*[x for y in map_modified.tolist() for x in y]))\n",
        "\n",
        "\n",
        "#############################################\n",
        "# Visualization helpers for molecular graphs\n",
        "#############################################\n",
        "\n",
        "allowable_atoms = [\n",
        "    \"H\",\n",
        "    \"C\",\n",
        "    \"N\",\n",
        "    \"O\",\n",
        "    \"F\",\n",
        "    \"C\",\n",
        "    \"Cl\",\n",
        "    \"Br\",\n",
        "    \"I\",\n",
        "    \"H\",\n",
        "    \"Unknown\",\n",
        "]\n",
        "\n",
        "def to_atom(t):\n",
        "    try:\n",
        "        return allowable_atoms[int(t.argmax())]\n",
        "    except:\n",
        "        return \"C\"\n",
        "\n",
        "\n",
        "def to_bond_index(t):\n",
        "    t_s = t.squeeze()\n",
        "    return [1, 2, 3, 4][\n",
        "        int(\n",
        "            torch.dot(\n",
        "                t_s,\n",
        "                torch.tensor(\n",
        "                    range(t_s.size()[0]), dtype=torch.float, device=t.device\n",
        "                ),\n",
        "            ).item()\n",
        "        )\n",
        "    ]\n",
        "\n",
        "def to_rdkit(data, device=None):\n",
        "    has_pos = False\n",
        "    node_list = []\n",
        "    for i in range(data.x.size()[0]):\n",
        "        node_list.append(to_atom(data.x[i][:5]))\n",
        "\n",
        "    # create empty editable mol object\n",
        "    mol = Chem.RWMol()\n",
        "    # add atoms to mol and keep track of index\n",
        "    node_to_idx = {}\n",
        "    invalid_idx = set([])\n",
        "    for i in range(len(node_list)):\n",
        "        if node_list[i] == \"Stop\" or node_list[i] == \"H\":\n",
        "            invalid_idx.add(i)\n",
        "            continue\n",
        "        a = Chem.Atom(node_list[i])\n",
        "        molIdx = mol.AddAtom(a)\n",
        "        node_to_idx[i] = molIdx\n",
        "\n",
        "    added_bonds = set([])\n",
        "    for i in range(0, data.edge_index.size()[1]):\n",
        "        ix = data.edge_index[0][i].item()\n",
        "        iy = data.edge_index[1][i].item()\n",
        "        bond = to_bond_index(data.edge_attr[i])  # <font color='red'>TODO</font> fix this\n",
        "        # bond = 1\n",
        "        # add bonds between adjacent atoms\n",
        "\n",
        "        if data.edge_attr[i].sum() == 0:\n",
        "          continue\n",
        "\n",
        "        if (\n",
        "            (str((ix, iy)) in added_bonds)\n",
        "            or (str((iy, ix)) in added_bonds)\n",
        "            or (iy in invalid_idx or ix in invalid_idx)\n",
        "        ):\n",
        "            continue\n",
        "        # add relevant bond type (there are many more of these)\n",
        "\n",
        "        if bond == 0:\n",
        "            continue\n",
        "        elif bond == 1:\n",
        "            bond_type = Chem.rdchem.BondType.SINGLE\n",
        "            mol.AddBond(node_to_idx[ix], node_to_idx[iy], bond_type)\n",
        "        elif bond == 2:\n",
        "            bond_type = Chem.rdchem.BondType.DOUBLE\n",
        "            mol.AddBond(node_to_idx[ix], node_to_idx[iy], bond_type)\n",
        "        elif bond == 3:\n",
        "            bond_type = Chem.rdchem.BondType.TRIPLE\n",
        "            mol.AddBond(node_to_idx[ix], node_to_idx[iy], bond_type)\n",
        "        elif bond == 4:\n",
        "            bond_type = Chem.rdchem.BondType.SINGLE\n",
        "            mol.AddBond(node_to_idx[ix], node_to_idx[iy], bond_type)\n",
        "\n",
        "        added_bonds.add(str((ix, iy)))\n",
        "\n",
        "    if has_pos:\n",
        "        conf = Chem.Conformer(mol.GetNumAtoms())\n",
        "        for i in range(data.pos.size(0)):\n",
        "            if i in invalid_idx:\n",
        "                continue\n",
        "            p = Point3D(\n",
        "                data.pos[i][0].item(),\n",
        "                data.pos[i][1].item(),\n",
        "                data.pos[i][2].item(),\n",
        "            )\n",
        "            conf.SetAtomPosition(node_to_idx[i], p)\n",
        "        conf.SetId(0)\n",
        "        mol.AddConformer(conf)\n",
        "\n",
        "    # Convert RWMol to Mol object\n",
        "    mol = mol.GetMol()\n",
        "    mol_frags = rdmolops.GetMolFrags(mol, asMols=True, sanitizeFrags=False)\n",
        "    largest_mol = max(mol_frags, default=mol, key=lambda m: m.GetNumAtoms())\n",
        "    return largest_mol\n",
        "\n",
        "\n",
        "def MolTo3DView(mol, size=(300, 300), style=\"stick\", surface=False, opacity=0.5):\n",
        "    \"\"\"Draw molecule in 3D\n",
        "\n",
        "    Args:\n",
        "    ----\n",
        "        mol: rdMol, molecule to show\n",
        "        size: tuple(int, int), canvas size\n",
        "        style: str, type of drawing molecule\n",
        "               style can be 'line', 'stick', 'sphere', 'carton'\n",
        "        surface, bool, display SAS\n",
        "        opacity, float, opacity of surface, range 0.0-1.0\n",
        "    Return:\n",
        "    ----\n",
        "        viewer: py3Dmol.view, a class for constructing embedded 3Dmol.js views in ipython notebooks.\n",
        "    \"\"\"\n",
        "    assert style in ('line', 'stick', 'sphere', 'carton')\n",
        "\n",
        "    mol = Chem.AddHs(mol)\n",
        "    AllChem.EmbedMolecule(mol)\n",
        "    AllChem.MMFFOptimizeMolecule(mol, maxIters=200)\n",
        "    mblock = Chem.MolToMolBlock(mol)\n",
        "    viewer = py3Dmol.view(width=size[0], height=size[1])\n",
        "    viewer.addModel(mblock, 'mol')\n",
        "    viewer.setStyle({style:{}})\n",
        "    if surface:\n",
        "        viewer.addSurface(py3Dmol.SAS, {'opacity': opacity})\n",
        "    viewer.zoomTo()\n",
        "    return viewer\n",
        "\n",
        "def smi2conf(smiles):\n",
        "    '''Convert SMILES to rdkit.Mol with 3D coordinates'''\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol is not None:\n",
        "        mol = Chem.AddHs(mol)\n",
        "        AllChem.EmbedMolecule(mol)\n",
        "        AllChem.MMFFOptimizeMolecule(mol, maxIters=200)\n",
        "        return mol\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "print(\"Helper functions loaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "r07NtHDZaoYr"
      },
      "outputs": [],
      "source": [
        "#@title [RUN] Helper functions for unit testing\n",
        "\n",
        "################################\n",
        "# Dummy data helpers for Part 1\n",
        "################################\n",
        "\n",
        "def get_dummy_data_transductive():\n",
        "    input_dim = 64\n",
        "    A = torch.tensor([[0, 1, 1, 0],\n",
        "        [1, 0, 0, 0],\n",
        "        [1, 1, 0, 1],\n",
        "        [1, 1, 1, 0]])\n",
        "    x = torch.rand(A.shape[0], input_dim)\n",
        "    y = torch.tensor([[0.1680148244],\n",
        "        [0.3310719728],\n",
        "        [0.2041909844],\n",
        "        [0.2041909844]])\n",
        "    return A, x, y\n",
        "\n",
        "def get_dummy_data_inductive_layer():\n",
        "    input_dim = 64\n",
        "    A = torch.tensor([[0, 1, 1, 0],\n",
        "        [1, 0, 0, 0],\n",
        "        [1, 1, 0, 1],\n",
        "        [1, 1, 1, 0]])\n",
        "    x = torch.rand(A.shape[0], input_dim)\n",
        "    y = torch.tensor([[0.1086086035],\n",
        "        [0.1543375552],\n",
        "        [0.1992474943],\n",
        "        [0.1992474943]])\n",
        "    return A, x, y\n",
        "\n",
        "def get_dummy_data_inductive_model():\n",
        "    input_dim = 64\n",
        "    A = torch.tensor([[0, 1, 1, 0],\n",
        "        [1, 0, 0, 0],\n",
        "        [1, 1, 0, 1],\n",
        "        [1, 1, 1, 0]])\n",
        "    x = torch.rand(A.shape[0], input_dim)\n",
        "    y = torch.tensor([[-0.0814725384]])\n",
        "    return A, x, y\n",
        "\n",
        "################################\n",
        "# Dummy data helpers for Part 2\n",
        "################################\n",
        "\n",
        "def get_dummy_data():\n",
        "    yield Batch(\n",
        "        x=torch.Tensor([[1], [1]]),\n",
        "        pos=torch.Tensor([[0, 0, 0], [0, 0, 1]]),\n",
        "        edge_index=torch.LongTensor([[0, 1], [1, 0]]),\n",
        "        edge_attr=torch.Tensor([[1], [1]]),\n",
        "    )\n",
        "    yield Batch(\n",
        "        x=torch.Tensor([[1], [1]]),\n",
        "        pos=torch.Tensor([[0, 0, 0], [0, 0, 2]]),\n",
        "        edge_index=torch.LongTensor([[0, 1], [1, 0]]),\n",
        "        edge_attr=torch.Tensor([[1], [1]]),\n",
        "    )\n",
        "    yield Batch(\n",
        "        x=torch.Tensor([[1], [1]]),\n",
        "        pos=torch.Tensor([[0, 0, 0], [1, 2, 3]]),\n",
        "        edge_index=torch.LongTensor([[0, 1], [1, 0]]),\n",
        "        edge_attr=torch.Tensor([[1], [1]]),\n",
        "    )\n",
        "\n",
        "\n",
        "# Invariant Dummies\n",
        "def dummy_not_invariant(x, pos, edge_index, edge_attr):\n",
        "    return pos\n",
        "\n",
        "def dummy_invariant(x, pos, edge_index, edge_attr):\n",
        "    return x\n",
        "\n",
        "def dummy_only_trans_invariant(x, pos, edge_index, edge_attr):\n",
        "    return pos - torch.unsqueeze(pos[0], dim=0)\n",
        "\n",
        "def dummy_only_rot_invariant(x, pos, edge_index, edge_attr):\n",
        "    return torch.sum(pos * torch.unsqueeze(pos[0], dim=0), dim=-1)\n",
        "\n",
        "\n",
        "# Equivariant Dummies\n",
        "def dummy_equivariant(x, pos, edge_index, edge_attr):\n",
        "    return x, pos\n",
        "\n",
        "def dummy_not_equivariant(x, pos, edge_index, edge_attr):\n",
        "    return pos, 2 * pos + 2\n",
        "\n",
        "def dummy_h_not_invariant(x, pos, edge_index, edge_attr):\n",
        "    return pos, pos\n",
        "\n",
        "def dummy_x_not_equivariant(x, pos, edge_index, edge_attr):\n",
        "    return x, 2 * pos + 2\n",
        "\n",
        "def dummy_h_only_trans_invariant(x, pos, edge_index, edge_attr):\n",
        "    return dummy_only_trans_invariant(x, pos, edge_index, edge_attr), pos\n",
        "\n",
        "def dummy_h_only_rot_invariant(x, pos, edge_index, edge_attr):\n",
        "    return dummy_only_rot_invariant(x, pos, edge_index, edge_attr), pos\n",
        "\n",
        "def dummy_x_only_trans_equivariant(x, pos, edge_index, edge_attr):\n",
        "    return x, pos + 2\n",
        "\n",
        "def dummy_x_only_rot_equivariant(x, pos, edge_index, edge_attr):\n",
        "    return x, 2 * pos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSpYtULzawir"
      },
      "outputs": [],
      "source": [
        "# For storing experimental results over the course of the practical\n",
        "RESULTS = {}\n",
        "DF_RESULTS = pd.DataFrame(columns=[\"Test MAE\", \"Val MAE\", \"Epoch\", \"Model\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCMVQGcyayLT"
      },
      "source": [
        "Great! We are ready to dive into the Practical!\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvssQ0SOeJWR"
      },
      "source": [
        "# <font color=orange> 🐤 **Part 1: Learning the basics of Graph Neural Networks** </font>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClxVKxwvB41e"
      },
      "source": [
        "# 🕸 Preliminaries on graphs and notation\n",
        "\n",
        "As described in the lectures, a graph is a mathematical structure which defines a set of entities which are related in some way. Graphs contain **nodes** or **vertices** representing said entities with related nodes being connected by an **edge** or **link** that records the relation.\n",
        "\n",
        "Mathematically we can define simple graph as an ordered tuple ${G} = (V, E)$ where $V$ is a set of nodes (or vertices) and $E \\subseteq (V \\times V$) is a 2-tuple set of the edges in the graph. Hence if $u$ and $v$ are nodes in ${G}$, their relation is recorded with edge as $(u,v) \\in E$ if the edge is directed from $u$ to $v$.\n",
        "\n",
        "- The **neighbours of a node** $u$ is the set of nodes which share an edge with $u$, denoted ${N}(u) = \\{v | (u, v) \\in E\\}$.\n",
        "\n",
        "- Edges can be directed or undirected. **Directed** edges are uni-directional relations from a source node $u$ and target node $v$ recorded as $(u,v) \\in E$ and importantly $(u,v) \\neq (v,u)$. **Undirected edges** are bi-directional and hence $(u,v) == (v,u)$.\n",
        "\n",
        "- Graphs can be represented nicely by matrices. For a graph with $n$ nodes, $A \\in \\mathbb{R}^{n \\times n}$ is a symmetric **adjacency matrix** where $a_{i,j}$ is the weight of the edge between nodes $v_i$ and $v_j$. If $(v_i, v_j) \\notin E$ then $a_{i,j} = 0$.\n",
        "\n",
        "- A diagonal **degree matrix** $D \\in \\mathbb{R}^{n \\times n}$ is defined as the matrix where each entry on the diagonal is the row-sum of the adjacency matrix. Note that this gives us what we need to define the Laplacian matrix of the graph $L = D-A$.\n",
        "\n",
        "- For graphs with node features, each node $v_i \\in V$ has an associated $d$-dimensional feature vector $\\mathbf{x_i} \\in \\mathbb{R}^{d}$. Then the **feature matrix** $\\mathbf{X} \\in \\mathbb{R}^{n \\times d}$ can be used to represent the feature vectors for every node in the graph. Can you think of how an edge feature matrix may be defined? 🤔"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Arp-90joB6uu"
      },
      "source": [
        "# 🦾 Machine learning on graph structured data with GNNs\n",
        "\n",
        "Machine learning tasks on graph structured data can be categorised based on the nuanced differences of the dataset and the task being studied. Most generally, we are interested in the following basic tasks:\n",
        "\n",
        "- **Node prediction:** a data observation is a node within a graph, and we are interested in doing node classification/regression. Eg. the Cora citation network dataset, where we are interested in categorising papers that are nodes of a larger citation network.\n",
        "- **Edge prediction:** we are interested in predicting edges between samples in the dataset, for instance to predict links between potential connections in a social network.\n",
        "- **Graph level prediction:** a data observation is an entire graph, i.e. our dataset consists of graphs and we are interested in graph classification/regression. Eg. the QM9 molecular properties dataset, where we are interested in predicting quantum mechanical properties of each molecule/graph in the dataset.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1ZGdGCzR6MmQnQZuH__I5JltannhHfjem\"  width=\"800\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erI_trUhTvSB"
      },
      "source": [
        "# 🛍 A first look at Cora\n",
        "\n",
        "Cora is a small citation network dataset which was used extensively in early GNN papers (it is now discouraged to publish papers working with Cora as it is very easy to overfit on). There are many variations of the Cora dataset originally presented in [\"Automating the Construction of Internet Portals with Machine Learning\"](https://link.springer.com/article/10.1023/A:1009953814988) by McCallum et al. .\n",
        "\n",
        "We will use the **Cora dataset** variant as presented in [“FastGCN: Fast Learning with Graph Convolutional Networks via Importance Sampling”](https://arxiv.org/abs/1801.10247). It describes a citation network of 2708 papers and our task is classify each paper into one of **7 different categories**. Some quick facts of this Cora variant:\n",
        "\n",
        "*   There are 2708 papers (i.e. observations in the dataset)\n",
        "  * 1208 training\n",
        "  * 500 validation\n",
        "  * 1000 test\n",
        "*   Each paper is represented by a 1433 dimensional bag-of-words vector\n",
        "*   Each paper belongs to one of 7 classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0wx4woEtVcI"
      },
      "source": [
        "Ignoring GNNs for a moment, our first attempt would be to use a simple model such as a **feed forward MLP**. In fact, it's always good practice to first explore the task with simpler models for debugging and benchmarking.\n",
        "\n",
        "We will work with the Cora dataset through a `CoraDataset` object which will download the dataset and provides the following methods:\n",
        "\n",
        "* a function that returns torch tensors for `train_x`, `train_y`, `validation_x`, `validation_y`, `test_x`, `test_y`, corresponding to input x and target y for each of the train/val/test splits.\n",
        "> `train_val_test_split(self)`\n",
        "\n",
        "* a function that returns the feature matrix $\\mathbf{X} \\in \\mathbb{R}^{|V| \\times d}$ where $V$ is the set of nodes and $d$ the feature vector dimensionality.\n",
        "> `get_fullx(self)`\n",
        "\n",
        "* a function that returns a dense version of the adjacency matrix $\\mathbf{A}$\n",
        "> `get_adjacency_matrix(self)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "OxvbRR52iKEf"
      },
      "outputs": [],
      "source": [
        "# @title [RUN] `CoraDataset` implementation\n",
        "# Let's get the Planetoid Cora dataset from\n",
        "# “FastGCN: Fast Learning with Graph Convolutional\n",
        "# Networks via Importance Sampling” (https://arxiv.org/abs/1801.10247)\n",
        "\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.utils import to_dense_adj\n",
        "\n",
        "class CoraDataset(object):\n",
        "    def __init__(self):\n",
        "        super(CoraDataset, self).__init__()\n",
        "        cora_pyg = Planetoid(root='/tmp/Cora', name='Cora', split=\"full\")\n",
        "        self.cora_data = cora_pyg[0]\n",
        "        self.train_mask = self.cora_data.train_mask\n",
        "        self.valid_mask = self.cora_data.val_mask\n",
        "        self.test_mask = self.cora_data.test_mask\n",
        "\n",
        "    def train_val_test_split(self):\n",
        "        train_x = self.cora_data.x[self.cora_data.train_mask]\n",
        "        train_y = self.cora_data.y[self.cora_data.train_mask]\n",
        "\n",
        "        valid_x = self.cora_data.x[self.cora_data.val_mask]\n",
        "        valid_y = self.cora_data.y[self.cora_data.val_mask]\n",
        "\n",
        "        test_x = self.cora_data.x[self.cora_data.test_mask]\n",
        "        test_y = self.cora_data.y[self.cora_data.test_mask]\n",
        "        return train_x, train_y, valid_x, valid_y, test_x, test_y\n",
        "\n",
        "    def get_fullx(self):\n",
        "        return self.cora_data.x\n",
        "\n",
        "    def get_adjacency_matrix(self):\n",
        "        # We will ignore this for the first part\n",
        "        adj = to_dense_adj(self.cora_data.edge_index)[0]\n",
        "        return adj"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_7BEhQJt6AS"
      },
      "outputs": [],
      "source": [
        "# Lets download our cora dataset and get the splits\n",
        "cora_data = CoraDataset()\n",
        "train_x, train_y, valid_x, valid_y, test_x, test_y = cora_data.train_val_test_split()\n",
        "\n",
        "# Always check and confirm our data shapes match our expectations\n",
        "print(f\"Train shape x: {train_x.shape}, y: {train_y.shape}\")\n",
        "print(f\"Val shape x: {valid_x.shape}, y: {valid_y.shape}\")\n",
        "print(f\"Test shape x: {test_x.shape}, y: {test_y.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0gPZZdftpzb"
      },
      "source": [
        "🥼 We have implemented a simple MLP model for the Cora dataset to get you started."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "h1fue_eNL4Z_"
      },
      "outputs": [],
      "source": [
        "# @title [RUN] Hyperparameters for simple MLP\n",
        "\n",
        "NUM_EPOCHS =  100 #@param {type:\"integer\"}\n",
        "LR         = 0.001 #@param {type:\"number\"}\n",
        "\n",
        "#you can add more here if you need"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFigi0DQT3zG"
      },
      "outputs": [],
      "source": [
        "# Lets implement a simple feed forward MLP\n",
        "\n",
        "class SimpleMLP(Module):\n",
        "    \"\"\"A simple feed forward neural network with no hidden layers\n",
        "\n",
        "    Args:\n",
        "        input_dim (int): Dimensionality of the input feature vectors\n",
        "        output_dim (int): Dimensionality of the output softmax distribution\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(SimpleMLP, self).__init__()\n",
        "        self.layer_1 = Linear(input_dim, input_dim)\n",
        "        self.layer_2 = Linear(input_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Forward pass through SimpleMLP given input tensor x\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): input tensor\n",
        "        \"\"\"\n",
        "        x = self.layer_1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.layer_2(x)\n",
        "        y_hat = x\n",
        "        return y_hat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "IXoEefwAEbeK"
      },
      "outputs": [],
      "source": [
        "#@title [RUN] Helper functions for managing experiments, training, and evaluating models.\n",
        "\n",
        "def train_mlp_cora(x, y, model, optimiser):\n",
        "    model.train()\n",
        "    optimiser.zero_grad()\n",
        "    y_hat = model(x)\n",
        "    loss = F.cross_entropy(y_hat, y)\n",
        "    loss.backward()\n",
        "    optimiser.step()\n",
        "    return loss.data\n",
        "\n",
        "def evaluate_mlp_cora(x, y, model):\n",
        "    model.eval()\n",
        "    y_hat = model(x)\n",
        "    y_hat = y_hat.data.max(1)[1]\n",
        "    num_correct = y_hat.eq(y.data).sum()\n",
        "    num_total = len(y)\n",
        "    accuracy = 100.0 * (num_correct/num_total)\n",
        "    return accuracy\n",
        "\n",
        "def train_eval_loop(model, train_x, train_y, valid_x, valid_y, test_x, test_y):\n",
        "    optimiser = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "    training_stats = None\n",
        "    # Training loop\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        train_loss = train_mlp_cora(train_x, train_y, model, optimiser)\n",
        "        train_acc = evaluate_mlp_cora(train_x, train_y, model)\n",
        "        valid_acc = evaluate_mlp_cora(valid_x, valid_y, model)\n",
        "        if epoch % 10 == 0:\n",
        "            print(f\"Epoch {epoch} with train loss: {train_loss:.3f} train accuracy: {train_acc:.3f}\",\n",
        "                    f\"validation accuracy: {valid_acc:.3f}\")\n",
        "        # store the loss and the accuracy for the final plot\n",
        "        epoch_stats = {'train_acc': train_acc, 'val_acc': valid_acc, 'epoch':epoch}\n",
        "        training_stats = update_stats(training_stats, epoch_stats)\n",
        "    # Lets look at our final test performance\n",
        "    test_acc = evaluate_mlp_cora(test_x, test_y, model)\n",
        "    print(f\"Our final test accuracy for the SimpleMLP is: {test_acc:.3f}\")\n",
        "    return training_stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_olnWUkaLRtx"
      },
      "outputs": [],
      "source": [
        "# Instantiate our model\n",
        "model = SimpleMLP(input_dim=train_x.shape[-1], output_dim=7)\n",
        "\n",
        "# Run training loop\n",
        "train_stats_mlp_cora = train_eval_loop(model, train_x, train_y, valid_x, valid_y, test_x, test_y)\n",
        "plot_stats(train_stats_mlp_cora, name=\"MLP_Cora\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngIihap9B_mx"
      },
      "source": [
        "🔎 We should be getting final test accuracies of around 72% on Cora for an extremely simple MLP model. Not too bad!\n",
        "\n",
        "<font color='blue'> But are we using all the information/data available to us and can we do better with it? </font>\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdXltx7guY0J"
      },
      "source": [
        "# 👶 Our first GCN layer\n",
        "\n",
        "On our application of the MLP on Cora we have completely ignored the fact that Cora is a citation **network**!\n",
        "\n",
        "In Cora, citations form undirected edges between each of the nodes (papers) in this network. We think this additional information can be useful for categorising our papers, but how can we incorporate this structure in a neural network layer?\n",
        "\n",
        "In the course lectures, we were introduced to a general blue-print for creating GNN layers. We can build GNN layers $\\mathbf{F(X,A)}$ on graphs by applying a local permutation invariant operation $\\phi(\\mathbf{x_i}, \\mathbf{X}_{{N}_i})$. The various implementations of $\\phi$ are the subject of much research.\n",
        "\n",
        "For this practical, we will start by considering GNN layers with constant values for the convolution coefficients. Thus, we are interested in developing a Convolutional GNN layer that uses set parameters for the constant/coefficient $c_{i,j}$, for every edge $(i,j) \\in E$\n",
        "\n",
        "![](https://drive.google.com/uc?id=1Wdgdq606XW1MelvcU1nW5CxWe1rHsWt1)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EDBXcFuvWqj"
      },
      "source": [
        "\n",
        "The generic equation for a convolutional GNN looks as follows:\n",
        "\n",
        "$$\n",
        "\\mathbf{h_i} = \\phi \\big(\\mathbf{x_i}, \\oplus_{j \\in {N}_i} c_{i,j} \\psi (\\mathbf{x_j}) \\big)\n",
        "$$\n",
        "\n",
        "Getting more specific, let us look at the **GCN** from Kipf and Welling's [\"Semi-Supervised Classification with Graph Convolutional Networks\"](https://arxiv.org/abs/1609.02907). This employs a symmetric normalisation for the convolution coefficients with a re-normalisation to tackle exploding parameters.\n",
        "\n",
        "$$\n",
        "\\mathbf{H} = \\sigma \\big( \\mathbf{\\tilde{D}}^{-\\frac{1}{2}} \\mathbf{\\tilde{A}} \\mathbf{\\tilde{D}}^{-\\frac{1}{2}} \\mathbf{X} \\mathbf{W} \\big)\n",
        "$$\n",
        "\n",
        "Where $\\mathbf{\\tilde{A}} = \\mathbf{A} + \\mathbf{I}$ and $\\mathbf{\\tilde{D}}$ is the degree matrix of $\\mathbf{\\tilde{A}}$.\n",
        "\n",
        "Reformulating the above equation from a node-centric point of view corresponds to:\n",
        "\n",
        "- $c_{i,j}$ is a normalising coefficient corresponding to $\\frac{1}{\\sqrt{(deg(i)+1) (deg(j)+1)}}$,\n",
        "- $\\oplus_{j \\in {N}_i}$ is $\\sum_{j \\in {N}_i}$, i.e. the sum over neighbours,\n",
        "- $\\phi(\\mathbf{x}_i, \\mathbf{m}_i) = \\sigma(c_{i,i}\\psi(\\mathbf{x}_i) + \\mathbf{m}_i)$ with $\\mathbf{m}_i = \\sum_{j \\in {N}_i} c_{i,j} \\psi(\\mathbf{x}_j)$.\n",
        "\n",
        "The output node feature representation is the result of a weighted sum of itself and its neighbours, followed by a learnt affine transformation and non-linearity. The weights used for the weighted sum correspond to the connectivity/inverse of the degree of each node.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOwxWgomU3kw"
      },
      "source": [
        "### 💻**Task 1.1**  <font color=\"purple\"> Implement your first GNN layer based on the GCNLayer equations provided. (2.0 Marks) </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nop2qosNHzES"
      },
      "source": [
        "**Note:** When dealing with large, sparse matrices, multiplying them using sparse format is much more efficient. We do not impose doing that in this exercise but if you want to try [torch.tensor.to_sparse()](https://pytorch.org/docs/stable/generated/torch.Tensor.to_sparse.html) convert a dense matrix into a sparse matrix, while to [torch.sparse.mm()](https://pytorch.org/docs/stable/generated/torch.sparse.mm.html) perform multiplication between a sparse matrix and a sparse/dense matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "-BLISzysQkdA"
      },
      "outputs": [],
      "source": [
        "# @title [RUN] Hyperparameters for GCN\n",
        "\n",
        "NUM_EPOCHS =  100 #@param {type:\"integer\"}\n",
        "LR         = 0.01 #@param {type:\"number\"}\n",
        "\n",
        "#you can add more here if you need"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAfm307zEzBc"
      },
      "outputs": [],
      "source": [
        "# Fill in the initialisation and forward method the GCNLayer below\n",
        "\n",
        "class GCNLayer(Module):\n",
        "    \"\"\"Graph Convolutional Network layer from Kipf & Welling.\n",
        "\n",
        "    Args:\n",
        "        input_dim (int): Dimensionality of the input feature vectors\n",
        "        output_dim (int): Dimensionality of the output softmax distribution\n",
        "        A (torch.Tensor): 2-D adjacency matrix\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, output_dim, A):\n",
        "        super(GCNLayer, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.A = A\n",
        "\n",
        "        # ============ YOUR CODE HERE ==============\n",
        "        # Sample answer\n",
        "        # Compute symmetric norm\n",
        "        # self.adj_norm = ...\n",
        "\n",
        "        # + Simple linear transformation and non-linear activation\n",
        "        # self.linear = ...\n",
        "        # ===========================================\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Implements the forward pass for the layer\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): input node feature matrix\n",
        "        \"\"\"\n",
        "        # ============ YOUR CODE HERE ==============\n",
        "        # Sample answer\n",
        "        # x = ...\n",
        "        # ===========================================\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sG83uHmwbc-v"
      },
      "outputs": [],
      "source": [
        "# @title ✅ [RUN] **Please run this unit test to validate your code. The output would be used to mark your practical.**\n",
        "def testing_gcn():\n",
        "  torch.random.manual_seed(0)\n",
        "  np.random.seed(0)\n",
        "  A,x,y = get_dummy_data_transductive()\n",
        "\n",
        "  input_dim = x.shape[-1]\n",
        "  output_dim = y.shape[-1]\n",
        "\n",
        "  torch.random.manual_seed(0)\n",
        "  model = GCNLayer(input_dim, output_dim, A)\n",
        "  out = model(x)\n",
        "\n",
        "  assert(out.shape == (A.shape[0], output_dim)), \"Oops! 🤭 Output shape is wrong\"\n",
        "\n",
        "  perm = np.random.permutation(x.shape[0])\n",
        "  perm_x = x[perm]\n",
        "  perm_out = out[perm]\n",
        "  A_perm = A[perm, :][:, perm]\n",
        "\n",
        "  torch.random.manual_seed(0)\n",
        "  model_perm = GCNLayer(input_dim, output_dim, A_perm)\n",
        "\n",
        "  out_model_perm = model_perm(perm_x)\n",
        "  assert (torch.allclose(perm_out, out_model_perm, atol=1e-6)), \"🤔 Something is wrong in the model! The output is not permutation equivariant anymore 🥺\"\n",
        "\n",
        "  assert (torch.allclose(out, y, atol=1e-6)), \"🤔 Something is wrong in the model! The output is wrong.\"\n",
        "  print(\"✅ All seems good!!!\")\n",
        "\n",
        "\n",
        "# run unit test function\n",
        "testing_gcn()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJTiyZYs3cnY"
      },
      "source": [
        "---\n",
        "\n",
        "# **⚖ Semi-supervised learning on graphs:** Transductive vs Inductive\n",
        "\n",
        "Notice that we use the entire adjacency and node feature matrix each time we call the GCNLayer as opposed to the specific subsets of the train/validation/test samples that we did earlier with the MLP. This is because nodes from the different splits share edges with those from the other splits and building our representation via the GCN requires these.\n",
        "\n",
        "Hence, the learning performed with our GCNLayer is an instance of **transductive semi-supervised learning** as the model gets to see all of the observations in the dataset (even if it only has access to the labels from the training split).\n",
        "\n",
        "This is different to the **inductive learning** performed on the MLP where the model only sees the train observations during training and only sees validation/test observations for prediction.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "5FzQsYwlUUuj"
      },
      "outputs": [],
      "source": [
        "# @title [RUN] Helper functions for managing experiments, training, and evaluating models\n",
        "\n",
        "def train_gnn_cora(X, y, mask, model, optimiser):\n",
        "    model.train()\n",
        "    optimiser.zero_grad()\n",
        "    y_hat = model(X)[mask]\n",
        "    loss = F.cross_entropy(y_hat, y)\n",
        "    loss.backward()\n",
        "    optimiser.step()\n",
        "    return loss.data\n",
        "\n",
        "\n",
        "def evaluate_gnn_cora(X, y, mask, model):\n",
        "    model.eval()\n",
        "    y_hat = model(X)[mask]\n",
        "    y_hat = y_hat.data.max(1)[1]\n",
        "    num_correct = y_hat.eq(y.data).sum()\n",
        "    num_total = len(y)\n",
        "    accuracy = 100.0 * (num_correct/num_total)\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "# Training loop\n",
        "def train_eval_loop_gnn_cora(model, train_x, train_y, train_mask,\n",
        "                        valid_x, valid_y, valid_mask,\n",
        "                        test_x, test_y, test_mask\n",
        "                    ):\n",
        "    optimiser = Adam(model.parameters(), lr=LR)\n",
        "    training_stats = None\n",
        "    # Training loop\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        train_loss = train_gnn_cora(train_x, train_y, train_mask, model, optimiser)\n",
        "        train_acc = evaluate_gnn_cora(train_x, train_y, train_mask, model)\n",
        "        valid_acc = evaluate_gnn_cora(valid_x, valid_y, valid_mask, model)\n",
        "        if epoch % 10 == 0:\n",
        "            print(f\"Epoch {epoch} with train loss: {train_loss:.3f} train accuracy: {train_acc:.3f} validation accuracy: {valid_acc:.3f}\")\n",
        "        # store the loss and the accuracy for the final plot\n",
        "        epoch_stats = {'train_acc': train_acc, 'val_acc': valid_acc, 'epoch':epoch}\n",
        "        training_stats = update_stats(training_stats, epoch_stats)\n",
        "    # Lets look at our final test performance\n",
        "    test_acc = evaluate_gnn_cora(test_x, test_y, test_mask, model)\n",
        "    print(f\"Our final test accuracy for the SimpleGNN is: {test_acc:.3f}\")\n",
        "    return training_stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJ_shXwaE4fl"
      },
      "outputs": [],
      "source": [
        "# Lets see the GCNLayer in action!\n",
        "\n",
        "class SimpleGNN(Module):\n",
        "    \"\"\"A Simple GNN model using the GCNLayer for node classification\n",
        "\n",
        "    Args:\n",
        "        input_dim (int): Dimensionality of the input feature vectors\n",
        "        output_dim (int): Dimensionality of the output softmax distribution\n",
        "        A (torch.Tensor): 2-D adjacency matrix\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, num_gcn_layers, A):\n",
        "        super(SimpleGNN, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.A = A\n",
        "\n",
        "        # Note: if a single layer is used hidden_dim should be the same as input_dim\n",
        "        if num_gcn_layers > 1:\n",
        "          self.gcn_layers = [GCNLayer(input_dim, hidden_dim, A)]\n",
        "          self.gcn_layers += [GCNLayer(hidden_dim, hidden_dim, A) for i in range(num_gcn_layers-2)]\n",
        "          self.gcn_layers += [GCNLayer(hidden_dim, output_dim, A)]\n",
        "        else:\n",
        "          self.gcn_layers = [GCNLayer(input_dim, output_dim, A)]\n",
        "\n",
        "        self.gcn_layers = ModuleList(self.gcn_layers)\n",
        "        self.num_gcn_layers = num_gcn_layers\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Forward pass through SimpleGNN on input x\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): input node features\n",
        "        \"\"\"\n",
        "        for j in range(self.num_gcn_layers-1):\n",
        "          x = self.gcn_layers[j](x)\n",
        "          x = F.relu(x)\n",
        "\n",
        "        x = self.gcn_layers[-1](x)\n",
        "\n",
        "        y_hat = x\n",
        "        return y_hat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rl6KVverQy7C"
      },
      "outputs": [],
      "source": [
        "# Instantiate our model and optimiser\n",
        "A = cora_data.get_adjacency_matrix()\n",
        "X = cora_data.get_fullx()\n",
        "model = SimpleGNN(input_dim=train_x.shape[-1], output_dim=7, A=A, hidden_dim=train_x.shape[-1], num_gcn_layers=1)\n",
        "train_mask = cora_data.train_mask\n",
        "valid_mask = cora_data.valid_mask\n",
        "test_mask = cora_data.test_mask\n",
        "\n",
        "# Run training loop\n",
        "train_stats_gnn_cora = train_eval_loop_gnn_cora(model, X, train_y, train_mask,\n",
        "                                          X, valid_y, valid_mask,\n",
        "                                          X, test_y, test_mask\n",
        "                                       )\n",
        "plot_stats(train_stats_gnn_cora, name=\"GNN_Cora\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QA7iMu59vWyo"
      },
      "source": [
        "> 🔎 Alright! We got quite the boost here, seeing final test performances of about 84% despite no change to the number of trainable parameters being used. Neat! 👌\n",
        "\n",
        "Note the use of the `train_mask`, `valid_mask`, and `test_mask` which we need to utilise as the model is able to see the entire dataset at all times. They are masking the outputs of the model to the observations corresponding to the dataset indices in each of the splits. For training this ensures that we compute the loss only over the training observations and ensure we don't have an information leak.\n",
        "\n",
        "### 💻 <font color=\"purple\">  Explore enlarging the receptive field visible to the computation of $\\mathbf{H}$. First, how can this be done? Does this help? Try seeing this in action by changing the value of `num_gcn_layers` below and observing the effect of increasing the receptive field of your GNN on performance. </font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0_-NokM9c5n"
      },
      "outputs": [],
      "source": [
        "# @title [RUN] Size of receptive field\n",
        "num_gcn_layers = 2 #@param {type:\"integer\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pf3l7oo6M3Nm"
      },
      "outputs": [],
      "source": [
        "# ============ YOUR MODIFICATION HERE =============\n",
        "# TASK: What do you need to change in this line to enlarge the receptive field?\n",
        "# model = ...\n",
        "\n",
        "\n",
        "# Run training loop\n",
        "train_stats_gnn_cora_rf = train_eval_loop_gnn_cora(model, X, train_y, train_mask,\n",
        "                                          X, valid_y, valid_mask,\n",
        "                                          X, test_y, test_mask\n",
        "                                       )\n",
        "plot_stats(train_stats_gnn_cora_rf, name=\"GNN_Cora_Receptive_Field\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74pk764NVvlQ"
      },
      "source": [
        "\n",
        "> ⏭ Great you've covered the basics of GNN layer development and studying node level prediction.\n",
        "\n",
        "> Now lets look at **graph level prediction**. Consider the differences: we are no longer looking at each observation being a node (typically represented by an associated feature vector) but now each observation is an entire graph! As we do so, we run into our first challenge: *how do we batch graphs that can come in different sizes?* 🤔\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vaukihsc7CGy"
      },
      "source": [
        "#  🧬 **Supervised learning on graphs: Graph-level prediction**\n",
        "\n",
        "Molecules are a great example of an object from nature that can easily be represented as a graph of atoms (nodes) connected by bonds (edges).\n",
        "A popular application of GNNs in chemistry is the task of **Molecular Property Prediction**. The goal is to train a GNN model from historical experimental data that can predict useful properties of drug-like molecules. The model's predictions can then be used to guide the drug design process.\n",
        "\n",
        "![](https://drive.google.com/uc?id=1Hs6fMSZ6a0WdjKqzbmBME0RYoSwxMaYQ)\n",
        "\n",
        "One famous example of GNNs being used in molecular property prediction is in the world of **antibiotic discovery**, an area with a potentially massive impact on humanity and infamously little innovation. A GNN trained to predict how much a molecule would inhibit a bacteria was able identify the previously overlooked compound [**Halicin**](https://www.wikiwand.com/en/Halicin) (below) during virtual screening. Not only did halicin show powerful results during *in vitro* (in cell) testing but it also had a completely novel mechanism of action that no bacteria has developed resistance to (yet).\n",
        "\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Halicin.svg/440px-Halicin.svg.png\" width=\"30%\">\n",
        "\n",
        "In the following, we will explore molecular property prediction on the QM9 (Quantum Mechanics dataset 9) dataset. The dataset consists of about **130,000 small molecules** with 19 regression targets. Since being used by [MoleculeNet](https://arxiv.org/abs/1703.00564), it has become a popular dataset to benchmark new architectures for molecular property prediction.\n",
        "\n",
        "Specifically, we will be predicting the [electric dipole moment](https://en.wikipedia.org/wiki/Electric_dipole_moment) of drug-like molecules. According to Wikipedia:\n",
        "> \"The electric dipole moment is a measure of the separation of positive and negative electrical charges within a system, that is, a measure of the system's overall polarity.\"\n",
        "\n",
        "We can visualize this concept via the water molecule H<sub>2</sub>0, which forms a dipole due to its slightly different distribution of negative (blue) and postive (red) charge.\n",
        "\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/1/15/Water-elpot-transparent-3D-balls.png/500px-Water-elpot-transparent-3D-balls.png\" width=\"25%\">\n",
        "\n",
        "You do not need to worry about the exact physical and chemical principles that underpin dipole moments. As you might imagine, writing the equations from first priciples to predict a property like this, espeically for complex molecules (e.g. proteins), is very difficult. All you need know is that these molecules can be represented as graphs with node and edge features as well as **spatial information** that we can use to train a GNN model using the ground truth labels.\n",
        "\n",
        "Now let us load the QM9 dataset and explore how molecular graphs are represented. We will be using the PyTorch Geometric library to do so. (The dataset may take about 5min to download.)\n",
        "\n",
        "**What is [PyTorch Geometric](https://pytorch-geometric.readthedocs.io/en/latest/)?** PyG is a library for graph representation learning research and development:\n",
        "> PyTorch Geometric (PyG) consists of various methods for deep learning on graphs and other irregular structures, also known as Geometric Deep Learning, from a variety of published papers. In addition, it provides easy-to-use mini-batch loaders for operating on many small and single giant graphs, multi GPU-support, distributed graph learning, a large number of common benchmark datasets, and helpful transforms, both for learning on arbitrary graphs as well as on 3D meshes or point clouds.\n",
        "\n",
        "We will introduce PyG in detail subsequently."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fuoCxO7zqY1I"
      },
      "outputs": [],
      "source": [
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "    path = './qm9'\n",
        "    target = 0\n",
        "\n",
        "    # Transforms which are applied during data loading:\n",
        "    # Select the target/label\n",
        "    transform = T.Compose([SetTarget()])\n",
        "\n",
        "    # Load the QM9 dataset with the transforms defined\n",
        "    dataset = QM9(path, transform=transform)\n",
        "\n",
        "    # Normalize targets per data sample to mean = 0 and std = 1.\n",
        "    mean = dataset.data.y.mean(dim=0, keepdim=True)\n",
        "    std = dataset.data.y.std(dim=0, keepdim=True)\n",
        "    dataset.data.y = (dataset.data.y - mean) / std\n",
        "    mean, std = mean[:, target].item(), std[:, target].item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W25xS1H0-1uR"
      },
      "source": [
        "## Data Preparation and Splitting\n",
        "\n",
        "The QM9 dataset has over **130,000** molecular graphs!\n",
        "\n",
        "Let us create a more tractable sub-set of **3,000** molecular graphs for the purposes of this practical and separate it into training, validation, and test sets. We shall use 1,000 graphs each for training, validation, and testing.\n",
        "\n",
        "Feel free to experiment with the full/larger sub-sets of the QM9 dataset, too."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ufdp5NsGqfty"
      },
      "outputs": [],
      "source": [
        "print(f\"Total number of samples: {len(dataset)}.\")\n",
        "\n",
        "# Split datasets (in case of using the full dataset)\n",
        "# test_dataset = dataset[:10000]\n",
        "# val_dataset = dataset[10000:20000]\n",
        "# train_dataset = dataset[20000:]\n",
        "\n",
        "# Split datasets (our 3K subset)\n",
        "train_pyg_dataset = dataset[:1000]\n",
        "val_pyg_dataset = dataset[1000:2000]\n",
        "test_pyg_dataset = dataset[2000:3000]\n",
        "print(f\"Created dataset splits with {len(train_pyg_dataset)} training, {len(val_pyg_dataset)} validation, {len(test_pyg_dataset)} test samples.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NbF7Dqt-56O"
      },
      "source": [
        "## Visualising Molecular Graphs\n",
        "\n",
        "To get a better understanding of how the QM9 molecular graphs look like, let's visualise a few samples from the training set along with their corresponding target (their dipole moment).\n",
        "\n",
        "In the following plot we visualise the associated graph structure, where edges represent physical connections (i.e. bonds).\n",
        "\n",
        "**❗️Note:** we have implemented some code for you to convert a QM9 graph into a Molecule object that can be used by RDKit, a python package for chemistry and visualing molecules. It is not important for you to understand RDKit beyond visualisation purposes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aT62vhimuOb_"
      },
      "outputs": [],
      "source": [
        "# @title [RUN] Visualise molecules from QM9\n",
        "\n",
        "NUM_VIZ = 10 #@param {type:\"integer\"}\n",
        "\n",
        "mols = [to_rdkit(train_pyg_dataset[i]) for i in range(NUM_VIZ)]\n",
        "values = [str(round(float(train_pyg_dataset[i].y), 3)) for i in range(NUM_VIZ)]\n",
        "\n",
        "Chem.Draw.MolsToGridImage(mols, legends=[f\"y = {value}\" for value in values], molsPerRow=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWLvgFErBlJa"
      },
      "source": [
        "The loaded dataset is an instance of `torch_geometric.dataset`. Within an instance of a `Data` object, individual `Torch.Tensor` attributes (or any other variable type) can be easily dot accessed within a neural network layer. The graphs from PyG come with a number of pre-computed features which we describe below (do not worry if you are unfamiliar with the chemistry terms here):\n",
        "\n",
        "**Atom features (`data.x`)** - $\\mathbb{R}^{|V| \\times 11}$\n",
        "- 1st-5th features: Atom type (one-hot: H, C, N, O, F)\n",
        "- 6th feature (also `data.z`): Atomic number (number of protons).\n",
        "- 7th feature: Aromatic (binary)\n",
        "- 8th-10th features: Electron orbital hybridization (one-hot: sp, sp2, sp3)\n",
        "- 11th feature: Number of hydrogens\n",
        "\n",
        "**Edge Index (`data.edge_index`)** - $\\mathbb{R}^{2×|E|}$\n",
        "- A tensor of dimensions 2 x `num_edges` that describe the edge connectivity of the graph\n",
        "\n",
        "**Edge features (`data.edge_attr`)** - $\\mathbb{R}^{|E|\\times 4}$\n",
        "- 1st-4th features: bond type (one-hot: single, double, triple, aromatic)\n",
        "\n",
        "**Atom positions (`data.pos`)** - $\\mathbb{R}^{|V|\\times 3}$\n",
        "- 3D coordinates of each atom . (We will talk about their importance later in the practical.)\n",
        "\n",
        "**Target (`data.y`)** - $\\mathbb{R}^{1}$\n",
        "- A scalar value corresponding to the molecules electric dipole moment\n",
        "\n",
        "\n",
        "For now, we will only use information regardin the features (`data.x`), structure (`data.edge_index`) and target(`data.y`), ignoring the edge attributes and the position of each atom.\n",
        "\n",
        "In order to understand the internals of building GNNs in PyG, we will not (yet) directly use these original `torch_geometric` objects. Instead we will create a PyTorch wrapper class called ` Graph`. This class will store only the information needed for this task and will help us understand how PyG works under the hood.\n",
        "\n",
        "**❗️Note:** Instead of storing an entire adjacency matrix to describe the graph structure (as in the previous section), we will store it in a  more efficient way as a list of edge indices of shape `[2, num_edges]`. Concretly, for each edge we store the indices of the source and destination node.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yTnHMRJUueVi"
      },
      "outputs": [],
      "source": [
        "class Graph(object):\n",
        "    def __init__(self, edge_index, x, y):\n",
        "        \"\"\"\n",
        "        Minimal implementation of a Graph structure data object\n",
        "        for a mini-batch of graphs. We will store a big (sparse)\n",
        "        graph representing the entire batch.\n",
        "\n",
        "        Args:\n",
        "            x: node features  [num_nodes x num_feats]\n",
        "            y: graph labels   [num_graphs]\n",
        "            edge_index: list of edges [2 x num_edges]\n",
        "        \"\"\"\n",
        "        self.edge_index = edge_index\n",
        "        self.x = x.to(torch.float32)\n",
        "        self.y = y\n",
        "        self.num_nodes = self.x.shape[0]\n",
        "\n",
        "    #ignore this for now, it will be useful for batching\n",
        "    def set_batch(self, batch):\n",
        "        \"\"\"\n",
        "        list of ints that maps each node to the graph it belongs to\n",
        "        e.g. for batch = [0,0,0,1,1,1,1]: the first 3 nodes belong to graph_0\n",
        "        while the last 4 belong to graph_1\n",
        "        \"\"\"\n",
        "        self.batch = batch\n",
        "\n",
        "    # this function returns a sparse tensor\n",
        "    def get_adjacency_matrix(self):\n",
        "        \"\"\"\n",
        "        from the list of edges create a\n",
        "        num_nodes x num_nodes sparse adjacency matrix\n",
        "        \"\"\"\n",
        "        return torch.sparse.LongTensor(\n",
        "            self.edge_index,\n",
        "            # we work with a binary adj containing 1 if an edge exist\n",
        "            torch.ones((self.edge_index.shape[1])),\n",
        "            torch.Size((self.num_nodes, self.num_nodes))\n",
        "        )\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"{self.__class__.__name__}(num_nodes:{self.num_nodes} x:{self.x.shape} y:{self.y.shape} edge_index:{self.edge_index.shape})\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fk-k5TUN0Ofe"
      },
      "outputs": [],
      "source": [
        "# @title [RUN] Convert PyG graphs to our new Graph class objects\n",
        "\n",
        "def convert_dataset(pyg_dataset):\n",
        "    dataset = []\n",
        "    for graph in pyg_dataset:\n",
        "        dataset.append(\n",
        "            Graph(graph.edge_index, graph.x, graph.y)\n",
        "        )\n",
        "    return dataset\n",
        "\n",
        "# Convert the dataset from list(Data) -> list(Graph)\n",
        "train_dataset = convert_dataset(train_pyg_dataset)\n",
        "val_dataset = convert_dataset(val_pyg_dataset)\n",
        "test_dataset = convert_dataset(test_pyg_dataset)\n",
        "\n",
        "# Check what the object contains\n",
        "one_graph = train_dataset[0]\n",
        "print(f\"First graph contains {one_graph.x.shape[0]} nodes, with {one_graph.x.shape[1]} features each.\")\n",
        "print(f\"Graph labels have shape: {one_graph.y.size(0)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4T0NiLCN1E5"
      },
      "source": [
        "Note that, for efficiency, the adjacency matrix (`self.get_adjacency_matrix()`) is stored as a sparse matrix (using `torch.sparse.LongTensor()`). This means that, instead of the entire matrix, we will only store the indexes of the vertices and the value (weight) corresponding to each edge. This saves lots of memory in storing the tensors for which the majority of elements are zeros.\n",
        "\n",
        "If you need to convert a sparse tensor `x` into a dense one you can use `x.to_dense()`. Moreover, many operations are directly supported for sparse tensors via [`torch.sparse`](https://pytorch.org/docs/stable/sparse.html) (e.g. `torch.sparse.mm()` that multiplies a sparse matrix with a sparse/dense matrix).\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5QHpx1KMGLi"
      },
      "source": [
        "# 🔠 Mini-batching for graph data\n",
        "\n",
        "Since we are now dealing with **multiple graphs**, we need to figure out how to store them in **mini-batches**, to be able to make the computation as efficient as possible. For some types of data, stacking samples in mini-batches is a trivial task. For example, images of $32\\times32$ pixels are easy to batch because they have the same dimension (obtaining a tensor of dimension $batch\\_{size}\\times32\\times32$). On the other hand, graphs come in different sizes with adjacency matrices of different shapes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KgEw_0yeMyL9"
      },
      "outputs": [],
      "source": [
        "print(f'First graph : {train_dataset[0].x.shape} with adjacency {(train_dataset[0].num_nodes, train_dataset[0].num_nodes)}')\n",
        "print(f'Second graph: {train_dataset[1].x.shape} with adjacency {(train_dataset[1].num_nodes, train_dataset[1].num_nodes)}')\n",
        "print(f'Third graph : {train_dataset[2].x.shape} with adjacency {(train_dataset[2].num_nodes, train_dataset[2].num_nodes)}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIpnDzA0OhVo"
      },
      "source": [
        "One solution for this is to create a single *sparse* graph as the union of all the graphs in the mini-batch as follow:\n",
        "\n",
        "1. stack the features $x$ for all the nodes in all the graphs\n",
        "2. stack the labels $y$ for all the nodes in all the graphs\n",
        "3. stack all the adjacency matrices $A_i$ as diagonal blocks in the new adjacency matrix\n",
        "\n",
        "This way, we will obtain a new graph containing $\\sum_{i=1}^{B}|V_i|$ nodes, where $B$ is the batch_size and by $|V_i|$ we denote the number of nodes in graph $i$. Note that since **no** edges connect nodes from different graphs,  the  information propagation will not be affected by the way we store it.  \n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1RwI0CYA57S0OgLxgHgV6PBFNG9tnGvGR\" width=\"500\">\n",
        "</center>\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1Ux65wTJLXCfJ4TI4Up4mCHkaSja8NgrJ\" width=\"500\">\n",
        "</center>\n",
        "\n",
        "As you can see, the resulting matrix contains many zeros (sparse), thus our choice of storing the adjacency matrix as a sparse tensor can indeed bring us efficiency."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOrDII9ZRH1L"
      },
      "source": [
        "---\n",
        "\n",
        "Until now, we have a way to store the graphs in a mini-batch such that they could be efficiently processed.\n",
        "\n",
        "However, we need to also be able to extract information from this structure, to recover the graphs that it contains. For this, we need to remember what initial graph each node belongs to.\n",
        "\n",
        "We will do this by storing a list of indices `(self.batch)`, which map each node in the batch-graph to the initial graph it belong to. For example `batch=[0,0,0,1,1,2,2,2]` indicates that first 3 nodes belong to $G_0$, the next 2 nodes belong to $G_1$ and the last 3 nodes belong to $G_2$.\n",
        "\n",
        "### 💻 **Task 1.2:** <font color=\"purple\">Implement a mini-batching function for graph data which builds a single sparse graph from a batch of graphs (2.0 Marks) </font>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2cUts094jmZ4"
      },
      "outputs": [],
      "source": [
        "def create_mini_batch(graph_list: List[Graph]) -> Graph:\n",
        "    \"\"\"\n",
        "    Function for built a single sparse graph from a batch of graphs.\n",
        "\n",
        "    Args:\n",
        "        graph_list: list of Graph objects in a batch\n",
        "    Returns:\n",
        "        a big (sparse) Graph representing the entire batch\n",
        "    \"\"\"\n",
        "    # insert first graph into the structure\n",
        "    batch_edge_index = graph_list[0].edge_index\n",
        "    batch_x = graph_list[0].x\n",
        "    batch_y = graph_list[0].y\n",
        "    batch_batch = torch.zeros((graph_list[0].num_nodes), dtype=torch.int64)\n",
        "\n",
        "    # ============ YOUR CODE HERE =============\n",
        "    # define any additional variables you may need\n",
        "    # ...\n",
        "    # ==========================================\n",
        "\n",
        "    # append the rest of the graphs to the structure\n",
        "    for idx, graph in enumerate(graph_list[1:]):\n",
        "\n",
        "        # ============ YOUR CODE HERE =============\n",
        "        # concat the features\n",
        "        # batch_x = ...\n",
        "        # concat the labels\n",
        "        # batch_y = ...\n",
        "        # concat the adjacency matrix as a block diagonal matrix\n",
        "        # batch_edge_index = ...\n",
        "        # ==========================================\n",
        "\n",
        "        # ============ YOUR CODE HERE =============\n",
        "        # create the array of indexes mapping nodes in the\n",
        "        # batch-graph to the graph they belong to\n",
        "        # specify the mapping between the new nodes and the graph they belong to (idx+1)\n",
        "        # batch_batch = ...\n",
        "        # ==========================================\n",
        "\n",
        "    # create the big sparse graph\n",
        "    batch_graph = Graph(batch_edge_index, batch_x, batch_y)\n",
        "\n",
        "    # attach the index array to the Graph structure\n",
        "    batch_graph.set_batch(batch_batch)\n",
        "\n",
        "    return batch_graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6ZG23di3PRd"
      },
      "outputs": [],
      "source": [
        "#@title Visualize the mini-batching for a small list of batch_size=3 graphs\n",
        "\n",
        "# 3 random custom-designed graphs for visualisations\n",
        "graph1 = Graph(x=torch.rand((3,32)),\n",
        "               y=torch.rand((1)),\n",
        "               edge_index=torch.tensor([[0,0,0,1,1,1,2,2,2],[0,1,2,0,1,2,0,1,2]]))\n",
        "graph2 = Graph(x=torch.rand((5,32)),\n",
        "               y=torch.rand((1)),\n",
        "               edge_index=torch.tensor([[0,0,0,0,0,1,1,1,2,1,2,3,4], [0,1,2,3,4,2,3,4,4,0,0,0,0]]))\n",
        "graph3 = Graph(x=torch.rand((4,32)),\n",
        "               y=torch.rand((1)),\n",
        "              edge_index=torch.tensor([[0,1,2,3],[1,2,3,0]]))\n",
        "list_graphs = [graph1, graph2, graph3]\n",
        "\n",
        "# create a mini-batch from these 3 graphs\n",
        "batch_sample = create_mini_batch(list_graphs)\n",
        "# show statistics about the new graph built from this batch of graphs\n",
        "print(f\"Batch number_of_nodes: {batch_sample.num_nodes}\")\n",
        "print(f\"Batch features shape: {batch_sample.x.shape}\")\n",
        "print(f\"Batch labels shape: {batch_sample.y.shape}\")\n",
        "\n",
        "print(f\"Batch adjacency: \")\n",
        "print_color_numpy(batch_sample.get_adjacency_matrix().to_dense().numpy(), list_graphs)\n",
        "\n",
        "gallery([graph1, graph2, graph3, batch_sample], max_fig_size=(20,6), special_color=True)\n",
        "print(f\"And we also have access to which graph each node belongs to: {batch_sample.batch}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZsWpBF-U7UPx"
      },
      "outputs": [],
      "source": [
        "# @title ✅ [RUN] **Please run this unit test to validate your code. The output would be used to mark your practical.**\n",
        "\n",
        "def unit_test_mini_batch(batch):\n",
        "\n",
        "  # create mini-batch using the function from task 1.2\n",
        "  graph_batch = create_mini_batch(batch)\n",
        "\n",
        "  # manually loop through samples to create lists used for asserts\n",
        "  adj_list = []\n",
        "  x_list = []\n",
        "  y_list = []\n",
        "  out_list = []\n",
        "  for i in range(len(batch)):\n",
        "    batch_i = create_mini_batch([batch[i]])\n",
        "    batch_i_adj = batch_i.get_adjacency_matrix().to_dense()\n",
        "    adj_list.append(batch_i_adj)\n",
        "    x_list.append(batch_i.x)\n",
        "    y_list.append(batch_i.y)\n",
        "\n",
        "  adj_list_big = torch.block_diag(*adj_list)\n",
        "  adj_batch = graph_batch.get_adjacency_matrix().to_dense()\n",
        "  assert(torch.allclose(adj_batch, adj_list_big, atol=1e-6)), \"The adjacency matrices are wrongly combined\"\n",
        "\n",
        "  x_list_big = torch.concat(x_list)\n",
        "  assert(torch.allclose(x_list_big, graph_batch.x, atol=1e-6)), \"The node features are wrongly combined\"\n",
        "\n",
        "  y_list_big = torch.concat(y_list)\n",
        "  assert(torch.allclose(y_list_big, graph_batch.y, atol=1e-6)), \"The node labels are wrongly combined\"\n",
        "\n",
        "  assert(torch.allclose(graph_batch.batch, torch.tensor([0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2]), atol=1e-6)), \"The batch indexes are wrongly combined\"\n",
        "  print(\"✅ All seems good!!!\")\n",
        "\n",
        "\n",
        "# run unit test function\n",
        "unit_test_mini_batch(list_graphs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-s_ClR5Twrn"
      },
      "source": [
        "---\n",
        "\n",
        "## The Scatter function for aggregating information\n",
        "\n",
        "As you learned in the course, a simple way of aggregating information from node-level representation to obtain graph-level predictions is by (max/mean/sum) pooling. This can be efficiently obtained using the [`torch_scatter`](https://pytorch-scatter.readthedocs.io/en/1.3.0/functions/mean.html) library containing operations such as `scatter_mean`, `scatter_max`, `scatter_sum`.\n",
        "\n",
        "`scatter_*` receives as input a tensor and an array of indices and pools the information in the tensor stored at the indices specified in the array.\n",
        "\n",
        "Here's what `scatter_sum(array, index)` looks like, visually:\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=16E9Nyd-mPdYBWm923joWKJx4JR8c8pCz\" width=\"400\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkr_eSQoZxO5"
      },
      "source": [
        "### 💻 **Task 1.3:** <font color=\"purple\"> Having access to all the nodes embedings in a batch, use `scatter_*` to create graph embedings for each graph in the batch. (0.5 Marks) </font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GuT1FhZH32jN"
      },
      "outputs": [],
      "source": [
        "array = torch.tensor([13, 21, 3, 7, 11, 20, 2])\n",
        "index = torch.tensor([0,1,1,0,2,0,1])\n",
        "\n",
        "aggregate_sum = scatter_sum(array, index, dim=0)\n",
        "aggregate_mean = scatter_mean(array, index, dim=0)\n",
        "aggregate_max, aggregate_argmax = scatter_max(array, index, dim=0)\n",
        "\n",
        "print(\"Let's inspect what different scatter functions compute: \")\n",
        "print(f\"- sum aggregation output: {aggregate_sum}\")\n",
        "print(f\"- mean aggregation output: {aggregate_mean}\")\n",
        "print(f\"- max aggregation output: {aggregate_max}\\n\")\n",
        "\n",
        "batch_qm9 = create_mini_batch(train_dataset[:3])\n",
        "# ============ YOUR CODE HERE =============\n",
        "# Given the nodes features for a batch of graphs (batch_qm9.x)\n",
        "# and the list of indices indicating what graph each node belongs to\n",
        "# apply scatter_* to obtain a graph embedings for each graph in the batch\n",
        "# You can play with all of them (scatter_mean/scatter_max/scatter_sum)\n",
        "\n",
        "# node_emb = ...\n",
        "# node_batch = ...\n",
        "# graph_emb = ...\n",
        "print(node_emb.shape)\n",
        "print(graph_emb.shape)\n",
        "# =========================================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jW0zxO4klfGz"
      },
      "outputs": [],
      "source": [
        "# @title ✅ [RUN] **Please run this unit test to validate your code. The output would be used to mark your practical.**\n",
        "\n",
        "def unit_test_scatter():\n",
        "\n",
        "  num_edges = len(set(batch_qm9.batch.numpy()))\n",
        "\n",
        "  assert graph_emb.shape == (num_edges, batch_qm9.x.shape[-1]), \"Output shape is unexpected.\"\n",
        "\n",
        "  print(\"✅ All seems good!!!\")\n",
        "\n",
        "# run unit test function\n",
        "unit_test_scatter()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oub6anZdnXjJ"
      },
      "source": [
        "So far, we've learned:\n",
        "1. how to store a batch of graphs in an efficient way,\n",
        "2. how scatter operations work and how to use it to extract graph-level representations from node-level representations.\n",
        "\n",
        "Let's integrate what we've learned so far in a Graph Neural Network model.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPd6vIxLT6Cp"
      },
      "source": [
        "# 🔅 A simple Graph Neural Network for graph-level regression\n",
        "\n",
        "We will now design a Graph Neural Network model, similar to the GCN used on Cora, with the following modifications:\n",
        "* We are now working on graph-level prediction for molecular graphs from QM9, instead of node-level prediction on Cora.\n",
        "* The task is regression instead of classification.\n",
        "* We will use a simple sum aggregation instead of the symmetric normalised degree-based aggregation.\n",
        "\n",
        "Concretly, the non-normalised GCN we will use for molecular property prediction can be express as:\n",
        "\n",
        "\\begin{equation}\n",
        "\\mathbf{X^{k+1}= \\text{MLP}_k\\big(AX^k + X^k\\big)},\n",
        "\\end{equation}\n",
        "where the MLP at the $k$th layer, $\\text{MLP}_k$ is a multi-layer perceptron sequentially applies a Linear layer projecting the features from the input dimension to a hidden dimension, a ReLU activation, and another Linear projection from the hidden dimension to the output dimension.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0qJSFf13SkK"
      },
      "outputs": [],
      "source": [
        "# @title [RUN] Hyperparameters for molecular GCN\n",
        "\n",
        "BATCH_SIZE =  128  #@param {type:\"integer\"}\n",
        "NUM_EPOCHS =   30  #@param {type:\"integer\"}\n",
        "HIDDEN_DIM =   64  #@param {type:\"integer\"}\n",
        "LR         = 0.001 #@param {type:\"number\"}\n",
        "\n",
        "#you can add more here if you need"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Mhc4VbQ69a_"
      },
      "source": [
        "### 💻 **Task 1.4:** <font color=purple> Implement a simple GNN for molecular property prediction on QM9. Most of the code is provided to you, but you have to fill in the missing part that implements the core message passing equation shown above. (1.0 Mark) </font>\n",
        "\n",
        "**❗️Note:** A slight modification compared to the GCNLayer used in the Cora dataset is in the way we provide the adjacency matrix to the model. In the Cora setup, we provide the adjacency matrix in the `__init__` function,  while for QM9 we are giving it as argument in the `forward` function. This is due to the different nature of tasks we are tackling. While the Cora dataset is a transductive problem, where the entire dataset is a single graph, for the QM9 we have a lists of graphs, so we need to be able to provide a subset of them at each iteration.  \n",
        "\n",
        "**❗️Note:** The MLP needs to be a 2-layer one as follow: Linear - ReLU - Linear"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93sKHVmsK_-6"
      },
      "outputs": [],
      "source": [
        "class GCNLayer(Module):\n",
        "    \"\"\"\n",
        "    A single GCN layer, implementing MLP(AX + X)\n",
        "\n",
        "    Args:\n",
        "        in_feats (int): Dimensionality of input features\n",
        "        out_feats (int): Dimensionality of output features\n",
        "        hidden_dim (int): Dimensionality of hidden layers\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_feats: int, out_feats: int, hidden_dim: int):\n",
        "        super(GCNLayer, self).__init__()\n",
        "        self.in_feats = in_feats\n",
        "        self.out_feats = out_feats\n",
        "\n",
        "        self.linear1 = Linear(self.in_feats, hidden_dim)\n",
        "        self.linear2 = Linear(hidden_dim, self.out_feats)\n",
        "\n",
        "    def forward(self, x, adj_sparse):\n",
        "        \"\"\"Forward pass through the GCNLayer given the input\n",
        "        node features and the adjacency matrix\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): input node features\n",
        "            adj_sparse (torch.sparse.LongTensor): adjacency matrix using sparse\n",
        "                format\n",
        "        \"\"\"\n",
        "        # ============ YOUR CODE HERE =============\n",
        "        # aggregate the neighbours as in GCN: (AX + X)\n",
        "        # x = ...\n",
        "\n",
        "        # project the features (MLP_k)\n",
        "        # x = ...\n",
        "        # x = ...\n",
        "        # out = ...\n",
        "        # =========================================\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5YofxCV_qNTj"
      },
      "outputs": [],
      "source": [
        "# @title ✅ [RUN] **Please run this unit test to validate your code. The output would be used to mark your practical.**\n",
        "\n",
        "def unit_test_gcn():\n",
        "  torch.random.manual_seed(0)\n",
        "  np.random.seed(0)\n",
        "  A,x,y = get_dummy_data_inductive_layer()\n",
        "\n",
        "  input_dim = x.shape[-1]\n",
        "  output_dim = y.shape[-1]\n",
        "\n",
        "  torch.random.manual_seed(0)\n",
        "  model = GCNLayer(in_feats=input_dim, out_feats=output_dim, hidden_dim=32)\n",
        "\n",
        "  A_sparse = A.float().to_sparse_csr()\n",
        "  out = model(x, A_sparse)\n",
        "\n",
        "  assert(out.shape == (A.shape[0], output_dim)), \"Something is wrong with your output shape\"\n",
        "\n",
        "  perm = np.random.permutation(x.shape[0])\n",
        "  perm_x = x[perm]\n",
        "  perm_out = out[perm]\n",
        "  A_perm = A[perm, :][:, perm]\n",
        "  A_perm_sparse = A_perm.float().to_sparse_csr()\n",
        "\n",
        "  out_model_perm = model(perm_x, A_perm_sparse)\n",
        "\n",
        "  assert (torch.allclose(perm_out, out_model_perm, atol=1e-6)), \"Oops, something is wrong in the GCN implementation. You are not permutation equivariant anymore 🥺.\"\n",
        "\n",
        "  assert (torch.allclose(out, y, atol=1e-6)), \"🤔 Something is wrong in the model! The output is wrong.\"\n",
        "\n",
        "  print(\"✅ All seems good!!!\")\n",
        "\n",
        "# run unit test function\n",
        "unit_test_gcn()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOCawKw08CT2"
      },
      "source": [
        "Using the above GCN Layer, let's design a neural network with `num_layers` GCNLayers, to solve the graph-regression task on QM9.\n",
        "\n",
        "\n",
        "### 💻 **Task 1.5:** <font color=purple> Most of the code for a `SimpleGCN` model for  is provided. All you have to do is to fill-in the code that creates graph-representations from node-representations using the `scatter_sum` function you just learnt about (0.5 Mark) </font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XxxzXYeZHQah"
      },
      "outputs": [],
      "source": [
        "class SimpleGCN(Module):\n",
        "    \"\"\"\n",
        "    A Graph Neural Network containing GCN layers for graph-level prediction\n",
        "\n",
        "    The readout function used to obtain pooled graph-level representations\n",
        "    is just the sum of the node features in the graph\n",
        "\n",
        "    Args:\n",
        "        input_dim (int): Dimensionality of the input feature vectors\n",
        "        output_dim (int): Dimensionality of the output softmax distribution\n",
        "        hidden_dim (int): Dimensionality of the hidden layers\n",
        "        num_layers (int): Number of layers\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers=2):\n",
        "        super(SimpleGCN, self).__init__()\n",
        "        self.num_layers = num_layers # please select num_layers>=2\n",
        "        # a linear layer to create embedding representations\n",
        "        # based on each atom's input features\n",
        "        self.embed_x = Linear(input_dim, hidden_dim)\n",
        "\n",
        "        # instead of nn.Linear as in SimpleMLP model,\n",
        "        # now we have (num_layers) GCNLayer(s), each with different parameters\n",
        "        self.layers = [GCNLayer(hidden_dim, hidden_dim, hidden_dim) for _ in range(num_layers-1)]\n",
        "        self.layers += [GCNLayer(hidden_dim, output_dim, hidden_dim)]\n",
        "        self.layers = ModuleList(self.layers)\n",
        "\n",
        "    def forward(self, graph):\n",
        "        \"\"\"Forward pass through the SimpleGCN given a (mini-batch of) graph.\n",
        "\n",
        "        Args:\n",
        "            graph (Graph): a graph object which contains one or more graphs and\n",
        "                their attributes\n",
        "        \"\"\"\n",
        "        adj_sparse = graph.get_adjacency_matrix()\n",
        "        x = self.embed_x(graph.x)\n",
        "\n",
        "        # sequentially apply GNN layers\n",
        "        for i in range(self.num_layers-1):\n",
        "          x = self.layers[i](x, adj_sparse)\n",
        "          x = F.relu(x)\n",
        "        x = self.layers[-1](x, adj_sparse)\n",
        "\n",
        "        # ============ YOUR CODE HERE =============\n",
        "        # graph-level representations are obtained by pooling info from the nodes using sum\n",
        "        # y_hat = ...\n",
        "        # =========================================\n",
        "\n",
        "        y_hat = y_hat.squeeze(-1)\n",
        "        # also return the final node embeddings (for visualisations)\n",
        "        return y_hat, x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "eoA03MZK39ym"
      },
      "outputs": [],
      "source": [
        "# @title [RUN] Helper functions for managing experiments, training, and evaluating models\n",
        "\n",
        "def train(dataset, model, optimiser, epoch, loss_fct, metric_fct, print_every):\n",
        "    \"\"\" Train model for one epoch\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    num_iter = int(len(dataset)/BATCH_SIZE)\n",
        "    for i in range(num_iter):\n",
        "        batch_list = dataset[i*BATCH_SIZE:(i+1)*BATCH_SIZE]\n",
        "        batch = create_mini_batch(batch_list)\n",
        "        optimiser.zero_grad()\n",
        "        y_hat, _ = model(batch)\n",
        "        loss = loss_fct(y_hat, batch.y)\n",
        "        metric = metric_fct(y_hat, batch.y)\n",
        "        loss.backward()\n",
        "        optimiser.step()\n",
        "        if (i+1) % print_every == 0:\n",
        "          print(f\"Epoch {epoch} Iter {i}/{num_iter}\",\n",
        "                    f\"Loss train {loss.data}; Metric train {metric.data}\")\n",
        "    return loss.data, metric.data\n",
        "\n",
        "\n",
        "def evaluate(dataset, model, loss_fct, metrics_fct):\n",
        "    \"\"\" Evaluate model on dataset\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    # be careful in practice, as doing this way we will lose some\n",
        "    # examples from the validation split, when len(dataset)%BATCH_SIZE != 0\n",
        "    # think about how can you fix this!\n",
        "    num_iter = int(len(dataset)/BATCH_SIZE)\n",
        "    metrics_eval = 0\n",
        "    loss_eval = 0\n",
        "    for i in range(num_iter):\n",
        "        batch_list = dataset[i*BATCH_SIZE:(i+1)*BATCH_SIZE]\n",
        "        batch = create_mini_batch(batch_list)\n",
        "        y_hat, _ = model(batch)\n",
        "        metrics = metrics_fct(y_hat, batch.y)\n",
        "        loss = loss_fct(y_hat, batch.y)\n",
        "\n",
        "        metrics_eval += metrics.data\n",
        "        loss_eval += loss.data\n",
        "    metrics_eval /= num_iter\n",
        "    loss_eval /= num_iter\n",
        "    return loss_eval, metrics_eval\n",
        "\n",
        "\n",
        "def train_eval(model, train_dataset, val_dataset, test_dataset,\n",
        "               loss_fct, metric_fct, print_every=1):\n",
        "    \"\"\" Train the model for NUM_EPOCHS epochs\n",
        "    \"\"\"\n",
        "    #Instantiatie our optimiser\n",
        "    optimiser = Adam(model.parameters(), lr=LR)\n",
        "    training_stats = None\n",
        "\n",
        "    #initial evaluation (before training)\n",
        "    val_loss, val_metric = evaluate(val_dataset, model, loss_fct, metric_fct)\n",
        "    train_loss, train_metric = evaluate(train_dataset[:BATCH_SIZE], model,\n",
        "                                        loss_fct, metric_fct)\n",
        "    epoch_stats = {'train_loss': train_loss, 'val_loss': val_loss,\n",
        "                      'train_metric': train_metric, 'val_metric': val_metric,\n",
        "                      'epoch':0}\n",
        "    training_stats = update_stats(training_stats, epoch_stats)\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        if isinstance(train_dataset, list):\n",
        "            random.shuffle(train_dataset)\n",
        "        else:\n",
        "            train_dataset.shuffle()\n",
        "        train_loss, train_metric = train(train_dataset, model, optimiser, epoch,\n",
        "                                        loss_fct, metric_fct, print_every)\n",
        "        val_loss, val_metric = evaluate(val_dataset, model, loss_fct, metric_fct)\n",
        "        print(f\"[Epoch {epoch+1}]\",\n",
        "                    f\"train loss: {train_loss:.3f} val loss: {val_loss:.3f}\",\n",
        "                    f\"train metric: {train_metric:.3f} val metric: {val_metric:.3f}\"\n",
        "              )\n",
        "        # store the loss and the computed metric for the final plot\n",
        "        epoch_stats = {'train_loss': train_loss, 'val_loss': val_loss,\n",
        "                      'train_metric': train_metric, 'val_metric': val_metric,\n",
        "                      'epoch':epoch+1}\n",
        "        training_stats = update_stats(training_stats, epoch_stats)\n",
        "\n",
        "    test_loss, test_metric = evaluate(test_dataset, model,  loss_fct, metric_fct)\n",
        "    print(f\"Test metric: {test_metric:.3f}\")\n",
        "    return training_stats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gh5irkVH8lOp"
      },
      "source": [
        "Now it's finally time to train our model and see the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eWBtK14LN0TY"
      },
      "outputs": [],
      "source": [
        "# Instantiate our GCN model\n",
        "model_simple_gcn = SimpleGCN(input_dim=batch_qm9.x.size()[-1], output_dim=1, hidden_dim=HIDDEN_DIM, num_layers=4)\n",
        "\n",
        "# forward pass on dummy input\n",
        "out, _ = model_simple_gcn(batch_qm9)\n",
        "print(out.detach().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ykgm3D0gqocp"
      },
      "outputs": [],
      "source": [
        "# @title ✅ [RUN] **Please run this unit test to validate your code. The output would be used to mark your practical.**\n",
        "def testing_simple_gcn():\n",
        "  torch.random.manual_seed(0)\n",
        "  np.random.seed(0)\n",
        "  A,x,y = get_dummy_data_inductive_model()\n",
        "\n",
        "  input_dim = x.shape[-1]\n",
        "  output_dim = y.shape[-1]\n",
        "\n",
        "  torch.random.manual_seed(0)\n",
        "  model = SimpleGCN(input_dim=input_dim, output_dim=output_dim, hidden_dim=32)\n",
        "\n",
        "  A_sparse = A.to_sparse().indices()\n",
        "  graph = create_mini_batch([Graph(x=x, y=y, edge_index=A_sparse)])\n",
        "  out, _ = model(graph)\n",
        "\n",
        "  assert (torch.allclose(out, y, atol=1e-6)), \"🤔 Oops, something is wrong in the SimpleGCN implementation! The output is wrong.\"\n",
        "  print(\"✅ All seems good!!!\")\n",
        "\n",
        "# run unit test function\n",
        "testing_simple_gcn()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5DueMpa54X27"
      },
      "outputs": [],
      "source": [
        "#Train GCN model:\n",
        "train_stats_simple_gcn_qm9 = train_eval(model_simple_gcn, train_dataset, val_dataset,\n",
        "                                        test_dataset, loss_fct=F.mse_loss,\n",
        "                                        metric_fct=F.mse_loss, print_every=150)\n",
        "plot_stats(train_stats_simple_gcn_qm9, name='Simple_GCN_QM9', figsize=(5, 10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1K3smLkDWTP"
      },
      "source": [
        "---\n",
        "\n",
        "# 🚀 Part 2: Going Geometric -- from vanilla PyTorch to PyG\n",
        "\n",
        "Up until now you have implemented several graph neural networks for both substructure- and graph-level learning mostly on vanilla PyTorch. This was for pedagogic reasons and for you to appreciate the notorious difficulty of implementing these ''from scratch''.\n",
        "\n",
        "For the remainder of this practical, we will make extensive use of **PyTorch Geometric**. If you have never worked with PyG before, do not worry, we will provide you with some examples and guide you through all the fundamentals in a detailed manner. We also highly recommend [this self-contained official tutorial](https://pytorch-geometric.readthedocs.io/en/latest/notes/introduction.html), which will help you get started. Among other things, you will learn how to implement state-of-the-art GNN layers via the generic PyG [Message Passing](https://pytorch-geometric.readthedocs.io/en/latest/notes/create_gnn.html) class (more on this later).\n",
        "\n",
        "**❗️Note:** We will be using **sparse graphs** (where an edge between two atoms is present only when there exists a physical connection between them). At the end of the practical, we will share some code to study the advantages/downsides of fully-connected adjacency matrices versus sparse adjacency matrices.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwU6kwHObiIn"
      },
      "source": [
        "# 🧪 [Intro] Molecular Property Prediction with PyG\n",
        "\n",
        "Let us now look at the attributes of the PyG data objects that we initially loaded using the `QM9` dataset provided by PyG."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uIW69jB1i1P-"
      },
      "outputs": [],
      "source": [
        "data = train_pyg_dataset[0]\n",
        "\n",
        "print(f\"\\nThis molecule has {data.x.shape[0]} atoms, and {data.edge_attr.shape[0]} edges.\")\n",
        "\n",
        "print(f\"\\nFor each atom, we are given a feature vector with {data.x.shape[1]} entries (described above).\")\n",
        "\n",
        "print(f\"\\nFor each edge, we are given a feature vector with {data.edge_attr.shape[1]} entries (also described above).\")\n",
        "\n",
        "print(f\"\\nIn the next section, we will learn how to build a GNN in the Message Passing flavor to \\n\\\n",
        "process the node and edge features of molecular graphs and predict their properties.\")\n",
        "\n",
        "print(f\"\\nEach atom also has a {data.pos.shape[1]}-dimensional coordinate associated with it. \\n\\\n",
        "We will talk about their importance later in the practical.\")\n",
        "\n",
        "print(f\"\\nFinally, we have {data.y.shape[0]} regression target for the entire molecule.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDnWN7YvnaYs"
      },
      "source": [
        "## Using PyG for batching\n",
        "\n",
        "As you might remember from the previous practical, **batching graphs** can be quite a tedious and fiddly process. Thankfully, using PyG makes this super simple! Given a list of `Data` objects, we can easily batch this into a PyG `Batch` object as well as unbatch back into a list of graphs. Furthermore, in simple cases like ours, the PyG `DataLoader` object (different from the vanilla PyTorch one) handles all of the batching under the hood for us!\n",
        "\n",
        "Remember we have created sub-sets of molecular graphs (train, test, validation splits) from the QM9 dataset. Let us now load the datasets into the PyG `DataLoader`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79-EDckhEbjv"
      },
      "outputs": [],
      "source": [
        "# Create dataloaders with batch size = 32\n",
        "train_loader = DataLoader(train_pyg_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_pyg_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_pyg_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCilSuF9Eddu"
      },
      "source": [
        "Lets quickly batch and unbatch some graphs as a demonstration:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xd3Yn7jOgNbY"
      },
      "outputs": [],
      "source": [
        "# Toy graph 1\n",
        "edge_index_1 = torch.tensor(\n",
        "    [[0, 1, 1, 2], [1, 0, 2, 1]],\n",
        "    dtype=torch.long\n",
        ")\n",
        "x_1 = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n",
        "\n",
        "data_1 = Data(x=x_1, edge_index=edge_index_1)\n",
        "\n",
        "# Toy graph 2\n",
        "edge_index_2 = torch.tensor(\n",
        "    [[0, 2, 1, 0], [2, 0, 0, 1]],\n",
        "    dtype=torch.long\n",
        ")\n",
        "x_2 = torch.tensor([[1], [0], [-1]], dtype=torch.float)\n",
        "\n",
        "data_2 = Data(x=x_2, edge_index=edge_index_2)\n",
        "\n",
        "# Create batch from toy graphs\n",
        "data_list = [data_1, data_2]\n",
        "batch = Batch.from_data_list(data_list)\n",
        "\n",
        "assert (batch[0].x == data_1.x).all() and (batch[1].x == data_2.x).all()\n",
        "\n",
        "# Create DataLoader\n",
        "loader = DataLoader(data_list, batch_size=1, shuffle=False)\n",
        "it = iter(loader)\n",
        "batch_1 = next(it)\n",
        "batch_2 = next(it)\n",
        "\n",
        "assert (batch_1.x == data_1.x).all() and (batch_2.x == data_2.x).all()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zuv-ofkecJgU"
      },
      "source": [
        "Awesome! So far, we have downloaded and prepared the QM9 dataset, visualised some samples, understood the attributes associated with each molecular graph, developed GNNs in pure PyTorch, and reviewed how batching works in PyG. Now, we are ready to understand how we can develop GNNs in PyG for molecular property prediction.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "563IbrHKihGQ"
      },
      "source": [
        "# 📩 [Intro] Introduction to Message Passing Neural Networks in PyTorch Geometric\n",
        "\n",
        "As a gentle introduction to PyTorch Geometric, we will walk you through the first steps of developing a GNN in the **Message Passing** flavor.\n",
        "\n",
        "![](https://drive.google.com/uc?id=1Wdgdq606XW1MelvcU1nW5CxWe1rHsWt1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAwoHyWs452X"
      },
      "source": [
        "## Formalism\n",
        "\n",
        "Firstly, let us formalise our molecular property prediction pipeline. (Our notation will mostly follow what has been introduced in the lectures, but we do make some different choices for variable names.)\n",
        "\n",
        "### Graph\n",
        "Consider a molecular graph $G = \\left( V, {E} \\right)$, where ${V}$ is a set of $n$ nodes, and ${E}$ is a set of edges associated with the nodes. For each node $i \\in {V}$, we are given a $d_n$-dimensional initial feature vector $h_i \\in \\mathbb{R}^{d_n}$.\n",
        "For each edge $(i, j) \\in {E}$, we are given a $d_e$-dimensional initial feature vector $e_{ij} \\in \\mathbb{R}^{d_e}$. For QM9 graphs, $d_n = 11, d_e = 4$.\n",
        "\n",
        "### Label/target\n",
        "Associated with each graph ${G}$ is a scalar target or label $y \\in \\mathbb{R}^{1}$, which we would like to predict.\n",
        "\n",
        "We will design a Message Passing Neural Network for graph property prediction to do this. Our MPNN will consist of several layers of message passing, followed by a global pooling and prediction head.\n",
        "\n",
        "### MPNN Layer\n",
        "The Message Passing operation iteratively updates node features $h_i^{\\ell} \\in \\mathbb{R}^d$ from layer $\\ell$ to layer $\\ell+1$ via the following equation:\n",
        "$$\n",
        "h_i^{\\ell+1} = \\phi \\Bigg( h_i^{\\ell}, \\oplus_{j \\in {N}_i} \\Big( \\psi \\left( h_i^{\\ell}, h_j^{\\ell}, e_{ij} \\right) \\Big) \\Bigg),\n",
        "$$\n",
        "where $\\psi, \\phi$ are Multi-Layer Perceptrons (MLPs), and $\\oplus$ is a permutation-invariant local neighborhood aggregation function such as summation, maximization, or averaging.\n",
        "\n",
        "Let us break down the MPNN layer into three pedagogical steps:\n",
        "- **Step (1): Message.** For each pair of linked nodes $i, j$, the network first computes a message $m_{ij} =  \\psi \\left( h_i^{\\ell}, h_j^{\\ell}, e_{ij} \\right)$. The MLP $\\psi: \\mathbb{R}^{2d + d_e} → \\mathbb{R}^d$ takes as input the concatenation of the feature vectors from the source node, destination node, and edge.\n",
        "    - Note that for the first layer $\\ell=0$, $h_i^{\\ell=0} = W_{in} \\left( h_i \\right)$, where $W_{in} \\in \\mathbb{R}^{d_n}  \\rightarrow \\mathbb{R}^{d}$ is a simple linear projection (`torch.nn.Linear`) for the initial node features to hidden dimension $d$.\n",
        "- **Step (2): Aggregate.** At each node $i$, the incoming messages from all its neighbors are then aggregated as $m_{i} = \\oplus_{{j \\in {N}_i}} \\left( m_{ij} \\right)$, where $\\oplus$ is a permutation-invariant function. We will use summation, i.e. $\\oplus_{{j \\in {N}_i}} = \\sum_{{j \\in {N}_i}}$.\n",
        "- **Step (3): Update.** Finally, the network updates the node feature vector $h_i^{\\ell+1} = \\phi \\left( h_i^{\\ell}, m_i \\right)$, by concatenating the aggregated message $m_i$ and the previous node feature vector $h_i^{\\ell}$, and passing them through an MLP $\\phi: \\mathbb{R}^{2d} → \\mathbb{R}^{d}$.\n",
        "\n",
        "### Global Pooling and Prediction Head\n",
        "After $L$ layers of message passing, we obtain the final node features $h_i^{\\ell=L}$. As we have a single target $y$ per graph, we must pool all node features into a single graph feature or graph embedding $h_G \\in \\mathbb{R}^d$ via another permutation-invariant function $R$, sometimes called the 'readout' function, as follows:\n",
        "$$\n",
        "h_G = R_{i \\in {V}} \\left( h_i^{\\ell=L} \\right).\n",
        "$$\n",
        "We will use global average pooling over all node features, i.e.\n",
        "$$\n",
        "h_G = \\frac{1}{|{V}|} \\sum_{i \\in {V}} h_i^{\\ell=L}.\n",
        "$$\n",
        "\n",
        "The graph embedding $h_G$ is passed through a linear prediction head $W_{pred} \\in \\mathbb{R}^{d} \\rightarrow \\mathbb{R}^1$ to obtain the overall prediction $\\hat y \\in \\mathbb{R}^1$:\n",
        "$$\n",
        "\\hat{y} = W_{pred} \\left( h_G \\right).\n",
        "$$\n",
        "\n",
        "### Loss Function\n",
        "Our MPNN graph property prediction model can be trained end-to-end via minimizing the standard mean-squared error loss for regression:\n",
        "$$\n",
        "{L}_{MSE} = \\lVert y - \\hat y \\rVert^2_2.\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xcV8Yb148Kq"
      },
      "source": [
        "## Coding the basic Message Passing Neural Network Layer\n",
        "\n",
        "We are now ready to define a basic MPNN layer which implements what we have described above. In particular, we will code up the **MPNN Layer** first. (We will code up the other parts subsequently.)\n",
        "\n",
        "To do so, we will inherit from the `MessagePassing` base class, which automatically takes care of message propagation and is extremely useful to develop advanced GNN models. To implement a custom MPNN, the user only needs to define the behaviour of the `message` (i.e. $\\psi$), the `aggregate`(i.e. $\\oplus$), and `update` (i.e. $\\phi$) functions. You may also refer to the [PyG documentation](https://pytorch-geometric.readthedocs.io/en/latest/notes/create_gnn.html) for implementing custom message passing layers.\n",
        "\n",
        "Below, we provide the implementation of a standard MPNN layer as an example, with extensive inline comments to help you figure out what is going on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wO5GskvZnZ1j"
      },
      "outputs": [],
      "source": [
        "class MPNNLayer(MessagePassing):\n",
        "    def __init__(self, emb_dim=64, edge_dim=4, aggr='add'):\n",
        "        \"\"\"Message Passing Neural Network Layer\n",
        "\n",
        "        Args:\n",
        "            emb_dim: (int) - hidden dimension `d`\n",
        "            edge_dim: (int) - edge feature dimension `d_e`\n",
        "            aggr: (str) - aggregation function `\\oplus` (sum/mean/max)\n",
        "        \"\"\"\n",
        "        # Set the aggregation function\n",
        "        super().__init__(aggr=aggr)\n",
        "\n",
        "        self.emb_dim = emb_dim\n",
        "        self.edge_dim = edge_dim\n",
        "\n",
        "        # MLP `\\psi` for computing messages `m_ij`\n",
        "        # Implemented as a stack of Linear->BN->ReLU->Linear->BN->ReLU\n",
        "        # dims: (2d + d_e) -> d\n",
        "        self.mlp_msg = Sequential(\n",
        "            Linear(2*emb_dim + edge_dim, emb_dim), BatchNorm1d(emb_dim), ReLU(),\n",
        "            Linear(emb_dim, emb_dim), BatchNorm1d(emb_dim), ReLU()\n",
        "          )\n",
        "\n",
        "        # MLP `\\phi` for computing updated node features `h_i^{l+1}`\n",
        "        # Implemented as a stack of Linear->BN->ReLU->Linear->BN->ReLU\n",
        "        # dims: 2d -> d\n",
        "        self.mlp_upd = Sequential(\n",
        "            Linear(2*emb_dim, emb_dim), BatchNorm1d(emb_dim), ReLU(),\n",
        "            Linear(emb_dim, emb_dim), BatchNorm1d(emb_dim), ReLU()\n",
        "          )\n",
        "\n",
        "    def forward(self, h, edge_index, edge_attr):\n",
        "        \"\"\"\n",
        "        The forward pass updates node features `h` via one round of message passing.\n",
        "\n",
        "        As our MPNNLayer class inherits from the PyG MessagePassing parent class,\n",
        "        we simply need to call the `propagate()` function which starts the\n",
        "        message passing procedure: `message()` -> `aggregate()` -> `update()`.\n",
        "\n",
        "        The MessagePassing class handles most of the logic for the implementation.\n",
        "        To build custom GNNs, we only need to define our own `message()`,\n",
        "        `aggregate()`, and `update()` functions (defined subsequently).\n",
        "\n",
        "        Args:\n",
        "            h: (n, d) - initial node features\n",
        "            edge_index: (e, 2) - pairs of edges (i, j)\n",
        "            edge_attr: (e, d_e) - edge features\n",
        "\n",
        "        Returns:\n",
        "            out: (n, d) - updated node features\n",
        "        \"\"\"\n",
        "        out = self.propagate(edge_index, h=h, edge_attr=edge_attr)\n",
        "        return out\n",
        "\n",
        "    def message(self, h_i, h_j, edge_attr):\n",
        "        \"\"\"Step (1) Message\n",
        "\n",
        "        The `message()` function constructs messages from source nodes j\n",
        "        to destination nodes i for each edge (j, i) in `edge_index`.\n",
        "\n",
        "        The arguments can be a bit tricky to understand: `message()` can take\n",
        "        any arguments that were initially passed to `propagate`. Additionally,\n",
        "        we can differentiate destination nodes and source nodes by appending\n",
        "        `_i` or `_j` to the variable name, e.g. for the node features `h`, we\n",
        "        can use `h_i` and `h_j`.\n",
        "\n",
        "        This part is critical to understand as the `message()` function\n",
        "        constructs messages for each edge in the graph. The indexing of the\n",
        "        original node features `h` (or other node variables) is handled under\n",
        "        the hood by PyG.\n",
        "\n",
        "        Args:\n",
        "            h_i: (e, d) - destination node features, essentially h[edge_index[1]]\n",
        "            h_j: (e, d) - source node features, essentially h[edge_index[0]]\n",
        "            edge_attr: (e, d_e) - edge features\n",
        "\n",
        "        Returns:\n",
        "            msg: (e, d) - messages `m_ji` passed through MLP `\\psi`\n",
        "        \"\"\"\n",
        "        msg = torch.cat([h_i, h_j, edge_attr], dim=-1)\n",
        "        return self.mlp_msg(msg)\n",
        "\n",
        "    def aggregate(self, inputs, index):\n",
        "        \"\"\"Step (2) Aggregate\n",
        "\n",
        "        The `aggregate` function aggregates the messages from neighboring nodes,\n",
        "        according to the chosen aggregation function ('sum' by default).\n",
        "\n",
        "        Args:\n",
        "            inputs: (e, d) - messages `m_ji` from source to destination nodes\n",
        "            index: (e, 1) - list of destination nodes for each edge/message in `input`\n",
        "\n",
        "        Returns:\n",
        "            aggr_out: (n, d) - aggregated messages `m_i`\n",
        "        \"\"\"\n",
        "        return scatter(inputs, index, dim=self.node_dim, reduce=self.aggr)\n",
        "\n",
        "    def update(self, aggr_out, h):\n",
        "        \"\"\"\n",
        "        Step (3) Update\n",
        "\n",
        "        The `update()` function computes the final node features by combining the\n",
        "        aggregated messages with the initial node features.\n",
        "\n",
        "        `update()` takes the first argument `aggr_out`, the result of `aggregate()`,\n",
        "        as well as any optional arguments that were initially passed to\n",
        "        `propagate()`. E.g. in this case, we additionally pass `h`.\n",
        "\n",
        "        Args:\n",
        "            aggr_out: (n, d) - aggregated messages `m_i`\n",
        "            h: (n, d) - initial node features\n",
        "\n",
        "        Returns:\n",
        "            upd_out: (n, d) - updated node features passed through MLP `\\phi`\n",
        "        \"\"\"\n",
        "        upd_out = torch.cat([h, aggr_out], dim=-1)\n",
        "        return self.mlp_upd(upd_out)\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return (f'{self.__class__.__name__}(emb_dim={self.emb_dim}, aggr={self.aggr})')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPB24QlmU_46"
      },
      "source": [
        "Great! We have defined a **Message Passing layer** following the equation we had introduced previously. Let us use this layer to code up the full **MPNN graph property prediction model**. This model will take as input molecular graphs, process them via multiple MPNN layers, and predict a single property for each of them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0vqS1NAU_ZN"
      },
      "outputs": [],
      "source": [
        "class MPNNModel(Module):\n",
        "    def __init__(self, num_layers=4, emb_dim=64, in_dim=11, edge_dim=4, out_dim=1):\n",
        "        \"\"\"Message Passing Neural Network model for graph property prediction\n",
        "\n",
        "        Args:\n",
        "            num_layers: (int) - number of message passing layers `L`\n",
        "            emb_dim: (int) - hidden dimension `d`\n",
        "            in_dim: (int) - initial node feature dimension `d_n`\n",
        "            edge_dim: (int) - edge feature dimension `d_e`\n",
        "            out_dim: (int) - output dimension (fixed to 1)\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        # Linear projection for initial node features\n",
        "        # dim: d_n -> d\n",
        "        self.lin_in = Linear(in_dim, emb_dim)\n",
        "\n",
        "        # Stack of MPNN layers\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        for layer in range(num_layers):\n",
        "            self.convs.append(MPNNLayer(emb_dim, edge_dim, aggr='add'))\n",
        "\n",
        "        # Global pooling/readout function `R` (mean pooling)\n",
        "        # PyG handles the underlying logic via `global_mean_pool()`\n",
        "        self.pool = global_mean_pool\n",
        "\n",
        "        # Linear prediction head\n",
        "        # dim: d -> out_dim\n",
        "        self.lin_pred = Linear(emb_dim, out_dim)\n",
        "\n",
        "    def forward(self, data):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            data: (PyG.Data) - batch of PyG graphs\n",
        "\n",
        "        Returns:\n",
        "            out: (batch_size, out_dim) - prediction for each graph\n",
        "        \"\"\"\n",
        "        h = self.lin_in(data.x) # (n, d_n) -> (n, d)\n",
        "\n",
        "        for conv in self.convs:\n",
        "            h = h + conv(h, data.edge_index, data.edge_attr) # (n, d) -> (n, d)\n",
        "            # Note that we add a residual connection after each MPNN layer\n",
        "\n",
        "        h_graph = self.pool(h, data.batch) # (n, d) -> (batch_size, d)\n",
        "\n",
        "        out = self.lin_pred(h_graph) # (batch_size, d) -> (batch_size, 1)\n",
        "\n",
        "        return out.view(-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4xlvC8bZEv_"
      },
      "source": [
        "Awesome! We are done defining our first MPNN model for graph property prediction.\n",
        "\n",
        "But wait! Before we dive into training and evaluation this model, let us write some sanity checks for a **fundamental property** of the model and the layer.\n",
        "\n",
        "## Unit tests for Permutation Invariance and Equivariance\n",
        "\n",
        "The lectures have repeatedly stressed on certain fundamental properties for machine learning on graphs:\n",
        "- A **GNN <ins>layer**</ins> is **equivariant** to permutations of the set of nodes in the graph; i.e. as we permute the nodes, the node features produced by the GNN must permute accordingly.\n",
        "- A **GNN <ins>model**</ins> for graph-level property prediction is **invariant** to the permutations of the set of nodes in the graph; i.e. as we permute the nodes, the graph-level properly remains unchanged.\n",
        "\n",
        "(But wait...**What is a permutation?** Essentially, it is an **ordering of the nodes** in a graph. In general, there is **no canonical way** of assigning an ordering of the nodes, unlike textual or image data. However, graphs need to be stored and processed on computers in order to perform machine learning on them (which is what this course is about!). Thus, we need to ensure that our models are able to principally handle this **lack of canonical ordering** or permutation of graph nodes. This is what the above statements are trying to say.)\n",
        "\n",
        "### Formalism\n",
        "\n",
        "Let us try to formalise these notions of permutation invariance and equivariance via matrix notation (it is easier that way).\n",
        "\n",
        "- Let $\\mathbf{H} \\in \\mathbb{R}^{n \\times d}$ be a matrix of node features for a given molecular graph, where $n$ is the number of nodes/atoms and each row $h_i$ is the $d$-dimensional feature for node $i$.\n",
        "- Let $\\mathbf{A} \\in \\mathbb{R}^{n \\times n}$ be the adjacency matrix where each entry denotes $a_{ij}$ the presence or absence of an edge between nodes $i$ and $j$.\n",
        "- Let $\\mathbf{F}(\\mathbf{H}, \\mathbf{A}): \\mathbb{R}^{n \\times d} \\times \\mathbb{R}^{n \\times n} \\rightarrow \\mathbb{R}^{n \\times d}$ be a **GNN <ins>layer**</ins> that takes as input the node features and adjacency matrix, and returns the **updated node features**.\n",
        "- Let $f(\\mathbf{H}, \\mathbf{A}): \\mathbb{R}^{n \\times d} \\times \\mathbb{R}^{n \\times n} \\rightarrow \\mathbb{R}$ be a **GNN <ins>model**</ins> that takes as input the node features and adjacency matrix, and returns the **predicted graph-level property**.\n",
        "- Let $\\mathbf{P} \\in \\mathbb{R}^{n \\times n}$ be a **[permutation matrix](https://en.wikipedia.org/wiki/Permutation_matrix)** which has exactly one 1 in every row and column, and 0s elsewhere. Left-multiplying $\\mathbf{P}$ with a matrix changes the ordering of the rows of the matrix.\n",
        "\n",
        "### Permutation Equivariance\n",
        "\n",
        "The GNN <ins>layer</ins> $\\mathbf{F}$ is **permutation equivariant** as follows:\n",
        "$$\n",
        "\\mathbf{F}(\\mathbf{PH}, \\mathbf{PAP^T}) = \\mathbf{P} \\ \\mathbf{F}(\\mathbf{H}, \\mathbf{A}).\n",
        "$$\n",
        "\n",
        "Another way to formulate the above could be: (1) Consider the updated node features $\\mathbf{H'} = \\mathbf{F}(\\mathbf{H}, \\mathbf{A})$. (2) Applying any permutation matrix $\\mathbf{P}$ to the input of the GNN layer $\\mathbf{F}$ should produce the same result as applying the same permutation on $\\mathbf{H'}$:\n",
        "$$\n",
        "\\mathbf{F}(\\mathbf{PH}, \\mathbf{PAP^T}) = \\mathbf{P} \\ \\mathbf{H'}\n",
        "$$\n",
        "\n",
        "### Permutation Invariance\n",
        "\n",
        "The GNN <ins>model</ins> $f$ for graph-level prediction is **permutation invariant** as follows:\n",
        "$$\n",
        "f(\\mathbf{PH}, \\mathbf{PAP^T}) = f(\\mathbf{H}, \\mathbf{A}).\n",
        "$$\n",
        "\n",
        "Another way to formulate the above could be: (1) Consider the predicted molecular property $\\mathbf{\\hat y} = f(\\mathbf{H}, \\mathbf{A})$. (2) Applying any permutation matrix $\\mathbf{P}$ to the input of the GNN model $f$ should produce the same result as not applying it:\n",
        "$$\n",
        "f(\\mathbf{PH}, \\mathbf{PAP^T}) = \\mathbf{\\hat y}.\n",
        "$$\n",
        "\n",
        "With that formalism out of the way, let us write some unit tests to confirm that our `MPNNModel` and `MPNNLayer` are indeed permutation invariant and equivariant, respectively. (We have provided this for you)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXuzZIqpZVqS"
      },
      "outputs": [],
      "source": [
        "def permute_graph(data, perm):\n",
        "    \"\"\"Helper function for permuting PyG Data object attributes consistently.\n",
        "    \"\"\"\n",
        "    # Permute the node attribute ordering\n",
        "    data.x = data.x[perm]\n",
        "    data.pos = data.pos[perm]\n",
        "    data.z = data.z[perm]\n",
        "    data.batch = data.batch[perm]\n",
        "\n",
        "    # Permute the edge index\n",
        "    adj = to_dense_adj(data.edge_index)\n",
        "    adj = adj[:, perm, :]\n",
        "    adj = adj[:, :, perm]\n",
        "    data.edge_index = dense_to_sparse(adj)[0]\n",
        "\n",
        "    # Note:\n",
        "    # (1) While we originally defined the permutation matrix P as only having\n",
        "    #     entries 0 and 1, its implementation via `perm` uses indexing into\n",
        "    #     torch tensors, instead.\n",
        "    # (2) It is cumbersome to permute the edge_attr, so we set it to constant\n",
        "    #     dummy values For any experiments beyond unit testing, all GNN models\n",
        "    #     use the original edge_attr.\n",
        "\n",
        "    return data\n",
        "\n",
        "def permutation_invariance_unit_test(module, dataloader):\n",
        "    \"\"\"Unit test for checking whether a module (GNN model) is\n",
        "    permutation invariant.\n",
        "    \"\"\"\n",
        "    it = iter(dataloader)\n",
        "    data = next(it)\n",
        "\n",
        "    # Set edge_attr to dummy values (for simplicity)\n",
        "    data.edge_attr = torch.zeros(data.edge_attr.shape)\n",
        "\n",
        "    # Forward pass on original example\n",
        "    out_1 = module(data)\n",
        "\n",
        "    # Create random permutation\n",
        "    perm = torch.randperm(data.x.shape[0])\n",
        "    data = permute_graph(data, perm)\n",
        "\n",
        "    # Forward pass on permuted example\n",
        "    out_2 = module(data)\n",
        "\n",
        "    # Check whether output varies after applying transformations\n",
        "    return torch.allclose(out_1, out_2, atol=1e-04)\n",
        "\n",
        "\n",
        "def permutation_equivariance_unit_test(module, dataloader, with_pos=False):\n",
        "    \"\"\"Unit test for checking whether a module (GNN layer) is\n",
        "    permutation equivariant.\n",
        "    \"\"\"\n",
        "    it = iter(dataloader)\n",
        "    data = next(it)\n",
        "\n",
        "    # Set edge_attr to dummy values (for simplicity)\n",
        "    data.edge_attr = torch.zeros(data.edge_attr.shape)\n",
        "\n",
        "    # Forward pass on original example\n",
        "    if with_pos:\n",
        "        out_1 = module(data.x, data.pos, data.edge_index, data.edge_attr)\n",
        "    else:\n",
        "        out_1 = module(data.x, data.edge_index, data.edge_attr)\n",
        "\n",
        "    # Create random permutation\n",
        "    perm = torch.randperm(data.x.shape[0])\n",
        "    data = permute_graph(data, perm)\n",
        "\n",
        "    # Forward pass on permuted example\n",
        "    if with_pos:\n",
        "        out_2 = module(data.x, data.pos, data.edge_index, data.edge_attr)\n",
        "    else:\n",
        "        out_2 = module(data.x, data.edge_index, data.edge_attr)\n",
        "\n",
        "    # Check whether output varies after applying transformations\n",
        "    return torch.allclose(out_1[perm], out_2, atol=1e-04)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kj_EER0Mg5YQ"
      },
      "source": [
        "Now that we have defined the unit tests for permutation invariance (for the full MPNN model) and permutation equivariance (for the MPNN layer), let us perform the sanity check:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNAxOxMQkDwf"
      },
      "outputs": [],
      "source": [
        "# Instantiate temporary model, layer, and dataloader for unit testing\n",
        "layer = MPNNLayer(emb_dim=11, edge_dim=4)\n",
        "model = MPNNModel(num_layers=4, emb_dim=64, in_dim=11, edge_dim=4, out_dim=1)\n",
        "dataloader = DataLoader(train_pyg_dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "# Permutation invariance unit test for MPNN model\n",
        "print(f\"Is {type(model).__name__} permutation invariant? --> {permutation_invariance_unit_test(model, dataloader)}!\")\n",
        "\n",
        "# Permutation equivariance unit for MPNN layer\n",
        "print(f\"Is {type(layer).__name__} permutation equivariant? --> {permutation_equivariance_unit_test(layer, dataloader)}!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-cmASemh0wA"
      },
      "source": [
        "## Training and Evaluating Models\n",
        "\n",
        "Great! We are finally ready to train and evaluate our model on QM9. We have provided a **basic experiment loop** which takes as input the model and dataloaders, performs training, and returns the final performance on the **validation** and **test set**.\n",
        "\n",
        "We will be training a `MPNNModel` consisting of 4 layers of message passing with a hidden dimension of 64."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "FrYb8xr5iZQM"
      },
      "outputs": [],
      "source": [
        "#@title [RUN] Helper functions for managing experiments, training, and evaluating models.\n",
        "\n",
        "def train(model, train_loader, optimizer, device):\n",
        "    model.train()\n",
        "    loss_all = 0\n",
        "\n",
        "    for data in train_loader:\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        y_pred = model(data)\n",
        "        loss = F.mse_loss(y_pred, data.y)\n",
        "        loss.backward()\n",
        "        loss_all += loss.item() * data.num_graphs\n",
        "        optimizer.step()\n",
        "    return loss_all / len(train_loader.dataset)\n",
        "\n",
        "\n",
        "def eval(model, loader, device):\n",
        "    model.eval()\n",
        "    error = 0\n",
        "\n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "        with torch.no_grad():\n",
        "            y_pred = model(data)\n",
        "            # Mean Absolute Error using std (computed when preparing data)\n",
        "            error += (y_pred * std - data.y * std).abs().sum().item()\n",
        "    return error / len(loader.dataset)\n",
        "\n",
        "\n",
        "def run_experiment(model, model_name, train_loader, val_loader, test_loader, n_epochs=100):\n",
        "\n",
        "    print(f\"Running experiment for {model_name}, training on {len(train_loader.dataset)} samples for {n_epochs} epochs.\")\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    print(\"\\nModel architecture:\")\n",
        "    print(model)\n",
        "    total_param = 0\n",
        "    for param in model.parameters():\n",
        "        total_param += np.prod(list(param.data.size()))\n",
        "    print(f'Total parameters: {total_param}')\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Adam optimizer with LR 1e-3\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    # LR scheduler which decays LR when validation metric doesn't improve\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode='min', factor=0.9, patience=5, min_lr=0.00001)\n",
        "\n",
        "    print(\"\\nStart training:\")\n",
        "    best_val_error = None\n",
        "    perf_per_epoch = [] # Track Test/Val MAE vs. epoch (for plotting)\n",
        "    t = time.time()\n",
        "    for epoch in range(1, n_epochs+1):\n",
        "        # Call LR scheduler at start of each epoch\n",
        "        lr = scheduler.optimizer.param_groups[0]['lr']\n",
        "\n",
        "        # Train model for one epoch, return avg. training loss\n",
        "        loss = train(model, train_loader, optimizer, device)\n",
        "\n",
        "        # Evaluate model on validation set\n",
        "        val_error = eval(model, val_loader, device)\n",
        "\n",
        "        if best_val_error is None or val_error <= best_val_error:\n",
        "            # Evaluate model on test set if validation metric improves\n",
        "            test_error = eval(model, test_loader, device)\n",
        "            best_val_error = val_error\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "            # Print and track stats every 10 epochs\n",
        "            print(f'Epoch: {epoch:03d}, LR: {lr:5f}, Loss: {loss:.7f}, '\n",
        "                  f'Val MAE: {val_error:.7f}, Test MAE: {test_error:.7f}')\n",
        "\n",
        "        scheduler.step(val_error)\n",
        "        perf_per_epoch.append((test_error, val_error, epoch, model_name))\n",
        "\n",
        "    t = time.time() - t\n",
        "    train_time = t/60\n",
        "    print(f\"\\nDone! Training took {train_time:.2f} mins. Best validation MAE: {best_val_error:.7f}, corresponding test MAE: {test_error:.7f}.\")\n",
        "\n",
        "    return best_val_error, test_error, train_time, perf_per_epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JsGM5LWmiZQM"
      },
      "outputs": [],
      "source": [
        "model = MPNNModel(num_layers=4, emb_dim=64, in_dim=11, edge_dim=4, out_dim=1)\n",
        "model_name = type(model).__name__\n",
        "best_val_error, test_error, train_time, perf_per_epoch = run_experiment(\n",
        "    model,\n",
        "    model_name,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    test_loader,\n",
        "    n_epochs=100\n",
        ")\n",
        "RESULTS[model_name] = (best_val_error, test_error, train_time)\n",
        "df_temp = pd.DataFrame(perf_per_epoch, columns=[\"Test MAE\", \"Val MAE\", \"Epoch\", \"Model\"])\n",
        "DF_RESULTS = DF_RESULTS.append(df_temp, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4NWM5CbptmE"
      },
      "outputs": [],
      "source": [
        "RESULTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7rtvD0zvmpF"
      },
      "outputs": [],
      "source": [
        "p = sns.lineplot(x=\"Epoch\", y=\"Val MAE\", hue=\"Model\", data=DF_RESULTS)\n",
        "p.set(ylim=(0, 2));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r1pjr7brqKCz"
      },
      "outputs": [],
      "source": [
        "p = sns.lineplot(x=\"Epoch\", y=\"Test MAE\", hue=\"Model\", data=DF_RESULTS)\n",
        "p.set(ylim=(0, 1));"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQjp21t7Z2UF"
      },
      "source": [
        "Super! Everything up to this point has already been covered in the lectures, and we hope that the practical so far has been a useful recap along with the accompanying code.\n",
        "\n",
        "Now for the fun part, where you will be required to think what you have studied so far!\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bReLCZx9teYT"
      },
      "source": [
        "#<font color=lightblue>  🧊 Geometric Graphs and Message Passing with 3D Coordinates\n",
        "\n",
        "Remember that we were given **3D coordinates** with each atom in our molecular graph?\n",
        "\n",
        "Molecular graphs, and other structured data occurring in nature, do not simply exist on flat planes. Instead, molecules have an **inherent 3D structure** that influences their properties and functions.\n",
        "\n",
        "Let us visualize a molecule from QM9 in all of its 3D glory!\n",
        "\n",
        "Go ahead and try move this molecule with your mouse cursor!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9yFToebQcxo4"
      },
      "outputs": [],
      "source": [
        "MolTo3DView(smi2conf(Chem.MolToSmiles(to_rdkit(train_pyg_dataset[48]))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzDu7IH2H3qI"
      },
      "source": [
        "## 💻 <font color=purple> **Task 2.1:** Develop a Message Passing Neural Network `CoordMPNNModel` that incorporates the atom coordinates as node features. **(1.0 Marks)**.\n",
        "\n",
        "\n",
        "The `MPNNModel` we provided in the introduction above ignores the atom coordinates and only uses the node features to perform message passing. This means that the model is **not** leveraging useful **3D structural information** to predict the target property.\n",
        "\n",
        "Your first task is to modify the original `MPNNModel` to incorporate **atom coordinates** into the **node features**.\n",
        "\n",
        "We have defined most of the new `CoordMPNNModel` class for you, and you have to fill in the `YOUR CODE HERE` sections.\n",
        "\n",
        "🤔 *Hint: As reminder, the 3D atom positions are stored in `data.pos`. You don't have to do something very smart right now (that will come later). A **simple** solution is okay to get started, e.g. concatenation or summation.*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kRiMjgVSC7sD"
      },
      "outputs": [],
      "source": [
        "class CoordMPNNModel(MPNNModel):\n",
        "    def __init__(self, num_layers=4, emb_dim=64, in_dim=11, edge_dim=4, out_dim=1):\n",
        "        \"\"\"Message Passing Neural Network model for graph property prediction\n",
        "\n",
        "        This model uses both node features and coordinates as inputs.\n",
        "\n",
        "        Args:\n",
        "            num_layers: (int) - number of message passing layers `L`\n",
        "            emb_dim: (int) - hidden dimension `d`\n",
        "            in_dim: (int) - initial node feature dimension `d_n`\n",
        "            edge_dim: (int) - edge feature dimension `d_e`\n",
        "            out_dim: (int) - output dimension (fixed to 1)\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        # ============ YOUR CODE HERE ==============\n",
        "        # Adapt the input linear layer or add new input layers\n",
        "        # to account for the atom positions.\n",
        "        #\n",
        "        # Linear projection for initial node features and coordinates\n",
        "        # dim: ??? -> d\n",
        "        # self.lin_in = ...\n",
        "        # ==========================================\n",
        "\n",
        "        # Stack of MPNN layers\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        for layer in range(num_layers):\n",
        "            self.convs.append(MPNNLayer(emb_dim, edge_dim, aggr='add'))\n",
        "\n",
        "        # Global pooling/readout function `R` (mean pooling)\n",
        "        # PyG handles the underlying logic via `global_mean_pool()`\n",
        "        self.pool = global_mean_pool\n",
        "\n",
        "        # Linear prediction head\n",
        "        # dim: d -> out_dim\n",
        "        self.lin_pred = Linear(emb_dim, out_dim)\n",
        "\n",
        "    def forward(self, data):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            data: (PyG.Data) - batch of PyG graphs\n",
        "\n",
        "        Returns:\n",
        "            out: (batch_size, out_dim) - prediction for each graph\n",
        "        \"\"\"\n",
        "        # ============ YOUR CODE HERE ==============\n",
        "        # Incorporate the atom positions along with the features.\n",
        "        #\n",
        "        # h = ...\n",
        "        # ==========================================\n",
        "\n",
        "        for conv in self.convs:\n",
        "            h = h + conv(h, data.edge_index, data.edge_attr) # (n, d) -> (n, d)\n",
        "            # Note that we add a residual connection after each MPNN layer\n",
        "\n",
        "        h_graph = self.pool(h, data.batch) # (n, d) -> (batch_size, d)\n",
        "\n",
        "        out = self.lin_pred(h_graph) # (batch_size, d) -> (batch_size, 1)\n",
        "\n",
        "        return out.view(-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GjBznG2x96s"
      },
      "source": [
        "Before we go on to evaluating the new MPNN, let us once again run the permutation sanity checks again to make sure the model and layer have the desired properties that constitute every basic GNN:\n",
        "- The `MPNNLayer` should be permutation equivariant.\n",
        "- The `CoordMPNNModel` should be permutation invariant."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "34Besg_qKo7A"
      },
      "outputs": [],
      "source": [
        "# @title ✅ [RUN] **Please run this unit test to validate your code. The output would be used to mark your practical.**\n",
        "layer = MPNNLayer(emb_dim=11, edge_dim=4)\n",
        "model = CoordMPNNModel(num_layers=4, emb_dim=64, in_dim=11, edge_dim=4, out_dim=1)\n",
        "\n",
        "dataloader = DataLoader(train_pyg_dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "# Permutation invariance unit test for MPNN model\n",
        "is_permutation_invariant = permutation_invariance_unit_test(model, dataloader)\n",
        "assert is_permutation_invariant, \"🤔 Something is wrong in the model! Your CoordMPN is not permutation invariant 🥺\"\n",
        "\n",
        "# Permutation equivariance unit for MPNN layer\n",
        "is_permutation_equivariant = permutation_equivariance_unit_test(layer, dataloader)\n",
        "assert is_permutation_equivariant, \"🤔 Something is wrong in the model! Your MPNN Layer is not permutation equivariant 🥺\"\n",
        "\n",
        "model = CoordMPNNModel(num_layers=1, emb_dim=1, in_dim=1, edge_dim=1, out_dim=1)\n",
        "\n",
        "outs = torch.concatenate([model(dummy_data) for dummy_data in get_dummy_data()])\n",
        "are_all_equal = torch.all(outs == outs[0])\n",
        "\n",
        "assert not are_all_equal, \"🤔 Something is wrong in the model! Your CoordMPN is not using the positional information 🥺\"\n",
        "\n",
        "print(\"✅ All seems good!!!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZNSwwhuh_5D"
      },
      "outputs": [],
      "source": [
        "print(f\"Is {type(model).__name__} permutation invariant? --> {is_permutation_invariant}!\")\n",
        "print(f\"Is {type(layer).__name__} permutation equivariant? --> {is_permutation_equivariant}!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtVdT-uoP5cn"
      },
      "source": [
        "## <font color = blue> 💻 [OPTIONAL] Train and evaluate your `CoordMPNNModel` with node features and coordinates on QM9.\n",
        "\n",
        "Awesome! You are now ready to train and evaluate our new MPNN with node features and coordinates on QM9.\n",
        "\n",
        "Re-use the experiment loop we have provided and fill in the `YOUR CODE HERE` sections to run the experiment.\n",
        "\n",
        "You will be training a `CoordMPNNModel` consisting of 4 layers of message passing with a hidden dimension of 64, in order to compare your result fairly to the previous vanilla `MPNNModel`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4NCZinUVPozM"
      },
      "outputs": [],
      "source": [
        "# ============ YOUR CODE HERE ==============\n",
        "# Instantiate your CoordMPNNModel with the appropriate arguments.\n",
        "#\n",
        "# model = CoordMPNNModel(...)\n",
        "# ==========================================\n",
        "\n",
        "model_name = type(model).__name__\n",
        "best_val_error, test_error, train_time, perf_per_epoch = run_experiment(\n",
        "    model,\n",
        "    model_name, # \"MPNN w/ Features and Coordinates\",\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    test_loader,\n",
        "    n_epochs=100\n",
        ")\n",
        "\n",
        "RESULTS[model_name] = (best_val_error, test_error, train_time)\n",
        "df_temp = pd.DataFrame(perf_per_epoch, columns=[\"Test MAE\", \"Val MAE\", \"Epoch\", \"Model\"])\n",
        "DF_RESULTS = DF_RESULTS.append(df_temp, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNU5ISpKsHOR"
      },
      "outputs": [],
      "source": [
        "RESULTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rbTC_wWPr_qW"
      },
      "outputs": [],
      "source": [
        "p = sns.lineplot(x=\"Epoch\", y=\"Val MAE\", hue=\"Model\", data=DF_RESULTS)\n",
        "p.set(ylim=(0, 2));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PC5Cd0FKwxoD"
      },
      "outputs": [],
      "source": [
        "p = sns.lineplot(x=\"Epoch\", y=\"Test MAE\", hue=\"Model\", data=DF_RESULTS)\n",
        "p.set(ylim=(0, 1));"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_2h-Ki6RKSX"
      },
      "source": [
        "Hmm... If you've implemented the `CoordMPNNModel` correctly up till now, you may see a very curious result -- the performance of `CoordMPNNModel` is about equal or marginally worse than the vanilla `MPNNModel`!\n",
        "\n",
        "This is because the `CoordMPNNModel` may not be using 3D structural information in the most principled manner.</font>\n",
        "\n",
        "The next sections will help us formalise and understand why this is happening.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89EPWJ8fGwHe"
      },
      "source": [
        "## 🔄 Invariance to 3D Symmetries: Rotation and Translation\n",
        "\n",
        "We saw that the performance of `CoordMPNNModel` is unexpectedly mediocre compared to `MPNNModel` despite using both node features and coordinates. (But please do not panic if your results say otherwise.) In order to determine why, we must understand the concept of **3D symmetries**.\n",
        "\n",
        "### Geometric Invariance\n",
        "\n",
        "Recall that molecular graphs have 3D coordinates for each atom. A key detail which we have purposely withheld from you up till this point (😈) is that these 3D coordinates are **not  inherently fixed** or **permanent**. Instead, they were **experimentally determined** relative to a **frame of reference**.\n",
        "\n",
        "\n",
        "The atoms' 3D coordinates might be given in various different reference frames which are rotated or translated with respect to each other. However, the **properties** of this molecule will always remain the same no matter how we rotate or translate it. In other words, the molecule's properties are **invariant** to 3D rotations and translations.\n",
        "\n",
        "In this block we will study how to design GNN layers and models that respect these regularities.\n",
        "\n",
        "### Formalism\n",
        "\n",
        "Let us formalise the notion of invariance to 3D rotations and translations in GNNs via matrix notation.\n",
        "\n",
        "- Let $\\mathbf{H} \\in \\mathbb{R}^{n \\times d}$ be a matrix of node features for a given molecular graph, where $n$ is the number of nodes/atoms and each row $h_i$ is the $d$-dimensional feature for node $i$.\n",
        "- Let $\\mathbf{X} \\in \\mathbb{R}^{n \\times 3}$ be a matrix of node coordinates for a given molecular graph, where $n$ is the number of nodes/atoms and each row $x_i$ is the 3D coordinate for node $i$.\n",
        "- Let $\\mathbf{A} \\in \\mathbb{R}^{n \\times n}$ be the adjacency matrix where each entry denotes $a_{ij}$ the presence or absence of an edge between nodes $i$ and $j$.\n",
        "- Let $\\mathbf{F}(\\mathbf{H}, \\mathbf{X}, \\mathbf{A}): \\mathbb{R}^{n \\times d} \\times \\mathbb{R}^{n \\times 3} \\times \\mathbb{R}^{n \\times n} \\rightarrow \\mathbb{R}^{n \\times d}$ be a **GNN <ins>layer**</ins> that takes as input the node features, node coordinates, and adjacency matrix, and returns the **updated node features**.\n",
        "- Let $f(\\mathbf{H}, \\mathbf{X}, \\mathbf{A}): \\mathbb{R}^{n \\times d} \\times \\mathbb{R}^{n \\times 3} \\times \\mathbb{R}^{n \\times n} \\rightarrow \\mathbb{R}$ be a **GNN <ins>model**</ins> that takes as input the node features, node coordinates, and adjacency matrix, and returns the **predicted graph-level property**.\n",
        "\n",
        "(Notice that we have updated the notation for the GNN layer $\\mathbf{F}$ and GNN model $\\mathbf{f}$ to include the matrix of node coordinates $\\mathbf{X}$ as an additional input.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcWgYnZ9ymse"
      },
      "source": [
        "\n",
        "What does it mean for the GNN <ins>model</ins> $f$ and the GNN <ins>layer</ins> $\\mathbf{F}$ to be invariant to 3D rotations and translations? Let's express this mathematically using the definitions above.\n",
        "\n",
        "Let us define an orthogonal [**rotation matrix**](https://en.wikipedia.org/wiki/Rotation_matrix) $\\mathbf{Q} \\in \\mathbb{R}^{3 \\times 3}$ and [**translation vector**](https://en.wikipedia.org/wiki/Translation_(geometry)) $\\mathbf{t} \\in \\mathbb{R}^3$ that operate on the matrix of node coordinates $\\mathbf{X} \\in \\mathbb{R}^{n \\times 3}$.\n",
        "The GNN <ins>layer</ins> $\\mathbf{F}$ is **rotation** and **translation invariant** as follows:\n",
        "$$\n",
        "\\mathbf{F}(\\mathbf{H}, \\mathbf{X} \\ \\mathbf{Q} + \\mathbf{t}, \\mathbf{A}) = \\mathbf{F}(\\mathbf{H}, \\mathbf{X}, \\mathbf{A}).\n",
        "$$\n",
        "\n",
        "The GNN <ins>model</ins> $f$ for graph-level prediction is **rotation** and **translation invariant** as follows:\n",
        "$$\n",
        "f(\\mathbf{H}, \\mathbf{X} \\ \\mathbf{Q} + \\mathbf{t}, \\mathbf{A}) = f(\\mathbf{H}, \\mathbf{X}, \\mathbf{A}).\n",
        "$$\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfOU10W1O729"
      },
      "source": [
        "## 💻**Task 2.2:** Write the unit test to check your `CoordMPNNModel` for 3D rotation and translation invariance. **(1.0 Mark)**\n",
        "\n",
        "\n",
        "🤔 *Hint: Show that the output of the model varies when:*\n",
        "1. All the atom coordinates in `data.pos` are multiplied by any random _orthogonal_ rotation matrix $Q \\in \\mathbb{R}^{3 \\times 3}$. (We have provided a helper function for creating rotation matrices.)\n",
        "2. All the atom coordinates in `data.pos` are displaced by any random translation vector $\\mathbf{t} \\in \\mathbb{R}^3$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C017NYCReaRy"
      },
      "outputs": [],
      "source": [
        "def random_orthogonal_matrix(dim=3):\n",
        "  \"\"\"Helper function to build a random orthogonal matrix of shape (dim, dim)\n",
        "  \"\"\"\n",
        "  Q = torch.tensor(ortho_group.rvs(dim=dim)).float()\n",
        "  return Q\n",
        "\n",
        "\n",
        "def rot_trans_invariance_unit_test(module, dataloader):\n",
        "    \"\"\"Unit test for checking whether a module (GNN model/layer) is\n",
        "    rotation and translation invariant.\n",
        "    \"\"\"\n",
        "    it = iter(dataloader)\n",
        "    data = next(it)\n",
        "\n",
        "    # Forward pass on original example\n",
        "    # Note: We have written a conditional forward pass so that the same unit\n",
        "    #       test can be used for both the GNN model as well as the layer.\n",
        "    #       The functionality for layers will be useful subsequently.\n",
        "    if isinstance(module, MPNNModel):\n",
        "        out_1 = module(data)\n",
        "    else: # if isinstance(module, MessagePassing):\n",
        "        out_1 = module(data.x, data.pos, data.edge_index, data.edge_attr)\n",
        "\n",
        "    Q = random_orthogonal_matrix(dim=3)\n",
        "    t = torch.rand(3)\n",
        "    # ============ YOUR CODE HERE ==============\n",
        "    # Perform random rotation + translation on data.\n",
        "    #\n",
        "    # data.pos = ...\n",
        "    # ==========================================\n",
        "\n",
        "    # Forward pass on rotated + translated example\n",
        "    if isinstance(module, MPNNModel):\n",
        "        out_2 = module(data)\n",
        "    else: # if isinstance(module, MessagePassing):\n",
        "        out_2 = module(data.x, data.pos, data.edge_index, data.edge_attr)\n",
        "\n",
        "    # ============ YOUR CODE HERE ==============\n",
        "    # Check whether output varies after applying transformations.\n",
        "    #\n",
        "    # return torch.allclose(..., atol=1e-04)\n",
        "    # =========================================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vBzfG3Kqh_5G"
      },
      "outputs": [],
      "source": [
        "# @title ✅ [RUN] **Please run this unit test to validate your code. The output would be used to mark your practical.**\n",
        "dataloader = DataLoader(train_pyg_dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "# Non-invariant unit test\n",
        "is_3D_invariant = rot_trans_invariance_unit_test(dummy_not_invariant, dataloader)\n",
        "assert not is_3D_invariant, \"🤔 Something is wrong in your unit test! It gave a false positive 🥺\"\n",
        "\n",
        "# Only Translational Invariant unit test\n",
        "is_3D_invariant = rot_trans_invariance_unit_test(dummy_only_trans_invariant, dataloader)\n",
        "assert not is_3D_invariant, \"🤔 Something is wrong in your unit test! Maybe you did not code a check for rotational invariance? 🥺\"\n",
        "\n",
        "# Only Rotational Invariant unit test\n",
        "is_3D_invariant = rot_trans_invariance_unit_test(dummy_only_rot_invariant, dataloader)\n",
        "assert not is_3D_invariant, \"🤔 Something is wrong in your unit test! Maybe you did not code a check for translational invariance? 🥺\"\n",
        "\n",
        "# Invariant unit test\n",
        "is_3D_invariant = rot_trans_invariance_unit_test(dummy_invariant, dataloader)\n",
        "assert is_3D_invariant, \"🤔 Something is wrong in your unit test! It gave a false negative 🥺\"\n",
        "\n",
        "print(\"✅ All seems good!!!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxVHYY_ahxrX"
      },
      "source": [
        "Now that you have defined the unit tests for rotation and translation invariance, perform the sanity check on your `CoordMPNNModel`. Before you run it, pause a moment to think - what result would you expect?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2Gv4m3ahcya"
      },
      "outputs": [],
      "source": [
        "# Instantiate temporary model, layer, and dataloader for unit testing\n",
        "model = CoordMPNNModel(num_layers=4, emb_dim=64, in_dim=11, edge_dim=4, out_dim=1)\n",
        "dataloader = DataLoader(train_pyg_dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "# Rotation and translation invariance unit test for MPNN model\n",
        "print(f\"Is {type(model).__name__} rotation and translation invariant? --> {rot_trans_invariance_unit_test(model, dataloader)}!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYqLfZpFj0Pf"
      },
      "source": [
        "(<font color = red> 🔴 Spoiler alert: the unit test should return `False` for the `CoordMPNNModel`.)\n",
        "\n",
        "In this part, you have formalised how a GNN can be 3D rotation and translation invariant, thought about why this is desirable for molecular property prediction, and shown that the `CoordMPNNModel` was not rotation and translation invariant.\n",
        "\n",
        "At this point, you should have a concrete understanding of why the performance of `CoordMPNNModel` is equal or worse than the vanilla `MPNNModel`, and what we meant by our initial statement before we began this part:\n",
        ">\"The `CoordMPNNModel` may not be using 3D structural information in the most principled manner\"\n",
        "\n",
        "Let us try fixing this in the next part!\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byXbNG9lGizB"
      },
      "source": [
        "## ✈️ Upgrading message Passing with Invariance to 3D Rotations and Translations\n",
        "\n",
        "This section will dive into how we may design GNN models which operate on graphs with 3D coordinates in a more theoretically sound way."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWceJ74iH7lV"
      },
      "source": [
        "## <font color = purple> 💻 **Task 2.3:** Design a new Message Passing Layer as well as the accompanying MPNN Model that are both <ins>invariant</ins> to 3D rotations and translations. Verify this using the unit test you coded. **(3 Marks)**\n",
        "\n",
        "**❗️ Note:** There are multiple ways to arrive at invariance, so there is no single correct answer to this question.\n",
        "\n",
        "Our initial **'vanilla' MPNN** `MPNNModel` and `MPNNLayer` ignored the atom coordinates and only uses the node features to perform message passing. This means that the model was **not** leveraging **3D structural information** to predict the target property.\n",
        "\n",
        "Our second **'naive' coordinate MPNN** `CoordMPNNModel` used the node features along with the atom coordinates in an unprincipled manner, resulting in the model not being invariant to 3D rotations and translations of the coordinates (which was a desirable property, as we saw in the previous part).\n",
        "\n",
        "Your task is to define a new `InvariantMPNNLayer` which utilise both **atom coordinates** and **node features**.\n",
        "\n",
        "We have defined most of the new `InvariantMPNNLayer`, and you have to fill in the `YOUR CODE HERE` sections. We have also already defined the `InvariantMPNNModel` that instantiates your new layer to compose the model. You only need to define the new layer.\n",
        "\n",
        "🤔 *Hint 1: Unlike the previous `CoordMPNNModel`, we would suggest using the coordinate information to construct the messages as opposed to incorporating it into the node features. In particular, we would like to urge you to think about **how** we can use the coordinates in a principled manner to construct the messages: What is a quantity (or if you find multiple, what are quantities) that we can compute using a pair of coordinates that will be invariant to rotating and translating the coordinates?*\n",
        "\n",
        "🤔 *Hint 2:  tensors passed to `propagate()` can be mapped to the respective nodes  and  by appending `_i` or `_j` to the variable name, e.g. `h_i` and `h_j` for the node features `h`. Note that we generally refer to `_i` as the central nodes that aggregates information, and refer to `_j` as the neighboring nodes.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZ2f0wOEK-Qx"
      },
      "outputs": [],
      "source": [
        "class InvariantMPNNLayer(MessagePassing):\n",
        "    def __init__(self, emb_dim=64, edge_dim=4, aggr='add'):\n",
        "        \"\"\"Message Passing Neural Network Layer\n",
        "\n",
        "        This layer is invariant to 3D rotations and translations.\n",
        "\n",
        "        Args:\n",
        "            emb_dim: (int) - hidden dimension `d`\n",
        "            edge_dim: (int) - edge feature dimension `d_e`\n",
        "            aggr: (str) - aggregation function `\\oplus` (sum/mean/max)\n",
        "        \"\"\"\n",
        "        # Set the aggregation function\n",
        "        super().__init__(aggr=aggr)\n",
        "\n",
        "        self.emb_dim = emb_dim\n",
        "        self.edge_dim = edge_dim\n",
        "\n",
        "        # ============ YOUR CODE HERE ==============\n",
        "        # MLP `\\psi` for computing messages `m_ij`\n",
        "        # dims: (???) -> d\n",
        "        #\n",
        "        # self.mlp_msg = Sequential(...)\n",
        "        # ==========================================\n",
        "\n",
        "        # MLP `\\phi` for computing updated node features `h_i^{l+1}`\n",
        "        # dims: 2d -> d\n",
        "        self.mlp_upd = Sequential(\n",
        "            Linear(2*emb_dim, emb_dim), BatchNorm1d(emb_dim), ReLU(),\n",
        "            Linear(emb_dim, emb_dim), BatchNorm1d(emb_dim), ReLU()\n",
        "          )\n",
        "\n",
        "    def forward(self, h, pos, edge_index, edge_attr):\n",
        "        \"\"\"\n",
        "        The forward pass updates node features `h` via one round of message passing.\n",
        "\n",
        "        Args:\n",
        "            h: (n, d) - initial node features\n",
        "            pos: (n, 3) - initial node coordinates\n",
        "            edge_index: (e, 2) - pairs of edges (i, j)\n",
        "            edge_attr: (e, d_e) - edge features\n",
        "\n",
        "        Returns:\n",
        "            out: (n, d) - updated node features\n",
        "        \"\"\"\n",
        "        # ============ YOUR CODE HERE ==============\n",
        "        # Notice that the `forward()` function has a new argument\n",
        "        # `pos` denoting the initial node coordinates. Your task is\n",
        "        # to update the `propagate()` function in order to pass `pos`\n",
        "        # to the `message()` function along with the other arguments.\n",
        "        #\n",
        "        # out = self.propagate(...)\n",
        "        # return out\n",
        "        # ==========================================\n",
        "\n",
        "    # ============ YOUR CODE HERE ==============\n",
        "    # Write a custom `message()` function that takes as arguments the\n",
        "    # source and destination node features, node coordinates, and `edge_attr`.\n",
        "    # Incorporate the coordinates `pos` into the message computation such\n",
        "    # that the messages are invariant to rotations and translations.\n",
        "    # This will ensure that the overall layer is also invariant.\n",
        "    #\n",
        "    # def message(self, ...):\n",
        "    # \"\"\"The `message()` function constructs messages from source nodes j\n",
        "    #    to destination nodes i for each edge (j, i) in `edge_index`.\n",
        "    #\n",
        "    #    Args:\n",
        "    #        ...\n",
        "    #\n",
        "    #    Returns:\n",
        "    #        ...\n",
        "    # \"\"\"\n",
        "    #   ...\n",
        "    #   msg = ...\n",
        "    #   return self.mlp_msg(msg)\n",
        "    # ==========================================\n",
        "\n",
        "    def aggregate(self, inputs, index):\n",
        "        \"\"\"The `aggregate` function aggregates the messages from neighboring nodes,\n",
        "        according to the chosen aggregation function ('sum' by default).\n",
        "\n",
        "        Args:\n",
        "            inputs: (e, d) - messages `m_ji` from source to destination nodes\n",
        "            index: (e, 1) - list of destination nodes for each edge/message in `input`\n",
        "\n",
        "        Returns:\n",
        "            aggr_out: (n, d) - aggregated messages `m_i`\n",
        "        \"\"\"\n",
        "        return scatter(inputs, index, dim=self.node_dim, reduce=self.aggr)\n",
        "\n",
        "    def update(self, aggr_out, h):\n",
        "        \"\"\"The `update()` function computes the final node features by combining the\n",
        "        aggregated messages with the initial node features.\n",
        "\n",
        "        Args:\n",
        "            aggr_out: (n, d) - aggregated messages `m_i`\n",
        "            h: (n, d) - initial node features\n",
        "\n",
        "        Returns:\n",
        "            upd_out: (n, d) - updated node features passed through MLP `\\phi`\n",
        "        \"\"\"\n",
        "        upd_out = torch.cat([h, aggr_out], dim=-1)\n",
        "        return self.mlp_upd(upd_out)\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return (f'{self.__class__.__name__}(emb_dim={self.emb_dim}, aggr={self.aggr})')\n",
        "\n",
        "\n",
        "class InvariantMPNNModel(MPNNModel):\n",
        "    def __init__(self, num_layers=4, emb_dim=64, in_dim=11, edge_dim=4, out_dim=1):\n",
        "        \"\"\"Message Passing Neural Network model for graph property prediction\n",
        "\n",
        "        This model uses both node features and coordinates as inputs, and\n",
        "        is invariant to 3D rotations and translations.\n",
        "\n",
        "        Args:\n",
        "            num_layers: (int) - number of message passing layers `L`\n",
        "            emb_dim: (int) - hidden dimension `d`\n",
        "            in_dim: (int) - initial node feature dimension `d_n`\n",
        "            edge_dim: (int) - edge feature dimension `d_e`\n",
        "            out_dim: (int) - output dimension (fixed to 1)\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        # Linear projection for initial node features\n",
        "        # dim: d_n -> d\n",
        "        self.lin_in = Linear(in_dim, emb_dim)\n",
        "\n",
        "        # Stack of invariant MPNN layers\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        for layer in range(num_layers):\n",
        "            self.convs.append(InvariantMPNNLayer(emb_dim, edge_dim, aggr='add'))\n",
        "\n",
        "        # Global pooling/readout function `R` (mean pooling)\n",
        "        # PyG handles the underlying logic via `global_mean_pool()`\n",
        "        self.pool = global_mean_pool\n",
        "\n",
        "        # Linear prediction head\n",
        "        # dim: d -> out_dim\n",
        "        self.lin_pred = Linear(emb_dim, out_dim)\n",
        "\n",
        "    def forward(self, data):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            data: (PyG.Data) - batch of PyG graphs\n",
        "\n",
        "        Returns:\n",
        "            out: (batch_size, out_dim) - prediction for each graph\n",
        "        \"\"\"\n",
        "        h = self.lin_in(data.x) # (n, d_n) -> (n, d)\n",
        "\n",
        "        for conv in self.convs:\n",
        "            h = h + conv(h, data.pos, data.edge_index, data.edge_attr) # (n, d) -> (n, d)\n",
        "            # Note that we add a residual connection after each MPNN layer\n",
        "\n",
        "        h_graph = self.pool(h, data.batch) # (n, d) -> (batch_size, d)\n",
        "\n",
        "        out = self.lin_pred(h_graph) # (batch_size, d) -> (batch_size, 1)\n",
        "\n",
        "        return out.view(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "epMyUUnaSolt"
      },
      "outputs": [],
      "source": [
        "# ============ YOUR CODE HERE ==============\n",
        "# Instantiate temporary model, layer, and dataloader for unit testing.\n",
        "# Remember that we are now unit testing the InvariantMPNNModel,\n",
        "# which is  composed of the InvariantMPNNLayer.\n",
        "#\n",
        "# layer = ...\n",
        "# model = ...\n",
        "# ==========================================\n",
        "dataloader = DataLoader(train_pyg_dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "# Rotation and translation invariance unit test for MPNN model\n",
        "print(f\"Is {type(model).__name__} rotation and translation invariant? --> {rot_trans_invariance_unit_test(model, dataloader)}!\")\n",
        "\n",
        "# Rotation and translation invariance unit test for MPNN layer\n",
        "print(f\"Is {type(layer).__name__} rotation and translation invariant? --> {rot_trans_invariance_unit_test(layer, dataloader)}!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzZzzY1sh_5I"
      },
      "outputs": [],
      "source": [
        "# @title ✅ [RUN] **Please run this unit test to validate your code. The output would be used to mark your practical.**\n",
        "\n",
        "# Permutation equivariance unit test for layer\n",
        "is_permutation_equivariant = permutation_equivariance_unit_test(layer, dataloader, with_pos=True)\n",
        "assert is_permutation_equivariant, \"🤔 Something is wrong in the layer! Your layer is not permutation equivariant 🥺\"\n",
        "\n",
        "# 3D Invariance unit test for layer\n",
        "is_rot_trans_invariant = rot_trans_invariance_unit_test(layer, dataloader)\n",
        "assert is_rot_trans_invariant, \"🤔 Something is wrong in the layer! Your layer is not rotation and translation invariant 🥺\"\n",
        "\n",
        "# 3D Invariance unit test for model\n",
        "is_rot_trans_invariant = rot_trans_invariance_unit_test(model, dataloader)\n",
        "assert is_rot_trans_invariant, \"🤔 Something is wrong in the model! Your model is not rotation and translation invariant 🥺\"\n",
        "\n",
        "layer = InvariantMPNNLayer(emb_dim=1, edge_dim=1).eval()\n",
        "\n",
        "# Setting all weights and biases to positive to avoid all outputs becoming 0 due to ReLU\n",
        "layer = layer.requires_grad_(False)\n",
        "for p in layer.parameters():\n",
        "    torch.abs(p, out=p)\n",
        "\n",
        "outs = torch.concatenate(\n",
        "    [\n",
        "        layer(dummy_data.x, dummy_data.pos, dummy_data.edge_index, dummy_data.edge_attr)\n",
        "        for dummy_data in get_dummy_data()\n",
        "    ]\n",
        ")\n",
        "are_all_equal = torch.all(outs == outs[0])\n",
        "\n",
        "assert not are_all_equal, \"🤔 Something is wrong in the model! Your model is not using the positional information 🥺\"\n",
        "\n",
        "print(\"✅ All seems good!!!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqcJy1HtPgj6"
      },
      "source": [
        "Super! You have now defined a more geometrically principled message passing layer and used it to construct an MPNN model with is invariant to 3D rotations and translations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qx5XBblEryId"
      },
      "source": [
        "It is finally time to run an experiment with our geometrically principled model!\n",
        "\n",
        "## <font color = blue> 💻 [OPTIONAL] Train and evaluate your `InvariantMPNNModel`. Additionally, provide a few sentences explaining the model's results compared to the basic `MPNNModel` and the naive `CoordMPNNModel` defined previously. Is the new model visibly better?\n",
        "\n",
        "Re-use the experiment loop we have provided and fill in the `YOUR CODE HERE` sections to run the experiment.\n",
        "\n",
        "You will be training an `InvariantMPNNModel` consisting of 4 layers of message passing with a hidden dimension of 64, in order to compare your result fairly to the previous vanilla `MPNNModel` and naive `CoordMPNNModel`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDOR0aYRshZW"
      },
      "outputs": [],
      "source": [
        "# ============ YOUR CODE HERE ==============\n",
        "# Instantiate your InvariantMPNNModel with the appropriate arguments.\n",
        "#\n",
        "# model = InvariantMPNNModel(...)\n",
        "# ==========================================\n",
        "\n",
        "model_name = type(model).__name__\n",
        "best_val_error, test_error, train_time, perf_per_epoch = run_experiment(\n",
        "    model,\n",
        "    model_name, # \"MPNN w/ Features and Coordinates (Invariant Layers)\",\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    test_loader,\n",
        "    n_epochs=100\n",
        ")\n",
        "\n",
        "RESULTS[model_name] = (best_val_error, test_error, train_time)\n",
        "df_temp = pd.DataFrame(perf_per_epoch, columns=[\"Test MAE\", \"Val MAE\", \"Epoch\", \"Model\"])\n",
        "DF_RESULTS = DF_RESULTS.append(df_temp, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2A0UoiyawMqw"
      },
      "outputs": [],
      "source": [
        "RESULTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-eJEGsolyHBN"
      },
      "outputs": [],
      "source": [
        "p = sns.lineplot(x=\"Epoch\", y=\"Val MAE\", hue=\"Model\", data=DF_RESULTS)\n",
        "p.set(ylim=(0, 2));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fnkXCeabtk4a"
      },
      "outputs": [],
      "source": [
        "p = sns.lineplot(x=\"Epoch\", y=\"Test MAE\", hue=\"Model\", data=DF_RESULTS)\n",
        "p.set(ylim=(0, 1));"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9C1XPXAf_Tsx"
      },
      "source": [
        "Awesome! We have now gone from a vanilla `MPNNModel`, to a naive use of coordinate information in `CoordMPNNModel`, to a more geometrically principled approach in `InvariantMPNN` model.\n",
        "\n",
        "In the next part, we will try to further push the limits of how much information we can derive from the geometry of molecules!\n",
        "\n",
        "---\n",
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3abj3akCFcp"
      },
      "source": [
        "# 🚀 Message Passing with Equivariance to 3D Rotations and Translations\n",
        "\n",
        "In the previous part of the practical, we studied the concepts of **3D rotation** and **translation** invariance. Now, we will go one step further. We will consider a GNN for molecular property prediction that is composed of message passing layers that are **equivariant** to 3D rotations and translations.\n",
        "\n",
        "But why...you may ask.\n",
        "\n",
        "In order to motivate the need for geometric equivariance and symmetries, we would like to take you back to the notion of permutation symmetries in GNNs for graphs, as well as translation symmetries in ConvNets for 2D images.\n",
        "\n",
        "### Permutation Symmetry in GNNs vs. DeepSets\n",
        "\n",
        "Earlier in the practical, we reviewed the concept of **permutation invariance** and **equivariance**. Fundamentally, a GNN layer must be a permutation <ins>equivariant</ins> operation on the graph nodes, i.e. changing the node ordering of the graph results in the same permutation applied to the node outputs of the layer. However, the overall GNN model for graph-level property prediction is still a **permutation <ins>invariant</ins>** function on the graph nodes, i.e. changing the node ordering does not impact the predicted graph property.\n",
        "\n",
        "Recall from the lectures that the **[DeepSets model](https://arxiv.org/abs/1703.06114)** is yet another permutation <ins>invariant</ins> architecture over sets of nodes, and is a perfectly reasonable option for predicting graph-level properties (which are also permutation invariant, as we just stated). This raises a critical question: **why did we build permutation <ins>invariant</ins> GNN models composed of permutation <ins>equivariant</ins> GNN layers?**\n",
        "\n",
        "One line of thinking is that permutation <ins>equivariant</ins> GNN layers enable the model to better leverage the **relational structure** of the underlying nodes, as well as construct more powerful node representations by **stacking several layers** of these permutation <ins>equivariant</ins> operations. (You can try running a DeepSets model for QM9 yourself and see the performance drop.)\n",
        "\n",
        "Now, consider the same analogy for 3D rotation and translation symmetries for your molecular property prediction models. Consider your `InvariantMPNNModel` so far -- it is composed of `InvariantMPNNLayer` which are merely <ins>invariant</ins> to 3D rotations and translations.\n",
        "By definition, applying these layers loses geometric information related to orientation or positioning (as this is precisely the type of information that is *not* invariant, but rather transforms covariantly with 3D transformations of the system).\n",
        "\n",
        "Analogous to how permutation <ins>equivariant</ins> layer enabled GNNs to leverage relational structure in a more principled manner, a **3D rotation** and **translation <ins>equivariant</ins> layer** may enable your model to **leverage geometric structure** in a more principled manner, too.\n",
        "For instance, equivariant layers may enable models to reason about how various sub-structures in molecules are spatially oriented w.r.t. one-another.\n",
        "Solving such equivariant sub-tasks can often be critical for solving an overall invariant task.\n",
        "\n",
        "Pablo Picasso's famous abstract protraits are a great way to motivate geometric equivariance:\n",
        "<img src=\"https://drive.google.com/uc?id=1HNd850TrZlnWKraDi2HeGKP_x9PehEpN\" width=\"100%\">\n",
        "\n",
        "### Translation Symmetry in ConvNets for 2D Images\n",
        "\n",
        "Yet another example where <ins>invariant</ins> models are composed of <ins>equivariant</ins> layers is the ubiquitous **Convolutional Neural Network** for 2D images.\n",
        "The ConvNet model is <ins>invariant</ins> to **translations**, in the sense that it will detect a cat in an image, regardless of where the cat is positioned in the image.\n",
        "\n",
        "Importantly, the ConvNet is composed of **convolution filters** which are akin to sliding a rectangular window over the input image. Convolution filters are matching low level patterns within the image. Intuitively, one of these filters may be a cat detection filter, in that it will fire whenever it comes across cat-like pixels. Thus, convolution filters are translation <ins>equivariant</ins> functions since their output translates along with their input.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1vgTAG_n5r3H2nqo5vaZPyC60hbZMTEkN\" width=\"100%\">\n",
        "\n",
        "([Source](https://bernhard-kainz.com/))\n",
        "\n",
        "Translation <ins>invariant</ins> ConvNets are composed of translation <ins>equivariant</ins> convolution filters in order to build **hierarchical features** across multiple layers. Stacking deep ConvNets enables the features across layers to interact in a **compositional** manner and enables the overall network to learn increasingly **complex visual concepts**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yO7iwRjvDD16"
      },
      "source": [
        "### Formalism\n",
        "\n",
        "Hopefully, we have sufficiently motivated the need for 3D rotation and translation equivariant GNN layers. Let us now try to formalise the notion of equivariance to 3D rotations and translations via matrix notation.\n",
        "\n",
        "- Let $\\mathbf{H} \\in \\mathbb{R}^{n \\times d}$ be a matrix of node features for a given molecular graph, where $n$ is the number of nodes/atoms and each row $h_i$ is the $d$-dimensional feature for node $i$.\n",
        "- Let $\\mathbf{X} \\in \\mathbb{R}^{n \\times 3}$ be a matrix of node coordinates for a given molecular graph, where $n$ is the number of nodes/atoms and each row $x_i$ is the 3D coordinate for node $i$.\n",
        "- Let $\\mathbf{A} \\in \\mathbb{R}^{n \\times n}$ be the adjacency matrix where each entry denotes $a_{ij}$ the presence or absence of an edge between nodes $i$ and $j$.\n",
        "- Let $\\mathbf{F}(\\mathbf{H}, \\mathbf{X}, \\mathbf{A}): \\mathbb{R}^{n \\times d} \\times \\mathbb{R}^{n \\times 3} \\times \\mathbb{R}^{n \\times n} \\rightarrow \\mathbb{R}^{n \\times d}\\times \\mathbb{R}^{n \\times 3}$ be a **GNN <ins>layer**</ins> that takes as input the node features, node coordinates, and adjacency matrix, and returns the **updated node features** as well as **updated node coordinates**.\n",
        "- Let $f(\\mathbf{H}, \\mathbf{X}, \\mathbf{A}): \\mathbb{R}^{n \\times d} \\times \\mathbb{R}^{n \\times 3} \\times \\mathbb{R}^{n \\times n} \\rightarrow \\mathbb{R}$ be a **GNN <ins>model**</ins> that takes as input the node features, node coordinates, and adjacency matrix, and returns the **predicted graph-level property**.\n",
        "\n",
        "Our GNN <ins>model</ins> $f(\\mathbf{H}, \\mathbf{X}, \\mathbf{A})$ is composed of multiple rotation and translation equivariant GNN <ins>layers</ins> $\\mathbf{F}^{\\ell}(\\mathbf{H}^{\\ell}, \\mathbf{X}^{\\ell}, \\mathbf{A}), \\ell = 1, 2, \\dots, L$.\n",
        "\n",
        "### How is this different from Geometrically Invariant Message Passing?\n",
        "\n",
        "Importantly, and in contrast to rotation and translation invariant message passing layers, each round of equivariant message passing updates both the **node features** as well as the **node coordinates**:\n",
        "$$\n",
        "\\mathbf{H}^{\\ell+1}, \\mathbf{X}^{\\ell+1} = \\mathbf{F}^{\\ell} (\\mathbf{H}^{\\ell}, \\mathbf{X}^{\\ell}, \\mathbf{A}).\n",
        "$$\n",
        "\n",
        "Such a formulation is highly beneficial for GNNs to learn useful node features in settings where we are modelling a **dynamical system** and have reason to believe that the node coordinates are continuously being updated, e.g. by the action of **intermolecular forces**.\n",
        "\n",
        "Do note the following nuances about geometrically equivariant message passing layers $\\mathbf{F}$:\n",
        "- The updated **node coordinates** $\\mathbf{X'}$ are **equivariant** to 3D rotations and translations of the input coordinates $\\mathbf{X}$.\n",
        "- The updated **node features** $\\mathbf{H'}$ are still **invariant** to 3D rotations and translations of the input coordinates $\\mathbf{X}$ (similar to the geometrically invariant message passing layer).\n",
        "- The overall **MPNN model** $f$ will still be **invariant** to 3D rotations and translations. This is because we are predicting a **single scalar quantity** (the electric dipole moment) per molecule, which remains unchanged under any rotations and translations of the atoms' coordinates. Thus, the final node feature vectors after $L$ layers of message passing are aggregated into a graph embedding (and the final node coordinates are ignored). The graph embedding is then used to predict the target.\n",
        "\n",
        "The following figure aims to succinctly capture these nuances about geometrically equivariant message passing layers $\\mathbf{F}$ which are used to compose a geometrically invariant GNN $\\mathbf{f}$:\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1rRsjM8AdxiU-uJ7C5t1JDMkC19QKdGPg\" width=\"100%\">\n",
        "\n",
        "What we want you to investigate in this part is how we may improve a **GNN model** that is **invariant** to 3D rotations and translations by using **message passing layers** that are **equivariant** to these **3D symmetries**.\n",
        "\n",
        "Let us get started!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-az-clhTLLv"
      },
      "source": [
        "### The GNN <ins>layer</ins> $\\mathbf{F}$ is equivariant to 3D rotations and translations. Let's express this mathematically using the definitions above.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJ5uZz67020U"
      },
      "source": [
        "\n",
        "Let us define an orthogonal rotation matrix $\\mathbf{Q} \\in \\mathbb{R}^{3 \\times 3}$ and translation vector $\\mathbf{t} \\in \\mathbb{R}^3$.\n",
        "\n",
        "\n",
        "The GNN layer $\\mathbf{F}$ is **rotation** and **translation equivariant** as follows:\n",
        "$$\n",
        "\\mathbf{F}(\\mathbf{H}, \\mathbf{X} \\ \\mathbf{Q} + \\mathbf{t}, \\mathbf{A}) = \\mathbf{Q} \\ \\mathbf{F}(\\mathbf{H}, \\mathbf{X}, \\mathbf{A}) + \\mathbf{t}.\n",
        "$$\n",
        "\n",
        "\n",
        "Another way to formulate the above could be: (1) Consider the updated node features and coordinates $\\mathbf{H'}, \\mathbf{X'} = \\mathbf{F}(\\mathbf{H}, \\mathbf{X}, \\mathbf{A})$. (2) Applying any rotation matrix $\\mathbf{Q}$ and translation vector $\\mathbf{t}$ to the input coordinates $\\mathbf{X}$ of the GNN layer $\\mathbf{F}$ should produce the same result as applying the same transformations on the updated coordinates $\\mathbf{X'}$:\n",
        "$$\n",
        "\\mathbf{F}(\\mathbf{H}, \\mathbf{X} \\ \\mathbf{Q} + \\mathbf{t}, \\mathbf{A}) = \\mathbf{H'}, \\mathbf{Q} \\ \\mathbf{X'} + \\mathbf{t}.\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xp4sViNah_5K"
      },
      "source": [
        "Before we code up an equivariant layer, we will first write a unit test (like all good programmers 😄).\n",
        "\n",
        "## <font color = purple> 💻 **Task 2.4:** Write a unit test for 3D rotation and translation equivariance for a GNN layer. **(1.0 Mark)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jW0FATN-P6CJ"
      },
      "outputs": [],
      "source": [
        "def rot_trans_equivariance_unit_test(module, dataloader):\n",
        "    \"\"\"Unit test for checking whether a module (GNN layer) is\n",
        "    rotation and translation equivariant.\n",
        "\n",
        "    module returns a tuple -- updated features and updated positions.\n",
        "    \"\"\"\n",
        "    it = iter(dataloader)\n",
        "    data = next(it)\n",
        "\n",
        "    out_1, pos_1 = module(data.x, data.pos, data.edge_index, data.edge_attr)\n",
        "\n",
        "    Q = random_orthogonal_matrix(dim=3)\n",
        "    t = torch.rand(3)\n",
        "    # ============ YOUR CODE HERE ==============\n",
        "    # Perform random rotation + translation on data.\n",
        "    #\n",
        "    # data.pos = ...\n",
        "    # ==========================================\n",
        "\n",
        "    # Forward pass on rotated + translated example\n",
        "    out_2, pos_2 = module(data.x, data.pos, data.edge_index, data.edge_attr)\n",
        "\n",
        "    # ============ YOUR CODE HERE ==============\n",
        "    # Check whether output varies after applying transformations.\n",
        "    # return ...\n",
        "    # =========================================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7ro5omih_5K"
      },
      "outputs": [],
      "source": [
        "# @title ✅ [RUN] **Please run this unit test to validate your code. The output would be used to mark your practical.**\n",
        "dataloader = DataLoader(train_pyg_dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "# Non-Equivariant unit test\n",
        "is_3D_equivariant = rot_trans_equivariance_unit_test(dummy_not_equivariant, dataloader)\n",
        "assert not is_3D_equivariant, \"🤔 Something is wrong in your unit test! It gave a false positive 🥺\"\n",
        "\n",
        "# Node Features not invariant unit test\n",
        "is_3D_equivariant = rot_trans_equivariance_unit_test(dummy_h_not_invariant, dataloader)\n",
        "assert not is_3D_equivariant, \"🤔 Something is wrong in your unit test! Maybe you did not code a check for invariance of node features? 🥺\"\n",
        "\n",
        "# Only Translation Invariant Features unit test\n",
        "is_3D_equivariant = rot_trans_equivariance_unit_test(dummy_h_only_trans_invariant, dataloader)\n",
        "assert not is_3D_equivariant, \"🤔 Something is wrong in your unit test! Maybe you did not code a check for rotational invariance of node features? 🥺\"\n",
        "\n",
        "# Only Rotational Invariant Features unit test\n",
        "is_3D_equivariant = rot_trans_equivariance_unit_test(dummy_h_only_rot_invariant, dataloader)\n",
        "assert not is_3D_equivariant, \"🤔 Something is wrong in your unit test! Maybe you did not code a check for translational invariance of node features? 🥺\"\n",
        "\n",
        "# Node Positions not invariant unit test\n",
        "is_3D_equivariant = rot_trans_equivariance_unit_test(dummy_x_not_equivariant, dataloader)\n",
        "assert not is_3D_equivariant, \"🤔 Something is wrong in your unit test! Maybe you did not code a check for equivariance of node positions? 🥺\"\n",
        "\n",
        "# Only Translation Equivariant Positions unit test\n",
        "is_3D_equivariant = rot_trans_equivariance_unit_test(dummy_x_only_trans_equivariant, dataloader)\n",
        "assert not is_3D_equivariant, \"🤔 Something is wrong in your unit test! Maybe you did not code a check for rotational equivariance of node positions? 🥺\"\n",
        "\n",
        "# Only Rotational Equivariant Positions unit test\n",
        "is_3D_equivariant = rot_trans_equivariance_unit_test(dummy_x_only_rot_equivariant, dataloader)\n",
        "assert not is_3D_equivariant, \"🤔 Something is wrong in your unit test! Maybe you did not code a check for translational equivariance of node positions? 🥺\"\n",
        "\n",
        "# Equivariant unit test\n",
        "is_3D_equivariant = rot_trans_equivariance_unit_test(dummy_equivariant, dataloader)\n",
        "assert is_3D_equivariant, \"🤔 Something is wrong in your unit test! It gave a false negative 🥺\"\n",
        "\n",
        "print(\"✅ All seems good!!!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPMwl3y1C-LD"
      },
      "source": [
        "## <font color = purple> 💻 **Task 2.5:** Design a new Message Passing Layer that is <ins>equivariant</ins> to 3D rotations and translations. Verify the equivariance of your layer and invariance of the resulting model using your unit test. **(3.0 Marks)**\n",
        "\n",
        "🤔 *Hint 1: To ensure equivariance to 3D rotations and translations, your message passing layer should now update both the node features as well as the node coordinates. This means that each of the `message()`, `aggregate()`, and `update()` functions will be passing around a tuple of outputs, consisting of the node features and node coordinates.*\n",
        "\n",
        "🤔 *Hint 2: Certain quantities that can be computed among a pair of node coordinates do not change when the coordinates are rotated or translated -- these are **invariant quantities**. On the other hand, certain quantities may rotate or translate along with the coordinates -- these are **equivariant quantities**. We want you to think about how you can set up the message passing in a way that messages for the node feature updates are <ins>invariant</ins> to 3D rotations and translations, while messages for the node coordinates are <ins>equivariant</ins> to the same.*\n",
        "\n",
        "**❗️Note:** This task has multiple possible approaches for achieving. Directly importing or copying implementations from PyG will not be accepted as a valid answer.\n",
        "\n",
        "**❗️Note:** The trivial solution $\\mathbf{X}^{\\ell+1} = \\mathbf{X}^{\\ell}$ will not be accepted as a valid answer. A general intuition about GNNs is that each node learns how to **borrow information** from its neighbours — here, this holds true for both node feature information as well as node coordinate information. Thus, we want you to use message passing to update the node coordinates by aggregating from the node coordinates of the neighbours. The ‘game’ here is about how to design a learnable message function for the coordinates such that it is equivariant to 3D symmetries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oKraX_u9MXCS"
      },
      "outputs": [],
      "source": [
        "class EquivariantMPNNLayer(MessagePassing):\n",
        "    def __init__(self, emb_dim=64, edge_dim=4, aggr='add'):\n",
        "        \"\"\"Message Passing Neural Network Layer\n",
        "\n",
        "        This layer is equivariant to 3D rotations and translations.\n",
        "\n",
        "        Args:\n",
        "            emb_dim: (int) - hidden dimension `d`\n",
        "            edge_dim: (int) - edge feature dimension `d_e`\n",
        "            aggr: (str) - aggregation function `\\oplus` (sum/mean/max)\n",
        "        \"\"\"\n",
        "        # Set the aggregation function\n",
        "        super().__init__(aggr=aggr)\n",
        "\n",
        "        self.emb_dim = emb_dim\n",
        "        self.edge_dim = edge_dim\n",
        "\n",
        "        # ============ YOUR CODE HERE ==============\n",
        "        # Define the MLPs constituting your new layer.\n",
        "        # At the least, you will need `\\psi` and `\\phi`\n",
        "        # (but their definitions may be different from what\n",
        "        # we used previously).\n",
        "        #\n",
        "        # self.mlp_msg = ...  # MLP `\\psi`\n",
        "\n",
        "        # MLP `\\psi` for computing messages `m_ij`\n",
        "        # dims: d -> 1\n",
        "        # self.mlp_pos = ...\n",
        "\n",
        "        # MLP `\\phi` for computing updated node features `h_i^{l+1}`\n",
        "        # dims: 2d -> d\n",
        "        # self.mlp_upd = ...\n",
        "        # ===========================================\n",
        "\n",
        "    def forward(self, h, pos, edge_index, edge_attr):\n",
        "        \"\"\"\n",
        "        The forward pass updates node features `h` via one round of message passing.\n",
        "\n",
        "        Args:\n",
        "            h: (n, d) - initial node features\n",
        "            pos: (n, 3) - initial node coordinates\n",
        "            edge_index: (e, 2) - pairs of edges (i, j)\n",
        "            edge_attr: (e, d_e) - edge features\n",
        "\n",
        "        Returns:\n",
        "            out: [(n, d),(n,3)] - updated node features\n",
        "        \"\"\"\n",
        "        # ============ YOUR CODE HERE ==============\n",
        "        # Notice that the `forward()` function has a new argument\n",
        "        # `pos` denoting the initial node coordinates. Your task is\n",
        "        # to update the `propagate()` function in order to pass `pos`\n",
        "        # to the `message()` function along with the other arguments.\n",
        "        #\n",
        "        # out = self.propagate(...)\n",
        "        # return out\n",
        "        # ==========================================\n",
        "\n",
        "    # ============ YOUR CODE HERE ==============\n",
        "    # Write custom `message()`, `aggregate()`, and `update()` functions\n",
        "    # which ensure that the layer is 3D rotation and translation equivariant.\n",
        "    #\n",
        "    # def message(self, ...):\n",
        "    #   ...\n",
        "    #\n",
        "    # def aggregate(self, ...):\n",
        "    #   ...\n",
        "    #\n",
        "    # def update(self, ...):\n",
        "    #   ...\n",
        "    #\n",
        "    # ==========================================\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return (f'{self.__class__.__name__}(emb_dim={self.emb_dim}, aggr={self.aggr})')\n",
        "\n",
        "\n",
        "class FinalMPNNModel(MPNNModel):\n",
        "    def __init__(self, num_layers=4, emb_dim=64, in_dim=11, edge_dim=4, out_dim=1):\n",
        "        \"\"\"Message Passing Neural Network model for graph property prediction\n",
        "\n",
        "        This model uses both node features and coordinates as inputs, and\n",
        "        is invariant to 3D rotations and translations (the constituent MPNN layers\n",
        "        are equivariant to 3D rotations and translations).\n",
        "\n",
        "        Args:\n",
        "            num_layers: (int) - number of message passing layers `L`\n",
        "            emb_dim: (int) - hidden dimension `d`\n",
        "            in_dim: (int) - initial node feature dimension `d_n`\n",
        "            edge_dim: (int) - edge feature dimension `d_e`\n",
        "            out_dim: (int) - output dimension (fixed to 1)\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        # Linear projection for initial node features\n",
        "        # dim: d_n -> d\n",
        "        self.lin_in = Linear(in_dim, emb_dim)\n",
        "\n",
        "        # Stack of MPNN layers\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        for layer in range(num_layers):\n",
        "            self.convs.append(EquivariantMPNNLayer(emb_dim, edge_dim, aggr='add'))\n",
        "\n",
        "        # Global pooling/readout function `R` (mean pooling)\n",
        "        # PyG handles the underlying logic via `global_mean_pool()`\n",
        "        self.pool = global_mean_pool\n",
        "\n",
        "        # Linear prediction head\n",
        "        # dim: d -> out_dim\n",
        "        self.lin_pred = Linear(emb_dim, out_dim)\n",
        "\n",
        "    def forward(self, data):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            data: (PyG.Data) - batch of PyG graphs\n",
        "\n",
        "        Returns:\n",
        "            out: (batch_size, out_dim) - prediction for each graph\n",
        "        \"\"\"\n",
        "        h = self.lin_in(data.x) # (n, d_n) -> (n, d)\n",
        "        pos = data.pos\n",
        "\n",
        "        for conv in self.convs:\n",
        "            # Message passing layer\n",
        "            h_update, pos_update = conv(h, pos, data.edge_index, data.edge_attr)\n",
        "\n",
        "            # Update node features\n",
        "            h = h + h_update # (n, d) -> (n, d)\n",
        "            # Note that we add a residual connection after each MPNN layer\n",
        "\n",
        "            # Update node coordinates\n",
        "            pos = pos_update # (n, 3) -> (n, 3)\n",
        "\n",
        "        h_graph = self.pool(h, data.batch) # (n, d) -> (batch_size, d)\n",
        "\n",
        "        out = self.lin_pred(h_graph) # (batch_size, d) -> (batch_size, 1)\n",
        "\n",
        "        return out.view(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hgxcp6WpP6OF"
      },
      "outputs": [],
      "source": [
        "# ============ YOUR CODE HERE ==============\n",
        "# Instantiate temporary model, layer, and dataloader for unit testing.\n",
        "# Remember that we are now unit testing the FinalMPNNModel,\n",
        "# which is composed of the EquivariantMPNNLayer.\n",
        "#\n",
        "# layer = ...\n",
        "# model = ...\n",
        "# ==========================================\n",
        "dataloader = DataLoader(train_pyg_dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "# Rotation and translation invariance unit test for model\n",
        "is_rot_trans_invariant = rot_trans_invariance_unit_test(model, dataloader)\n",
        "print(f\"Is {type(model).__name__} rotation and translation invariant? --> {is_rot_trans_invariant}!\")\n",
        "\n",
        "# Rotation and translation equivariance unit test for layer\n",
        "is_rot_trans_equivariant = rot_trans_equivariance_unit_test(layer, dataloader)\n",
        "print(f\"Is {type(layer).__name__} rotation and translation equivariant? --> {is_rot_trans_equivariant}!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3Oqt8grl280"
      },
      "outputs": [],
      "source": [
        "# @title ✅ [RUN] **Please run this unit test to validate your code. The output would be used to mark your practical.**\n",
        "assert is_rot_trans_invariant, \"🤔 Something is wrong in the model! Your model is not rotation and translation invariant 🥺\"\n",
        "assert is_rot_trans_equivariant, \"🤔 Something is wrong in the layer! Your layer is not rotation and translation equivariant 🥺\"\n",
        "\n",
        "print(\"✅ All seems good!!!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Xo7x-U2DH-8"
      },
      "source": [
        "Awesome! You have now defined a new message passing layer that is equivariant to 3D rotations and translations, and used it to construct your final MPNN model for molecular property prediction.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUdwCBgiDl3t"
      },
      "source": [
        "It is finally time to run an experiment with our final geometrically principled model!\n",
        "\n",
        "## <font color = blue> 💻 [OPTIONAL] Train and evaluate your `FinalMPNNModel`. Additionally, provide a few sentences explaining the model's results compared to the basic `MPNNModel`, the naive `CoordMPNNModel`, and the `InvariantMPNNModel` defined previously. Is the new model better? By a significant margin or only minorly better?\n",
        "\n",
        "Re-use the experiment loop we have provided and fill in the `YOUR CODE HERE` sections to run the experiment.\n",
        "\n",
        "You will be training an `EquivariantMPNNModel` consisting of 4 layers of message passing with a hidden dimension of 64, in order to compare your result fairly to the previous vanilla `MPNNModel`, naive `CoordMPNNModel`, and `InvariantMPNNModel`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lIm8C-4wRVpd"
      },
      "outputs": [],
      "source": [
        "# ============ YOUR CODE HERE ==============\n",
        "# Instantiate your FinalMPNNModel with the appropriate arguments.\n",
        "#\n",
        "# model = FinalMPNNModel(...)\n",
        "# ==========================================\n",
        "\n",
        "model_name = type(model).__name__\n",
        "best_val_error, test_error, train_time, perf_per_epoch = run_experiment(\n",
        "    model,\n",
        "    model_name, # \"MPNN w/ Features and Coordinates (Equivariant Layers)\",\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    test_loader,\n",
        "    n_epochs=100\n",
        ")\n",
        "\n",
        "RESULTS[model_name] = (best_val_error, test_error, train_time)\n",
        "df_temp = pd.DataFrame(perf_per_epoch, columns=[\"Test MAE\", \"Val MAE\", \"Epoch\", \"Model\"])\n",
        "DF_RESULTS = DF_RESULTS.append(df_temp, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Ai6EhSASjP5"
      },
      "outputs": [],
      "source": [
        "RESULTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sGjNj20A0JcO"
      },
      "outputs": [],
      "source": [
        "p = sns.lineplot(x=\"Epoch\", y=\"Val MAE\", hue=\"Model\", data=DF_RESULTS)\n",
        "p.set(ylim=(0, 2));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xZFggF9ulrT"
      },
      "outputs": [],
      "source": [
        "p = sns.lineplot(x=\"Epoch\", y=\"Test MAE\", hue=\"Model\", data=DF_RESULTS)\n",
        "p.set(ylim=(0, 1));"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_n4dNz1UVpj"
      },
      "source": [
        "---\n",
        "\n",
        "<font color='red'>❗️YOUR ANSWER HERE</font>\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SyqO97bUZpS"
      },
      "source": [
        "Congratulations! You have now gone from a vanilla `MPNNModel`, to a naive use of coordinate information in `CoordMPNNModel`, to a more geometrically principled approach in `InvariantMPNNModel`, and finally arrived at `FinalMPNNModel`, a **GNN that is invariant** to 3D rotations and translations while consisting of **message passing layers that are equivariant** to these 3D symmetries.\n",
        "\n",
        "In the next parts, we will compare these models under two different settings.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uO-84rI6Exu5"
      },
      "source": [
        "## 🌯 [Extra Content] Wrapping up\n",
        "\n",
        "Let's wrap up the practical by analysing two important aspects of the models that we have studied so far: **the why of invariance and equivariance** and choice of **graph structure**.\n",
        "\n",
        "❗️**Note:** Ideally, **you do not need to write any new code** for the tasks in this part. You are only required to run the cells in the notebook and infer the empirical results that you see. This is an exercise to simulate how you may need to infer tables and figures when reading or writing your own research papers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLbfIuHMQBep"
      },
      "source": [
        "Let us take a moment to think about why invariance to 3D rotations and translations is something desirable (or undesirable) for geometric GNNs (GNNs in 3D space)...\n",
        "\n",
        "- As molecular properties are invariant to 3D rotations and translations, a GNN model for predicting molecular properties should also be invariant to them.\n",
        "- Ideally, one should **align domain-specific inductive biases**  to the inductive biases built into model architectures. We've seen that doing so not only improves performance, but also leads to improved data efficiency (seen in things such as requiring fewer epochs to converge, as well as convergence to a lower training loss and validation set MAE).\n",
        "\n",
        "On the flip side:\n",
        "- Invariance / equivariance might be a bad idea when we deal with 3D rotations in a space with an ambient force, such as gravity or an electromagnetic field. Intermediate equivariance might be a good idea even if the downstream label is invariant (e.g. predicting a molecular property (invariant) may require reasoning about the forces between the atoms (equivariant)).\n",
        "- Besides architecture design, there could be other approaches for developing (approximately) equivariant models. For instance, data augmentation or symmetry-promoting loss functions are simple and popular approach that may be more scalable as they do not necessitate a restricted set of operations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04WVO1Mnukdm"
      },
      "source": [
        "### Dense vs. Sparse Graphs\n",
        "\n",
        "Now, let's turn our attention to the choice of the **underlying graph structure**.\n",
        "\n",
        "In this practical we have been using sparse adjacency matrices to represent molecules (i.e. atoms are connected only if there exists a physical connection between them). Note, however, that we can create a **fully-connected** graph (i.e. all atoms in a molecule are connected to each other, except self-loops). In this case, the information about the molecule structures are available to the model through the edge features (`data.edge_attr`) as follows:\n",
        "- When two atoms are physically connected, the edge attributes indicate the **bond type** (single, double, triple, or aromatic) through a one-hot vector.\n",
        "- When two atoms are **not** physically connected, **all edge attributes** are **zero**.\n",
        "\n",
        "In the following task, we will study the advantages/downsides of fully-connected adjacency matrices versus sparse adjacency matrices."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bHtpzJlMqrC"
      },
      "source": [
        "## <font color = blue> 💻 [OPTIONAL] Compare the models' performance in the two scenarios (fully-connected versus sparse graphs). Explain your findings.\n",
        "\n",
        "The code to load datasets in the fully-connected format is provided to you. You may need to wait for some time to let all the models finish training with the fully-connected format.\n",
        "\n",
        "Grab a coffee/tea! ☕️\n",
        "\n",
        "**❗️Note:** Once again, it is highly encouraged that you attempt this task even if you have not been successful in implementing all of the models in the practical. Just answer based on the models you did understand and implement!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KCXierFguw7b"
      },
      "outputs": [],
      "source": [
        "# Load QM9 dataset with dense graphs\n",
        "\n",
        "# Transforms which are applied during data loading:\n",
        "# (1) Fully connect the graphs, (2) Select the target/label\n",
        "transform = T.Compose([CompleteGraph(), SetTarget()])\n",
        "\n",
        "# Load the QM9 dataset with the transforms defined\n",
        "dense_dataset = QM9(path, transform=transform)\n",
        "\n",
        "# Normalize targets per data sample to mean = 0 and std = 1.\n",
        "mean = dense_dataset.data.y.mean(dim=0, keepdim=True)\n",
        "std = dense_dataset.data.y.std(dim=0, keepdim=True)\n",
        "dense_dataset.data.y = (dense_dataset.data.y - mean) / std\n",
        "mean, std = mean[:, target].item(), std[:, target].item()\n",
        "\n",
        "# Split datasets (3K subset)\n",
        "train_dataset_dense = dense_dataset[:1000]\n",
        "val_dataset_dense = dense_dataset[1000:2000]\n",
        "test_dataset_dense = dense_dataset[2000:]\n",
        "print(f\"Created sparse dataset splits with {len(train_dataset_dense)} training, {len(val_dataset_dense)} validation, {len(test_dataset_dense)} test samples.\")\n",
        "\n",
        "# Create dataloaders with batch size = 32\n",
        "train_loader_dense = DataLoader(train_dataset_dense, batch_size=32, shuffle=True)\n",
        "test_loader_dense = DataLoader(test_dataset_dense, batch_size=32, shuffle=False)\n",
        "val_loader_dense = DataLoader(val_dataset_dense, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5Hzvjjlu8Po"
      },
      "source": [
        "Let's now check that the sparse dataset that we have been using throughout the practical is actually more sparse than the fully-connected dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KcoOtUlRu-7y"
      },
      "outputs": [],
      "source": [
        "val_batch_dense = next(iter(val_loader_dense))\n",
        "val_batch_sparse = next(iter(val_loader))\n",
        "\n",
        "# These two batches should correspond to the same molecules. Let's add a sanity check\n",
        "assert torch.allclose(val_batch_sparse.y, val_batch_dense.y, atol=1e-4)\n",
        "\n",
        "print(f\"Number of edges in sparse batch {val_batch_sparse.edge_index.shape[-1]}. Number of edges in dense batch {val_batch_dense.edge_index.shape[-1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmEYl8nUvoiy"
      },
      "source": [
        "Let's now compare the models under the two scenarios:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rA2iXAeg0c1s"
      },
      "outputs": [],
      "source": [
        "sparse_results = RESULTS\n",
        "dense_results = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hphYbE9WvnQg"
      },
      "outputs": [],
      "source": [
        "# ============ YOUR CODE HERE ==============\n",
        "# Instantiate your models\n",
        "# models = ...\n",
        "# ==========================================\n",
        "\n",
        "for model in models:\n",
        "  model_name = type(model).__name__\n",
        "\n",
        "  if model_name not in dense_results:\n",
        "    dense_results[model_name] = run_experiment(\n",
        "        model,\n",
        "        model_name,\n",
        "        train_loader_dense,\n",
        "        val_loader_dense,\n",
        "        test_loader_dense,\n",
        "        n_epochs=100\n",
        "    )\n",
        "\n",
        "  if model_name not in sparse_results:\n",
        "    sparse_results[model_name] = run_experiment(\n",
        "        model,\n",
        "        model_name,\n",
        "        train_loader,\n",
        "        val_loader,\n",
        "        test_loader,\n",
        "        n_epochs=100\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2RoAlb-ytrE"
      },
      "outputs": [],
      "source": [
        "df_sparse = pd.DataFrame.from_dict(sparse_results, orient='index', columns=['Best val MAE', 'Test MAE', 'Train time'])\n",
        "df_dense = pd.DataFrame.from_dict(dense_results, orient='index', columns=['Best val MAE', 'Test MAE', 'Train time', 'Train History'])\n",
        "df_sparse['type'] = 'sparse'\n",
        "df_dense['type'] = 'dense'\n",
        "df = df_sparse.append(df_dense)\n",
        "\n",
        "sns.set(rc={'figure.figsize':(10, 6)})\n",
        "sns.barplot(x=df.index, y=\"Test MAE\", hue=\"type\", data=df);\n",
        "\n",
        "# You might want to save and download this plot\n",
        "plt.savefig(\"comparison.png\")\n",
        "# files.download(\"comparison.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3G6fTYdwzLWj"
      },
      "source": [
        "Compare the models' performances under the two scenarios. Which models performed better/worst? Why do you think that is the case? Did you observe any differences between the fully-connected and sparse scenarios? Provide at least *two* arguments to explain the differences.\n",
        "\n",
        "---\n",
        "\n",
        "<font color='red'>❗️YOUR ANSWER HERE</font>\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqzHnsceNk4z"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "[Fin.](https://www.youtube.com/watch?v=b9434BoGkNQ)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vg3BV0uSDqlx"
      },
      "source": [
        "---\n",
        "---\n",
        "---\n",
        "\n",
        "# FAQ and General Advice\n",
        "\n",
        "### Unit Testing\n",
        "Consider using the unit test functions as sanity checks to make sure what you think is going on is actually going on. You can even consider writing your own unit tests beyond what we have asked in order to test specific properties of layers/models or numerical issues during training.\n",
        "\n",
        "### Theory vs. Empirical Results\n",
        "If you are confident that your proposed layer is theoretically sound, e.g. if your solution satisfied 3D equivariance but the results are not impressive or you are unable to achieve stable training, it may be due to numerical instability or engineering issues. If that is the case and you are not able to overcome those issues eventually, you may still submit whatever you have as a solution.\n",
        "\n",
        "### GPU rate-limit on Google Colab\n",
        "**TL;DR** Don’t panic, start early, save and load your results instead of re-running every time.\n",
        "\n",
        "We experienced rate-limits several times during the testing of the practical. It seems that there is an upper limit to the amount of GPU computation per user per 12-24 hours. When the limit is hit, Colab disconnects the GPU runtime (you do reconnect back to the GPU by the next day). Thus, we have tried to keep the practical as computationally simple as we can.\n",
        "\n",
        "We have several suggestions to make life more manageable, which we enumerate in the following bullet points:\n",
        "- If possible, do not leave things for the last moment. Start early so that you are not struggling with the rate limit on the day of the deadline!\n",
        "- If you do get rate-limited, you can consider writing and testing your model implementations with very small dataset sizes, e.g. 100 samples each. When you reconnect to the GPU, you can re-run your models with the full dataset.\n",
        "- If you find yourself hit by regular rate-limiting (e.g. if you also have other Colab projects running, this can happen a lot), you can save the results of each task to your Google Drive/local storage and simply load them each time you re-run the notebook.\n",
        "- You can use some combination of a new Google account, your cam.ac.uk account, and/or a new IP address to get a fresh GPU runtime if you have been rate-limited on one account.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
